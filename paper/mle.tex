\chapter{Maximum likelihood estimation} \label{mle}
\index{maximum likelihood estimation|ff}
\index{MLE|see{maximum likelihood estimation}}

Maximum likelihood estimators (MLEs) are the bread and butter of
statistics. Most of the techniques we've handled so far are MLE
techniques, except mathematicians over the ages have found ways to hide
that fact from you. But if there isn't a nice, convenient way to get
around doing the maximization, you'll have to do it yourself. Fortunately,
the GSL has the {\tt gsl\_multimin} family of objects, to help you find
the optimal parameters. Apophenia even has an \ttind{apop\_maximum\_likelihood}
function that preps and calls the GSL functions for you. You give it a
function and some parameters, and it will find the optimum.


\section{Why likelihood functions are great} There are two reasons, with four names.

\paragraph{MLEs achieve the Cramer-Rao lower bound} The CRLB of variance
is the inverse of the derivative of the derivative of the log of the
likelihood function. [I'll get around to writing it nicely later.] It's
called a `lower bound' because Mr.s Cramer and Rao proved that any
estimator of $\beta$ must have a variance greater than or equal to the
CRLB. Your favorite statistics textbook will also prove that for the MLE,
the variance is actually equal to the CRLB, meaning that we can not get
an estimator of $\beta$ which will have any smaller a variance.

\paragraph{The Neyman-Pearson lemma} There are two types of error we could
have with a hypothesis test: Type I is that we reject the null when it's
true; Type II is that we accept the null when it's false. The first type
is the one we focus on, because it's what we mean when we say that our
test has $\alpha=95\%$ confidence. What about Type II errors? Well, Neyman
and Pearson showed that a likelihood ratio test will have the minimum
possible Type II error of any test with the $\alpha$ that we selected. After establishing this fact, we
just ignore Type II errors.

\section{Description: Maximum likelihood estimators} 


\comment{
\subsection{The GSL's multimin functions} The process of finding a minimum consists of trying a
value, picking a direction to move in, and checking whether the change is a good enough one. The GSL
gives you a function to do all of these things, which you'll have to put together to do a complete
minimization.
}

\section{Hypothesis testing: Likelihood ratio tests} Every test
in the last chapter was a likelihood ratio test---I just didn't tell
you what the likelihood function was. Those functions are easy because
they've been carefully studied and methods have been found to let you
calculate them without explicitly writing down a likelihood function
and calculating its value at various locations.

But if your data is at all interesting, then you'll need to write down
the likelihood function yourself.  Fortunately, we have a computer to
do the tedious math, unlike poor Mr. Gauss, who had no such conveniences.


\paragraph{What if you don't know the variance or distribution?} 
The main convenience of the canned methods of the last
chapter is that we have mathematical proofs telling us exactly what the distribution looks like. 

What if our data doesn't fit the assumptions of any of the proofs in the textbook?

Then we bootstrap to find the distribution! I'll put an example here which puts together the techniques
from the last chapter and this one, constructing a likelihood function like the one above using the
bootstrap.

\section{Writing your own}
The design of the {\tt apop\_\-model} hopes to make it as easy as possible for you,
dear reader, to write new models. For the most part, all you need to
do is write a log likelihood function, and \ttind{apop\_\-maximum\_\-likelihood}
does the rest.


\begin{itemize}
\item Write a likelihood function. Its header will look like this:
%[
double apop_new_log_likelihood(const gsl_vector *beta, void *d)
%]
where {\tt beta} will be the parameters to be maximized, and {\tt d} is the fixed parameters---the data. In every case currently included
with Apophenia, {\tt d} is a {\tt gsl\_\-matrix,} but you do not have to conform
to that. This function will return the value of the log likelihood function at the given parameters.

\item Is this a constrained optimization? See below on how to set them.

\item Write the object. In your header file, include 
%[
apop_model apop_new_likelihood = {"The Me distribution", 
            number_of_parameters, 
{       //what will apop_new_likelihood.estimate return?
        1,      //parameters 
        1,      //covariance
        1,      //confidence
        0,      //predicted
        0,      //residuals
        1,      //log_likelihood
        1       //names;
},          new_estimate,
            new_log_likelihood, 
            NULL,   //place dlog likelihood here.
            NULL,   //place constraint fn here.
            NULL    //place RNG here.
            };
%]
If there are constraints, then replace the appropriate {\tt NULL} with the right constraint function; see below.
{\tt number\_\-of\_\-parameters} is probably a positive integer like {\tt 2}, but
it is often (the number of columns in your data set) -1, in which case,
set {\tt number\_\-of\_\-parameters} to {\tt -1}.

\item Test. Debug. Retest.

\item (optional) Write a gradient for the log likelihood function. This
typically involves calculating a derivative by hand, which is an easy
problem in high-school calculus. The function's header will look like: 
%[
void apop_new_dlog_likelihood(const gsl_vector *beta, void *d, 
                                    gsl_vector *gradient)
%]
where {\tt beta} and {\tt d} are fixed as above, and {\tt gradient} is a {\tt gsl\_\-vector} with dimension matching {\tt beta}. 
At the end of this function, you will have to assign the appropriate derivative to every element of the gradient vector:
%[
gsl_vector_set(gradient,0, d_a);
gsl_vector_set(gradient,1, d_b);
%]
Now add the resulting dlog likelihood function to your object, by replacing the {\tt NULL} labeled "place dlog likelihood here" with the name of your dlog likelihood function.
\item Send the code to the maintainer for inclusion in future versions of Apophenia.
\end{itemize}


\subsection{Setting constraints}\index{optimization!constrained}

The problem is that the parameters of a function must not take on
certain values, either because the function is undefined for those
values or because parameters with certain values would not fit the
real-world problem.

The solution is to rewrite the function being maximized such that the
function is continuous at the constraint boundary but takes a steep
downward slope. The unconstrained maximization routines will be able
to search a continuous function but will never return a solution that
falls beyond the parameter limits.

If you give it a likelihood function with no regard to constraints plus
an array of constraints, \ttind{apop\_\-maximum\_\-likelihood} will combine
them to a function that fits the above description and search accordingly.

This is similar to the common penalty function methods of turning an
constrained problem into an unconstrained one, as in \cite{avriel:nonlinear},
with a few differences. Primarily, we don't know if the constraint is
because the author of the system declared an arbitrary cutoff (`we can't spend more
than \$1,000.') or if evaluating the likelihood function fails
($\ln(-1)$). 

A constraint function must do three things:
\begin{itemize}
\item It must check the constraint, and if the constraint does not bind (i.e., the parameter values are OK), then it must return zero.
\item If the constraint does bind, it must return a penalty, that indicates how far off the parameter is from meeting the constraint.
\item if the constraint does bind, it must set a return vector that the likelihood function can take as a valid input. The penalty at this returned value must be zero.
\end{itemize}

The idea is that if the constraint returns zero, the log likelihood
function will return the log likelihood as usual, and if not, it will
return the log likelihood at the constraint's return vector minus the
penalty. To give a concrete example, here is a constraint function that
will ensure that both parameters of a two-dimensional input are both
greater than zero:

%[
static double beta_zero_and_one_greater_than_x_constraint(gsl_vector *beta, 
                                    void * d, gsl_vector *returned_beta){
double          limit0          = 0,
                limit1          = 0,
                tolerance       = 1e-3; // or try GSL_EPSILON_DOUBLE
double          beta0   = gsl_vector_get(beta, 0),
                beta1   = gsl_vector_get(beta, 1);
        if (beta0 > limit0 && beta1 > limit1)
                return 0;
        //else create a valid return vector and return a penalty.
        gsl_vector_set(returned_beta, 0, GSL_MAX(limit0 + tolerance, beta0)); 
        gsl_vector_set(returned_beta, 1, GSL_MAX(limit1 + tolerance, beta1));
        return GSL_MAX(limit0 + tolerance - beta0, 0) 
                        + GSL_MAX(limit1 + tolerance - beta1, 0); 
}
%]

Observe how it manages all three of the above steps. First, it checks
the constraints and quickly returns zero if none of them bind. Then, if
they do bind, it sets the return vector to just inside the constrained
region. Finally, it returns the distance (on the Manhattan metric)
between the input point and the point returned. The hope is that the
evaluation system will repeatedly try points closer and closer to the
zero-penalty point, and the penalty will continuously decline as we
approach that point.

For another example, have a look at the budget constraint in the code
listing at the end of this chapter.

\section{Non-stats modeling}    \label{econ101}

The MLE functions of Apophenia are designed to maximize a function
subject to constraints---which sounds a lot like any of a variety of
other problems, especially in Economics. With little abuse of the package,
one could use it to solve non-statistical models involving maximization
subject to constraints. For example, the code listing at the end of this
chapter shows how one could numerically solve a utility maximization
problem from Econ 101. 

It requires a few digressions from the MLE nomenclature:
\begin{itemize}
\item The log likelihood is actually the utility function. Don't take logs,
since that would mess up the marginal utilities.

\item The data is the fixed input to the MLE, which means the parameters:
prices, budget info, utility parameters.

\item The betas in the MLE framework are the free parameters to be
maximized, which in this case means the goods the consumer is choosing.
\end{itemize}

Utility is $U = x_1^\alpha * x_2^\beta$. 
The budget constraint dictates that $P_1 x_1 + P_2 x_2 <= B$.
                                                             
The data vector looks like this:\\
0:  price0\\
1:  price1\\
2:  budget \\
3:  alpha  \\
4:  beta   
                                                             
Most of the work is in writing down all the constraints, since the
function itself is trivial. Having written down the model, the estimation
is one function call, and calculating the marginal values is one more.
Overall, the program is overkill for a problem that can be solved via
two derivatives, but the same framework can be used for problems with no
analytic solutions (to give one example, if the consumer has a stochastic
utility function).

\paragraph{Code listing: econ 101 homework}
\hrule 
%[
#include <apophenia/headers.h>

apop_model econ_101;

static apop_estimate * econ101_estimate(gsl_matrix * data, 
                            apop_inventory *uses, void *parameters){
apop_estimate           *est;
apop_estimation_params  mle_params;
    mle_params.method       = 000;
    mle_params.starting_pt  = NULL;
    mle_params.step_size    = 1e-1;
    mle_params.tolerance    = 1e-8;
    mle_params.verbose      = 0;
    apop_inventory_filter(uses, econ_101.inventory_filter);
    est = apop_maximum_likelihood(parameters, uses, econ_101, mle_params);
    est->uses.covariance    = 0;    //MLE finds them, but it's meaningless.
    est->uses.confidence    = 0;    //MLE finds them, but it's meaningless.
    est->uses.log_likelihood  = 0;
    return est;
}
%*
//
// The constraint function, including three constraints: x0>0, x1>0, and
// the bundle is under budget.  First, we check wether anything binds,
// and if not we return zero immediately.  Both sets of constraints are
// handled in the same way: derive new values that are within bounds,
// and report how far you had to move.

static double budget_constraint(gsl_vector *beta, void * d, 
                                        gsl_vector *returned_beta){
gsl_vector  *budget = d;
double  price0      = gsl_vector_get(budget, 0),
        price1      = gsl_vector_get(budget, 1),
        cash        = gsl_vector_get(budget, 2),
        x0          = gsl_vector_get(beta, 0),
        x1          = gsl_vector_get(beta, 1),
        tolerance   = 1e-3,
        new_x0, new_x1, penalty;
    if ((x0 * price0 + x1 * price1<= cash) && (x0 > 0) && (x1 > 0))
        return 0;
    //else:
    if (x0 <= 0 || x1 <= 0){
        new_x0  = (new_x0 > 0)? x0 : tolerance;
        new_x1  = (new_x1 > 0)? x1 : tolerance;
        penalty = (fabs(new_x0 - x0) + fabs(new_x1 + x1));
    } else {
        new_x0  = GSL_MAX(0, cash - x1* price1);
        new_x1  = GSL_MIN(x1, cash - new_x0* price0);
        penalty = (GSL_MAX(0,x0 * price0 + x1 * price1- cash));
    }
    gsl_vector_set(returned_beta, 0, new_x0);
    gsl_vector_set(returned_beta, 1, new_x1);
    return penalty;
}
%*
static double econ101_log_likelihood(const gsl_vector *beta, void *d){
gsl_vector  *params = d;
double      bb0     = gsl_vector_get(params, 3),
            bb1     = gsl_vector_get(params, 4),
            qty0    = gsl_vector_get(beta, 0),
            qty1    = gsl_vector_get(beta, 1);
    return pow(qty0, bb0) * pow(qty1, bb1);
}    
%*
apop_model econ_101 = {"Max Cobb-Douglass subject to a budget constraint", 2,  {
    1,    //parameters
    0,    //covariance
    0,    //confidence
    0,    //predicted
    0,    //residuals
    0,    //log_likelihood
    0    //names;
},         
    econ101_estimate, econ101_log_likelihood, NULL, NULL, budget_constraint, NULL};
%*
int main(){
double          param_array[]   =  {1, 3, 38.4, 0.4, 0.6};//see header.
gsl_vector      *params         = gsl_vector_alloc(5);
gsl_vector      *marginals      = gsl_vector_alloc(2);
apop_estimate   *e;
double          x1, x2;
    apop_convert_array_to_vector(param_array,&params,5);
    e   = econ_101.estimate(NULL, NULL, params);
    printf("The optimal quantities:\n");
    apop_estimate_print(e);

    x2  = param_array[2]/(param_array[3]/param_array[4]+1)/param_array[1];
    x1  = (param_array[2] - param_array[1] * x2)/param_array[0];
    printf("\nAnalytically, these should be:\n %g\n %g\n\n", x1, x2);

    apop_fn_for_derivative  = econ_101.log_likelihood;
    apop_numerical_gradient(e->parameters, params, marginals);
    printf("The marginal values:\n");
    apop_vector_print(marginals, "\n", NULL);
    printf("\nAnalytically, these should be:\n %g\n %g\n", 
            param_array[3]*pow(x1,param_array[3]-1)*pow(x2,param_array[4]),
            param_array[4]*pow(x2,param_array[4]-1)*pow(x1,param_array[3]));

    return 0;
}
%]
