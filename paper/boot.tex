\chapter{Monte Carlo} \label{boot} 

\blindvocab{Monte Carlo method}
Monte Carlo (Spanish and French for Mount Carl) is a city in Monaco
famous for its casinos, and has more glamorous associations with its name
than Reno or Atlantic City.

Monte Carlo methods are thus about randomization: taking existing data
and making random transformations to learn more about it. But
\airq{random} does not necessarily mean \airq{haphazard}.
At the
roulette table, a single player may come out ahead, but with millions of
suckers testing their luck, casinos find that even a 49-51 bet in their
favor is a reliable method of
making money.  Similarly, a single random transformation of the data will
no doubt produce a somehow distorted picture, but reapplying it thousands
or millions of times will present an increasingly accurate picture of
the underlying data.

This chapter will first look at the basics of random number generation.
It will then discuss the general process of describing a data set with
Monte Carlo techniques.  As a special case,
bootstrapping and jackknifing are methods of getting a variance out of
data that, by all rights, should not be able to give you a variance. 

\section{Random number generation}\index{random numbers|(}\label{randomnumbers}\label{rngs}
\vocabmarker{random number generator}
Random number generators are not random: given the same setup, they
will produce the same value every time you use them. To lay-intuition,
this is not really \airq{random}, but for the programmer, it is wonderful,
because you can replicate your results.

There are two places where you will need replication. The first is with
debugging, since you don't want the segfault you are trying to track
down to magically appear and disappear every other run. The second is
in reporting your results, because when a colleague asks to see how you
arrived at your numbers, you should be able to reproduce them to four
decimal places.

Of course, using the same stream of numbers every time creates the
possibility of getting a lucky draw, where \airq{lucky} can mean any of a
number of things. The solution is a fixed process of pseudorandom
number generation plus a varying initializing \vocab{seed}. The GSL implements
such a process.


\begin{figure}
\ckeyind{static}
\cindex{apop\_rng\_alloc}
	\hrule\vskip4pt
\begin{lstlisting}[frame=none]
gsl_rng *apop_rng_alloc(int seed){
static int first_use    = 1;
   if (first_use){
       first_use --;
       gsl_rng_env_setup();
   }
gsl_rng *setme  =  gsl_rng_alloc(gsl_rng_taus);
    gsl_rng_set(setme, seed);
    return setme;
}
\end{lstlisting}
	\hrule
\caption{Allocating and initializing a random number generator.}
\label{rng_alloc}
\end{figure}

Figure \ref{rng_alloc} shows a function from the Apophenia library to initialize a \cind{gsl\_rng}.
In all cases, the function takes in an integer, and then sets up the
random number generation (RNG) environment to produce new numbers
via the Tausworth routine.  On the first call, the function calls the
\cind{gsl\_rng\_env\_setup} function to work some internal magic in
the GSL. Figure \ref{drawbeta} below shows an example using this
function.

Adjacent integer seeds will produce a wholly different stream of numbers,
so there is no need to make the seed look random. The GSL's default seed is
zero, and if you need ten different seeds, I suggest using 0, 1, \dots, 9.
See below for one more useful seeding method.

\subsection{Random number distributions}
Now that you have a random number generator, here are some functions that use it to draw from all of your favorite distributions. Input an RNG as allocated above plus the appropriate parameters, and the GSL will transform the uniform RNG as necessary.
\index{Gaussian distribution} \index{t distribution} \index{F distribution} \index{flat distribution} 
\index{Uniform distribution}\cindex{gsl\_ran\_...}\cindex{gsl\_rng\_uniform}
\index{Bernoulli distribution} \index{Beta distribution} 
\index{Binomial distribution} \index{chi squared distribution@$\chi^2$ distribution}

\begin{lstlisting}
double gsl_ran_bernoulli (gsl_rng *r, double p);
double gsl_ran_beta (gsl_rng *r, double a, double b);
double gsl_ran_binomial (gsl_rng *r, double p, int n);
double gsl_ran_chisq (gsl_rng *r, double NU);
double gsl_ran_fdist (gsl_rng *r, double NU1, double NU2);
double gsl_ran_gaussian (gsl_rng *r, double SIGMA);
double gsl_ran_tdist (gsl_rng *r, double NU);
double gsl_ran_flat (gsl_rng *r, double A, double B);
double gsl_rng_uniform (gsl_rng *r);
\end{lstlisting}

The \airq{flat} distribution is a Uniform[A,B] distribution. Since the
Uniform[0,1] distribution is so common, it gets its own no-options
function, \cinline{gsl\_rng\_un\-i\-form(r)}. Notice that the Gaussian draw
assumes a mean of zero, so if you intend to draw from a ${\cal N}(7,2)$,
then add the mean after the call: \cinline{gsl\_ran\_gaussian (r, 2) + 7}.

\paragraph{The Beta distribution}\index{Beta distribution}\label{beta}
The Beta distribution is wonderful for all sorts of modeling, because
it can describe such a wide range of probability functions for a
variable $\in [0,1]$.  But its $\alpha$ and $\beta$ parameters may be
difficult to interpret; we are more used to the mean and variance. Thus,
Apophenia provides one convenience function for the Beta distribution,
\cind{apop\_ran\-dom\_beta}. You can give it a mean, a variance, and
a random number, and it will calculate the appropriate values of $\alpha$
and $\beta$ and return a random draw from the appropriate distribution.

Quick---what is the variance of a Uniform$[0,1]$? Answer: ${1\over 12}$,
which means that the Beta distribution will never have a variance greater
than ${1\over 12}$ (and close to ${1\over 12}$, perverse things may
happen computationally for $\mu \not\approx {1\over 2}$).\footnote{More
trivia: the Uniform$[0,1]$ is symmetric, so its skew is zero. Its
kurtosis is $\frac{1}{80}$.} The mean of a
function that has positive density iff $x \in [0,1]$ must be
$\in (0,1)$. If you send \cind{apop\_ran\-dom\_beta} values of $\mu$
and $\sigma^2$ that are outside of these bounds, the function will
return a \cinline{GSL\_NAN}.

\cindex{apop\_plot\_hist\-o\-gram}
\codefig{drawbeta}{Building a picture of a distribution via random draws.}

What does a Beta distribution with, say, $\mu = \frac{3}{8}, \sigma^2 =
\frac{1}{24}$ look like? Figure \ref{drawbeta} sets up an RNG,
makes a million draws from a Beta distribution, and plots the result.
The output of this example is at left in Figure \ref{histofig}; by
contrast, the case where $\mu=0.492$, $\sigma^2 = 0.093$ is pictured at
right.


%\def\bebox#1{\vbox{\hbox{\rotatebox{-90}{\scalebox{.30}{\includegraphics{#1}}}} }}

\def\bebox#1{\vbox{\hbox{\rotatebox{-90}{\includegraphics[width=\textwidth*\real{0.38}]{#1}}} }}

\begin{figure}[htb]
\hskip -1.4cm
\begin{tabular}{cc}
\bebox{betauni.eps}& \bebox{betabi.eps}
\end{tabular}

\caption{The flexible Beta distribution.}
\label{histofig}
\end{figure}

\paragraph{\treesymbol Seeding with the time} There are situations where
a fixed seed is really not what you want---you want different numbers
every time you run your program. The easiest solution is to seed using
the \cind{time} function. The standard library function \ci{time(NULL)}
will return the number of seconds that have elapsed since the beginning
of 1970, which is roughly when UNIX and C were first written. As I write
this, \ci{time} returns 1,147,182,523---not a very good way to tell the
time. There are a number of functions that will turn this into hours,
minutes, or months; see any reference on C's standard
library (such as the GNU C Library documentation) for details. But this
illegible form provides the perfect seed for an RNG, and you get a new
one every second.

\codefig{time}{Seeding an RNG using the time.}

Figure \ref{time} shows a sample program that
does this, producing ten random numbers that will be different every
time.  This is not industrial-strength random number generation, because
patterns could conceivably slip in. If you are running the program repeatedly  
via a batch file, then the program could run in fixed
intervals that induce somehow-correlated numbers. For an example of the extreme case, try
compiling the above program (it is included in the bundle of sample
code online), and run it continuously from the shell. In the \bi{bash}
shell
(what you are probably using on a UNIX-type system such as Linux, Cygwin, or MacOS), try
\begin{lstlisting}[language=bash]
while true; do ./time; done
\end{lstlisting}
You should see the same numbers a few dozen times until the clock ticks
over, and then another stream repeated several times.  [You can get your
command prompt back using $<$ctrl$>$-C.\index{halting via $<$ctrl$>$-C}\index{breaking via $<$ctrl$>$-C}] If you have multiple processors
and run one simulation on each, then runs that start in the same second
will be replicating each other. Finally, if you ever hope to debug this
program, then you will need to write down the time started so that you
can replicate the runs that break: 
\begin{lstlisting}[texcl=true]
//I assume the database is already open and has a one-column
//table named \sinline{runs}. The time is a long integer
//in the GNU standard library, so its printf tag is \ci{\%li}.
long int right_now = time(NULL);
apop_query("insert into runs (%li);", right_now);
gsl_rng *r = apop_rng_alloc(right_now);
\end{lstlisting}
Caveats aside, if you just want
to see some variety every time the program runs, then this trick
works fine.



\subsection{Drawing from your own data} \index{histograms!drawing from|(}
Another possibility, beyond drawing from famous distributions that your
data theoretically approximates, would be to draw from your actual data.

We have already created histograms---rough probability mass
functions---for plotting data in Chapter \ref{gnuplot} and for goodness
of fit tests in Chapter \ref{testing}. Now we only need a mechanism to
make draws from such a PMF.

The GSL provides a means of turning a data set into a PMF from which you
can then make draws.  It does so by aggregating the data into a histogram
and then producing a CMF.\footnote{That's right: the \cind{gsl\_histogram}
struct internally holds a PMF, and the \cind{gsl\_histogram\_pdf} struct
internally holds a CMF.} Then, the \cind{gsl\_histogram\_pdf\_sample}
function will map a draw from a Uniform[0,1] distribution to the CMF,
thus producing a random draw from your data.

The \cind{apop\_vector\_to\_pdf} function takes the requisite steps
for you, producing a histogram from the data and then converting it to
a \cind{gsl\_histogram\_pdf} structure from which draws can be
made. It takes two arguments: a \cinline{gsl\_vector} with the data, and
an \cinline{int} listing the number of bins that the histogram should
have. This should be calibrated to the resolution of the data: if the
data is accurate to a thousandth, then it makes sense to have on the
order  of a thousand
bins. Over-accuracy takes up memory, but there is no numerical harm to having
zeros in the vast majority of bins. Usage:
\begin{lstlisting}
    //Setup:
    gsl_vector  *data    = produce_data_set(...);
    gsl_histogram_pdf *p = apop_vector_to_pdf(data, 1000);
    gsl_rng *r = apop_rng_alloc(7);

    //Draw from the PDF:
    double      draw;
    while (get_more_data){
        draw = gsl_histogram_pdf_sample(p, gsl_rng_uniform(r));
        ...
    }

    //Eventually, clean up:
    gsl_histogram_pdf_free(p);
\end{lstlisting}
\cindex{gsl\_histogram\_pdf\_free}
\index{histograms!drawing from|)}

\paragraph{\treesymbol The standard C RNG}
If the GSL is not available, the standard C library includes a \cind{rand}
function to make random draws and an \cind{srand} function to set random
seeds. E.g.:
\begin{lstlisting}
#include <stdlib.h>
srand(27);
printf("draw from a U[0,1]: %i", rand()/(RAND_MAX +1));
\end{lstlisting}

The GSL's RNGs are preferable for a few reasons. First,
\cind{gsl\_ran\_max}\ci{(r)} is typically greater than \ci{RAND\_MAX},
giving you greater variation and precision. 
Second, the standard specifies that there must be a \ci{rand} function,
but not how it works: two machines may give you two streams of random
numbers for the same seed.

\index{Agents!assigning RNGs}
Finally, \ci{rand} gives your entire
program exactly one stream of numbers, while you can initialize many
\ci{gsl\_rng}s that will each be independent of each other. 
For example,
if you give every agent in a simulation its own RNG, you can re-run the
simulation with one agent eliminated and are guaranteed that the
variation is due to the agent, not RNG shifts. Here is some sample code
to clarify how such a setup would be initialized.
\begin{lstlisting}
typedef struct agent{
    long int agent_number;
    gsl_rng *r;
    ...
} agent;

void init_agent(agent *initme, int agent_no){
    initme->agent_number = agent_no;
    initme->r            = apop_rng_init(agent_no);
    ...
}
\end{lstlisting}


\index{random numbers|)}

\summary{
\item Random number generators produce a deterministic sequence of
values. This is a good thing, because we could never debug a program
without it. Change the stream by setting a different seed.
\item Given a random number generator, you can use it to draw from any
common distribution or from a histogram.
\item Once you produce a histogram of a data set, you can also use the
RNG to produce draws from the data set.
}

\section{Finding statistics for a distribution} \label{billiondraws}
For many statistic-distribution pairs, there exists a closed-form
solution for the statistic: the kurtosis of a ${\cal N}(\mu,\sigma)$
is $3\sigma^4$; the variance of a binomial distribution is $np(1-p)$,
et cetera. One can also take recourse in the \ind{Slutsky theorem}, that
says that given an estimate $r$ for some statistic $\rho$ and a continuous
function $f(\cdot)$, then $f(r)$ is a valid estimate of $f(\rho)$. Thus,
sums or products of means, variances, and so on are easy to calculate as well.

However, there is a limit to how far closed-form solutions will take us.
This is especially true for small data sets: virtually every theorem
about a statistic begins by saying \airq{in the limit as $n\to \infty$,
it holds that\dots}.

Lacking a closed-form calculation for a statistic, the next best thing
is to estimate the statistic from the data. 

One way to calculate the expected value of $f(\cdot)$ would be to a numeric
integral over the entire domain of the distribution. Write a loop to
sum $$\frac{f(-500.00)\cdot p(-500.00)}{100000} + \frac{f(-499.99)\cdot
p(-499.99)}{100000} + \cdots + \frac{f(500.00)\cdot p(500.00)}{100000}.$$ This can be effective, but there are
some details to be hammered out: if your distribution has a domain over all
$\Re$, should you integrate from $[-3,3]$
or $[-30,30]$? You must decide up-front how much finer resolution will
affect the integral, because (barring some exceptional tricks) each
resolution is a new calculation rather than a modification of prior 
calculations. If you would like to take this approach, the GSL includes
a set of numerical integration functions.

Another approach is to evaluate $f(\cdot)$ at values randomly drawn
from the distribution.  Just as we produced a nice picture of the
Beta distribution by taking enough random draws, we can calculate
statistics of the overall distribution via random draws.  Values will,
by definition, appear in proportion to their likelihood, so the $p(\cdot)$
part takes care of itself. There is no cutoff such that the tails of the
distribution are assumed away. You can incrementally monitor
$E[f(\cdot)]$ at 1,000 random draws, at 10,000, and so on, to see how
much more you are getting with the extra computation.


\paragraph{An example: the \ind{kurtosis} of a \ind{t distribution}}\label{tkurt} 
Perhaps the
story is best told via an example.  You probably
know that a \ind{t distribution} is much like a Normal distribution but
with fatter tails, but probably not how much fatter those tails are.
The kurtosis of a vector is easy to calculate---just call
\cind{apop\_kurtosis}. By taking a million or so draws from the
distribution, we can produce a vector whose values cover the $t$
distribution rather well, and then find the kurtosis of that vector.

Listing \ref{tdistkurtosis} shows a program to execute this procedure. 
It opens with the usual introductory material, where variables are
declared and constants set. The draws are done by the line
\ci{gsl\_vector\_set(v, i, gsl\_ran\_tdist(r, df))}, which sets an
element of the vector \ci{v} to a random value. Once the vector is
filled, we can print the kurtosis. Notice that the kurtosis is
multiplied by $(n-1)/n$ to convert from sample kurtosis to population 
kurtosis. This has no appreciable effect for $n >$ 1 million, but since it takes
0.00 seconds to compute, it doesn't hurt.

\codefig{tdistkurtosis}{Monte Carlo calculation of kurtoses for
the $t$ distribution family.}

I tried this on a few computers, from my laptop to a small research
server, and the process took from under two minutes up to eight
minutes---not bad for .15 billion draws from $t$ distributions followed
by finding the fourth moment of vectors 5 million elements
long.\comment{\label{rcomplaint}I attempted to replicate this test in
R. On the laptop that needed six minutes for the C program, the R code
\cinline{for (i in 1:30) o<-rt(5000000,i)} needed 18 minutes. I did
not calculate the kurtosis because R has no native kurtosis calculation,
and I wasn't inclined to write one for this test. R's \binline{e1071}
package has a kurtosis function, but it uses the na\"ive method---sum
everything, then divide at the end---that would overflow for five million
data points. Writing a kurtosis calculator that does not overflow
is an exercise for the reader, whose answer can be found in the GSL
source or Apophenia's \binline{apop\_db.c} file.}

The true kurtosis of a $t$ distribution with $df$ degrees of freedom
is $(3 df - 6)/(df - 4)$.  For $df\leq 4$, the kurtosis is undefined,
just as the variance is undefined for a \ind{Cauchy distribution} (i.e., a $t$
distribution with $df=1$). At $df = 5$, it is finite, and it monotonically
decreases as $df$ continues upwards.

Here is an excerpt from the simulation output, along with the true
kurtosis: 

\begin{center}
\fbox{
\begin{tabular}{lll}
df       &k (est)    &     k (analytic)\\
\hline
1        &1.053e+06   \\
2        &21165.3   \\
3        &219.779   \\
4        &18.1571           \\
5        &8.87748        &9 \\
6        &5.94114        &6 \\
7        &4.8948 &5 \\
8        &4.48172        &4.5   \\
9        &4.19337        &4.2   \\
10       &4.00679        &4 \\
15       &3.54983        &3.54545   \\
20       &3.37601        &3.375 \\
25       &3.28091        &3.28571   \\
30       &3.23369        &3.23077   
\end{tabular}
}
\end{center}


Appropriately enough, the estimates for $df\leq 4$ are terrible.  
The fact that there is no consistent estimator for these small 
$df$ cases makes itself evident in re-estimations. The reader could readily
modify the code in Listing \ref{tdistkurtosis} to repeat the kurtosis estimation
procedure many times; here are eight runs and their means:

\vspace{\baselineskip}
\iftwocol\hspace{-8.0cm} 
\else\hspace{-1.4cm} \fi
\fbox{
\begin{tabular}{l|llllllll|l}
df  &Run 1 &Run 2 &Run 3 &Run 4 &Run 5 &Run 6 &Run 7 &Run 8 &Mean\\
\hline
1  &1.05e6 &3.25e6 &4.91e6 &2.55e6 &1.70e6 &2.22e6 &1.58e6 &4.92e6&2.77e6\\
2  &2.12e4 &9.70e4 &1.00e6 &5.37e5 &4.69e4 &2.59e4 &2.86e4 &4.45e4&2.26e5\\
3  &219.779&416.333&201.000&713.504&182.242&146.174&134.896&139.599&269.191\\
4  &18.157 &22.924 &16.448 &18.511 &17.296 &18.523 &24.658 &17.996&19.314\\
5  &8.877  &7.972  &8.446  &9.347  &8.490  &8.983  &9.101  &8.546&8.72\\
10  &4.009   &4.001   &4.015   &3.998   &3.990   &3.995   &3.986   &4.022 &4.002\\
20  &3.380   &3.376   &3.380   &3.380   &3.378   &3.381   &3.375   &3.373 &3.378\\
30  &3.229   &3.228   &3.230   &3.233   &3.230   &3.231   &3.235   &3.230 &3.231\\
40  &3.170   &3.167   &3.167   &3.166   &3.166   &3.165   &3.169   &3.171 &3.168\\
50  &3.125   &3.131   &3.132   &3.129   &3.130   &3.127   &3.130   &3.135 &3.130\\
60  &3.109   &3.107   &3.111   &3.108   &3.106   &3.108   &3.103   &3.104 &3.107\\

\end{tabular}
}
\vspace{\baselineskip}

The runs for fewer than five degrees of freedom are indeed inconsistent:
for $df = 1$, they range from 1.58 million to 4.92 million. Even with
$df = 5$, run \#2 digresses over 10\% from the correct value of nine.

But perhaps this focus on the problem situations is too pessimistic.
After all, if you are fitting a $t$ distribution with five degrees
of freedom, that means you only have six data points, and no amount of
statistical finesse will save you. But as the variance of the statistic being
estimated shrinks, a Monte Carlo estimate of the statistic gets closer to
the correct value, and does so consistently. For degrees of freedom in the
tens, the estimates are all within a few hundredths of the correct value.
Monte Carlo estimation will not save a hopeless cause, but in
appropriate situations, it quickly produces clean and useful estimates.

\summary{
\item By making random draws from a model, we can make statements about 
global properties of the model that improve in accuracy as the number of
draws $\to \infty$.
\item The variance of the Monte Carlo estimation of a parameter tends to
mirror the variance of the underlying parameter. The maximum likelihood
estimator for a parameter achieves the Cram\'er-Rao lower bound, so the
variance of the Monte Carlo estimate will only be worse. For reasonable
parameters, this is not a problem, but in extreme cases, the Monte Carlo
estimate may not converge to a consistent value.
}

\section{Finding the statistics of a parameter}
After running a regression or other such estimation of model parameters,
we frequently want to test the hypothesis that the parameters are not
zero. To do so, we need the parameters' variance.
We can apply the same procedure as above: produce a million parameter
estimates, and then find the variance of those million numbers. However,
the same parameter estimation technique on the same data will always
produce the same number. The way to get different draws from the
distribution of the parameter is to take different draws from the
underlying data set.

The bootstrapping and jackknifing processes consist of taking artificial
samples of your data, and then calculating a statistic for each of these
samples. These draws will be independent and identically distributed.
Typically, your statistic is for the form $\sum (X_i)/ N$, where  $N$
is the number of observations, and $X_i$ is a data point in the case
of a mean, $(X-\mu)^2$ for a variance, et cetera. In other words, the
statistic is often the mean of some iid process, and so the Central
Limit Theorem applies to the series of statistics that you are
producing, regardless of how ugly the underlying data may be.

Since the CLT guarantees that the  statistic is Normally distributed
and we can now calculate the variance of the distribution, we can resume
hypothesis testing as normal. The confidence intervals calculated via these
methods will approach the true confidence interval for the statistic.

\paragraph{An important caveat} Bootstrapping from a sample will not fix
the errors in your sample. If your sampling technique isn't perfect---and
it isn't---then it won't capture the full variation in the data. That
means that the variances you calculate using bootstrap will be less than
the true variance. In a bind you'll just have
to state that and go on. Bootstrapping is a generally accepted technique,
and has reasonable persuasive power.

\codefig{bootdraw}{A function to draw samples from the data, for use in a jackknife.}%This should really be lower.

But having smaller variances makes
it easier to reject the null hypothesis, which is what your paper is
probably trying to do, so bootstrapping works slightly in your favor,
and against parsimony and skepticism. Therefore, the method should be
reserved as a last resort.
\comment{of getting information about the variance of your variable without
bootstrapping, even if that estimate overstates the variance, then use
that instead of bootstrapping. Otherwise, you dishonor your name, and
bring shame to your research group.}

\subsection{Creating random samples} \vocabmarker{jackknife}\blindvocab{bootstrap}
\index{jackknife|(textbf}
The primary difference between bootstrapping and jackknifing is that
the bootstrap takes a series of draws with replacement from a data set,
while the jackknife uses a subset of the data---a series of samples
without replacement. Here, I will discuss the jackknife.

Assume that we have a
data vector \cinline{gsl\_vector * data} and a function \cinline{double
calc\_statistic(gsl\_vec\-tor *da\-ta)} that finds some statistics. The
function \cinline{mean()} fits this description, as would a function to find
a single OLS coefficient.

%bootdraw should be here.

The easiest means of drawing without replacement is to
systematically remove one line of data at a time, as we saw in Listing
\ref{jackiteration} (page \pageref{jackiteration}). For each subset of data, we find the parameter;
once we have a list of $n$ different values for the parameter, $p_1,
p_2, \dots, p_n$, then the standard deviation can be estimated as
$\hat\sigma = \sqrt{\sum{(p_i - \overline p_{\forall})}}$, where $p_{\forall}$ is
the parameter using the entire data set.

\exercise{
Modify Listing \ref{jackiteration} to calculate the jackknife estimate
for a model, replacing the ``Do math here'' comments with the
appropriate parameter estimations.
}

Alternatively, we can try different-sized subsets,
drawing some subset of the data
without replacement. Drawing without replacement means that we need to
keep track of what has been drawn to date, and must check every new draw
to make sure that the new draw is not a repeat. Listing \ref{bootdraw} lists a function which
does all of this. It makes a series of random draws from a uniform distribution in the range
[0, \cinline{data-$>$size}]. It then checks the list of indices which have
already been drawn. If it finds a match, then it invalidates the draw
by rolling back the counter by one, while if it does not find a match then it
adds the draw to the list of draws and the index to the list of indices.

\codefig{bootvar}{A function to find the variance of a series of jackknife
estimates of a statistic.}


We can then use these draws to calculate a list of parameter values,
as in Figure \ref{bootvar}. The procedure looks much like the procedure
for finding the kurtosis for the $t$ distributions above: take a million
draws, write down the statistic for each, and then take the variance of
that vector.


It is valid to use the standard deviation returned by this function 
in the normal way to construct confidence intervals and test
hypotheses about the statistic.

Again, Apophenia has you covered with a jackknifing function, whose
use could not be simpler. To produce the covariance matrix for the
parameters of a Poisson distribution for a given data set:
\begin{lstlisting}
apop_data *covar    = apop_jackknife(data, apop_poisson, NULL);
\end{lstlisting}
In fact, this is redundant, because the \cinline{apop\_pois\-son}
model already uses the \cind{apop\_jackknife} function internally,
so the usual \cinline{apop\_pois\-son.est\-i\-mate(data, NULL)}
will return an estimate with jackknifed variances.
\index{jackknife|)textbf}

\exercise{\index{normality!tests for}
On page \pageref{bootkurt}, I mentioned that one could
bootstrap the variance of the kurtosis and then test that it equals
$3\sigma^4$ using the standard $t$ test. 

Write an \ci{apop\_model} with an \ci{estimate} function that takes in a
data set and returns one parameter: the kurtosis. Feel free to use
\cind{apop\_vector\_kurtosis} and the \ci{apop\_model} template from
Section \ref{writeyourown}, leaving everything but the \ci{estimate}
function at its default values.

Once your model is written, send it with your favorite data to the
\ci{apop\_jackknife} function to produce a variance. Given the variance
of the kurtosis and the mean kurtosis, run a $t$ test using
\cind{gsl\_ran\_tdist\_pdf}.
}

\summary{
\item To test a hypothesis about a model parameter, we need to have an
estimate of the parameter's variance. 
\item If there is no analytic way to find this variance, we can make
multiple draws from the data itself, calculate the parameter, and then
find the variance of that artificial set of parameters. The Central
Limit Theorem tells us that the artificial parameter set will approach a
well-behaved Normal distribution.
}

\section{\ind{Markov Chain Monte Carlo}} 
The convergence to the kurtosis of the $t$ distributions was not
spectacular. We could have found more precise values via a plain old
integral with significantly fewer than five million slices. 

The trick to improving the efficiency of the method is to oversample
values that will have the largest effect on the outcome, and the trick
to that trick is to model the distribution as a set of states and
transition probabilities---a \ind{Markov chain}.

More forthcoming, but notice that the \ind{simulated annealing}
algorithm from Chapter \ref{mle} was such an algorithm.


\subsection{The curse of dimensionality}

If your data is described by
many parameters, then getting a good view of the distribution can require
a huge number of draws. If $1,000$ points describes one dimension well,
you may need $1,000^2$ points in two dimensions, and $1,000^{20}$ in
twenty dimensions. 

Markov chains come to the rescue: under certain conditions, you can
iteratively search one dimension at a time. Begin with a guess as to
the parameter value, $(x_1, x_2, \dots, x_{20})$, and search for the
best value of $x_1$, keeping
$(x_2, \dots, x_{20})$ fixed. Then, search for $x_2$, keeping
$(x_1, x_3,  \dots, x_{20})$ fixed. Repeat until the $\xv$ converges.

This is known as \vocab{Gibbs sampling}.
The method is popular for Bayesian techniques, but is also applicable in
other contexts.

Details will be forthcoming.


\section{Non-parametric modeling}\label{nonparam} It would be nice if we did not
have to specify a distribution, but could find the best fit from the
data itself; this is the goal of \vocab{non-parametric modeling}. 

Alas, this unconstrained goal is far beyond our means.
A distribution can be any function $d:\Re \to [0,\infty)$ such that
$\int_{\forall \Re} d(x) dx = 1$. This is an infinite-dimensional set:
one can map this set of functions to $\Re^\infty$.

Thus, to find the best-fitting $d$ from a data set of a thousand points
is equivalent to finding a deterministic mapping from $\Re^{1,000}
\to \Re^\infty$.  Clearly, we need to impose some sort of constraints
on how this mapping will occur. We would write down a model describing
some subset of distributions; the most popular is to say that the
true distribution is the sum of $n$ ${\cal N}(\mu_i, \sigma_i)$
distributions. Then, we would estimate the best values of $n$ and
$(\mu_i, \sigma_i), i =\{1\dots n\}$, from the data.  

In other words, non-parametric modeling involves writing down a
para\-metrized model and estimating the parameters from data.  This is
especially clear when we sit down to implement such a model at the
computer, because the model will be a black box that takes in a data set
and returns a set of parameter estimates, just like every other model in
this book. 
Such terms as {\em distribution-fitting methods} or {\em optimal
distribution estimation} would probably better describe the methods
discussed in this section.


\paragraph{Testing for bimodality}
A good example of the use of kernel densities is the metod of testing
for multimodality from \citet{silverman:boot}.

It is based on this function:
	%\eqn{smooth}{\hat f(t,X)={{\sum_{i=1}^n{\cal N}((t-X_i)/h)\over n\cdot h}},}
\begin{equation}
	\hat f(t,\Xv,h)={{\sum_{i=1}^n{\cal N}((t-x_i)/h)\over n\cdot
h}},\label{bikernel}
\end{equation}
where $\Xv = [x_1, x_2,\dots x_n] \in \Re^n$ is the vector
of $n$ data points observed, ${\cal N}(y)$ is a Normal$(0,1)$
density function evaluated at $y$, and $h\in \Re^+$ is a smoothing
parameter. 
Figure \ref{smoothing} shows the effect of raising $h$ on the shape of
the fitted curve.\footnote{The data is the male viewership for 86 TV
specials, gathered by Michael Chwe for \citet{chwe:ritual}.} When
$h$ is very small, the Normal distributions around each data point
approach spikes, so there is a mode at every data point. As $h$ rises,
the spike around each point spreads out and merges with other spikes,
until eventualy the entire data set is subsumed under one single-peaked
curve. Thus, there is a monotonic relationship between $h$ and the number
of modes in the density function induced by $h$.

Thus, although $f(t, \Xv, h)$ is a one-parameter distribution, its
behavior matches the data much more closely than a simple bell curve for
small values of $h$, and can represent an arbitrarily smooth
distribution for large values of $h$.
 
\citet{silverman:boot} offers a bootstrap method of testing a null
hypothesis of the form `the distribution has $k$ or fewer modes'. Let
$h_0$ be the smallest value of $h$ such that $\hat f(t,\Xv,h_0)$ has
$k$ modes; then the null hypothesis is that $h_0$ is consistent with
the data.  We then draw a few hundred bootstrap samples from the data,
$\Xv_1'$, \dots, $\Xv_{200}'$; write down $\hat f(t,\Xv_1',h_0)$, \dots, $\hat
f(t,\Xv_{200}',h_0)$; and count the modes of each of these functions. Thanks
to the monotonic relationship between $h$ and the number of modes, the
percentage of bootstrap distributions with $k$ or fewer modes matches
the likelihood that $\hat f(t,\Xv,h_0)$ is consistent with the data.
If we reject this hypothesis, then we would need a lower value of $h$,
and therefore more modes, to explain the data.

A parsimonious researcher should begin by testing
the unimodal hypothesis, and if he fails to reject that hypothesis, he
should stop. Else, he should check the bimodal hypothesis, and should
stop there if he fails to reject, et cetera. 


\begin{figure}[htb]
\hskip -.4cm
\begin{tabular}{cc}
\bebox{smoothing1.ps}& \bebox{smoothing1.5.ps}\\
\bebox{smoothing3.ps}& \bebox{smoothing4.ps}
\end{tabular}
\caption{As $h$ rises, the kernel density smooths out and has fewer modes.}
\label{smoothing}
\end{figure}


\paragraph{A run through the code}
Listing \ref{bimodality} shows the code used to produce these figures,
and tests a data set of television program ratings for bimodality.

As with any run through the code, we begin with \ci{main}. After the
variable-declaration preface, it:

\begin{enumerate}
\item Reads in a data file, and pulls the
first column to the \ci{data} vector. 
\item Produces a mapping from $k \to h$.
\item Produces an animation of the values of $h$ from the lower end of
the rante of $h$ to the upper end.
\item Runs a bootstrap test on each value of $k$ to find the confidence
with which we can reject the statement `the distribution has $k$ or
fewer modes'.
\end{enumerate}

Step one, which reads in data and calls \ci{setvars} to set some
parameters, is self-explanatory. 
The input data is simply
a list of values---no need to produce a histogram or otherwise
pre-aggregate the data, since the kernel density provides a
semi-histogram itself.

Step two begins at the \ci{produce\_k\_to\_h\_table} function. That
function is simply a \ci{for} loop that calls
\ci{find\_smallest\_h\_for\_k} for each value of $k$. The function is
called with data, the number of modes the function is seeking
(\ci{goal\_k}), and a minimum and maximum in which to search for $h$.

The function sets $h$ to the midpoint of \ci{min} and \ci{max}, and
runs the \ci{countmodes} function, discussed below, to find the number
of modes for that value of $h$. There are three possibilities. The first
is that the mode count equals the number of modes sought, and the range
in which we are searching is small enough that we can conclude our
search and return the given value of $h$ as the smallest value that will
produce $k$ modes. 

The other two possibilities are that the mode is definitely smaller than
$h$ (when the mode count given $h$ is too large) and so we should be
searching $[$\ci{min}, \ci{h}$]$, or that it is definitely larger than
$h$, meaning that we should be searching $[$\ci{h}, \ci{max}$]$. In
these cases, the function {\em calls itself} with the modified range.
This is known as \vocab{recursion}. The function takes in an input (in
this case a range), and then either modifies the input (shrinking it)
and tries again, or it returns a value. When one function in the chain
of repeated calls
finally returns a value, it passes it to the parent function, who passes
the value to its parent function, et cetera.\footnote{This type of
recursion is known as tail recursion. Incidentally, it is one of the few
cases where C is not the fastest language around, because the interpreters
of some recursion-oriented languages have built in tail-recursion
optimizations that C compilers typically lack.} Thus, by repeatedly
splitting $[$\ci{min}, \ci{max}$]$, the function eventually converges
upon a smallest value of $h$ that produces $k$ modes (to within the
given tolerance). 

How does the function count modes? This is the crux of the kernel
density estimation process, and the function \ci{countmodes} does this.
It runs two loops, both indexed by \ci{t}; in the animations
produced in step three and the plots in Figure \ref{smoothing}, \ci{t}
is stepping along the $x$-axis.
The first loop finds the value of Equation \ref{bikernel} at
$t$, for each value of $t$ along the $x$-axis. The \ci{fmap} structure
now has a table mapping \ci{t} $\to$ $f(\ci{t}, \Xv, h)$.

The second loop searches for modes, which simply involves looping
through each point and checking whether it is larger than both the
point's predecessor and successor.  The $\ci{t} \to f(\ci{t}, \Xv, h)$
map is then thrown out, and the count of modes returned.

Step three, produce an animation, is of course not necessary for the
calculation of probabilities, but the animation produced here is one of
the most amusing in the book, as the density function slowly
melts from a sharp series of spikes like the first panel of Figure
\ref{smoothing} to a unimodal blob. The plot function itself should be
familiar from the section on animation (Section \ref{animation}): it
simply writes a \ind{Gnuplot} plot header, the mapping, an \ci{e} to mark the
end of data, and a pause. Doing this a hundred times produces the
Gnuplottable animation.

Step four, the bootstrap tests, consist of simply calling
\ci{countmodes} a few thousand times. As above, Silverman showed that
if $n\%$ of bootstrap estimates produce kernel densities for $h(k)$
with more than $k$ modes, then we can reject the hypothesis that the
data has more than $k$ modes with $n\%$ confidence.

Thus, this step produces \ci{boot\_iterations} bootstrap draws of the
data, and counts the modes in each. 

The program will spend the most time bootstrapping. After all, it
will evaluate a Normal distribution \ci{boot\_iterations} $\times$
\ci{data->size} $\times$ \ci{resolution} $\times$ \ci{max\_k} times
(398 million times, by the current calibration).

\lstset{showstringspaces=false, basicstyle=\small, emphstyle=\bf\small, language=C,%
breaklines=true,%
caption={Silverman's kernel density test for bimodality. Online source: \bi{bimodality.c}},captionpos=b,label=bimodality}
\lstinputlisting{sources/bimodality.c}
    \setlistdefaults
