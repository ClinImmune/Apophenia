\chapter{Monte Carlo} \label{boot}

Monte Carlo (Spanish and French for Mount Carl) is a city in Monaco
famous for its casinos, and more glamorous associations with its name
than Las Vegas or Atlantic City.

Monte Carlo methods are thus about randomization: taking existing data
and making random transformations to learn more about it. At the
roulette table, a single player may come out ahead, but the house is
confident that with enough players testing the odds, it will come out
ahead. Similarly, a single random transformation will no doubt produce a
somehow distorted picture of the data, but reapplying it thousands or
millions of times will present an increasingly accurate picture.

Bootstrapping and jackknifing are methods of getting a variance out of
data that, by all rights, should not be able to give you a variance. Say
that you have estimated a parameter, and also want to test whether
that parameter is different from zero. By repeatedly re-estimating the
parameter, you can determine its variance, and thus test a hypothesis
about it.

\section{Random number generation}\index{random
numbers|(}\label{randomnumbers}
Before moving on to the main show, a digression is in order on the
process of generating random numbers. 

Random number generators are not random: given the same setup, they
will produce the same value every time you use them. To lay-intuition,
this is not really `random', but for the programmer, it is wonderful,
because you can replicate your results.

There are two places where you will need replication. The first is with
debugging, since you don't want the segfault you are trying to track
down to magically appear and disappear every other run. The second is
in reporting your results, because when a colleague asks to see how you
arrived at your numbers, you should be able to reproduce them to four
decimal places.

Of course, using the same stream of numbers every time creates the
possibility of getting a lucky draw, where \airq{lucky} can mean any of a
number of things. The solution is a fixed process of pseudorandom
number generation plus a varying initializing seed. Here is how one
would initialize a \cind{gsl\_rng}:
\begin{lstlisting}
gsl_rng * initrng(int seed){
    gsl_rng_env_setup();
    gsl_rng *r  = gsl_rng_alloc(gsl_rng_taus);
    gsl_rng_set(r, seed);  
    return r;
}
\end{lstlisting}
The function takes in an integer, and then sets up the random number
generation (RNG) environment to produce new numbers via the Tausworth
routine. Every integer will produce a different stream of numbers.

There is no need to make the seed look random. The GSL's default seed is
zero, and if you need ten different seeds, I suggest using 0, 1, \dots ,9.

\subsection{Random number distributions}
Now that you have a random number generator, here are some functions that use it to draw from all of your favorite distributions:
\index{Gaussian distribution} \index{t distribution} \index{F distribution}
\index{Uniform distribution}\cindex{gsl\_ran\_...}\cindex{gsl\_rng\_uniform}
\index{Bernoulli distribution} \index{Beta distribution} \index{Binomial distribution} 
\index{chi squared distribution@$\chi^2$ distribution}

\begin{lstlisting}
double gsl_ran_bernoulli (gsl_rng *r, double p);
double gsl_ran_beta (gsl_rng *r, double a, double b);
double gsl_ran_binomial (gsl_rng *r, double p, int n);
double gsl_ran_chisq (gsl_rng *r, double NU);
double gsl_ran_fdist (gsl_rng *r, double NU1, double NU2);
double gsl_ran_gaussian (gsl_rng *r, double SIGMA);
double gsl_ran_tdist (gsl_rng *r, double NU);
double gsl_ran_flat (gsl_rng *r, double A, double B);
double gsl_rng_uniform (gsl_rng *r);
\end{lstlisting}

The 'flat' distribution is a Uniform[A,B] distribution. Since the
Uniform[0,1] distribution is so common, it gets its own no-options
function, \cinline{gsl\_rng\_uniform(r)}. Notice that the Gaussian draw
assumes a mean of zero, so if you intend to draw from a ${\cal N}(7,2)$,
then add the mean after the call: \cinline{gsl\_ran\_gaussian (r, 2) + 7}.

\paragraph{The Beta distribution}\index{Beta distribution}\label{beta}
The Beta distribution is wonderful for all sorts of modeling, because
it can describe such a wide range of probability functions for a
variable $\in [0,1]$.  But its $\alpha$ and $\beta$ parameters may be
difficult to interpret; we are more used to the mean and variance. Thus,
Apophenia provides one convenience function for the Beta distribution,
\cind{apop\_ran\-dom\_beta}. You can give it a mean, a variance, and
a random number, and it will calculate the appropriate values of $\alpha$
and $\beta$ and return a random draw from the appropriate distribution.

Quick---what is the variance of a Uniform$[0,1]$? Answer: ${1\over 12}$,
which means that the Beta distribution will never have a variance greater
than ${1\over 12}$ (and close to ${1\over 12}$, perverse things may
happen computationally for $\mu \not\approx {1\over 2}$). The mean of a
function that has positive density iff $x \in [0,1]$ must be
$\in (0,1)$. If you send \cind{apop\_ran\-dom\_beta} values of $\mu$
and $\sigma^2$ that are outside of these bounds, the function will
return a \cinline{GSL\_NAN}.

\subsection{Drawing from your own data} \index{histograms!drawing from|(}
Another possibility, beyond
drawing from famous distributions that your data theoretically
approximates, would be to draw from your actual data. 

The GSL provides a means of turning a data set into a PDF from which you
can then make draws.  It
does so by aggregating the data into a histogram and then producing a CDF.
Then, the \cind{gsl\_histogram\_pdf\_sample} function will
map a draw from a Uniform[0,1] distribution to the CDF, thus producing a
random draw from your data.

The \cinline{apop\_vector\_to\_pdf} function takes the requisite steps
for you, producing a histogram from the data and then converting it to
a \cind{gsl\_histogram\_pdf} structure from which draws can be
made. It takes two arguments: a \cinline{gsl\_vector} with the data, and
an \cinline{int} listing the number of bins that the histogram should
have. This should be calibrated to the resolution of the data: if the
data is accurate to a thousandth, then it makes sense to have on the
order  of a thousand
bins. Over-accuracy takes up memory, but there is no harm to having
zeros in the vast majority of bins. Usage:
\begin{lstlisting}
    //Setup:
    gsl_vector  *data    = produce_data_set(...);
    gsl_histogram_pdf *p = apop_vector_to_pdf(data, 1000);
    gsl_rng *r = initrng(7); //see initrng() definition above.

    //Draw from the PDF:
    double      draw;
    while (get_more_data){
        draw = gsl_histogram_pdf_sample(p, gsl_rng_uniform(r));
        ...
    }

    //Eventually, clean up:
    gsl_histogram_pdf_free(p);
\end{lstlisting}
\index{histograms!drawing from|)}

\index{random numbers|)}

\section{Finding the variance of a parameter}
The bootstrapping and jackknifing processes consist of taking artificial
samples of your data, and then calculating a statistic for each of these
samples. These draws will be independent and identically distributed.
Typically, your statistic is for the form $\sum (X_i)/ N$, where  $N$
is the number of observations, and $X_i$ is a data point in the case
of a mean, $(X-\mu)^2$ for a variance, et cetera. In other words, the
statistic is often the mean of some iid process, and so the Central
Limit Theorem applies to the series of statistics that you are producing
(regardless of how ugly the underlying data may be).

The primary use of this is for hypothesis testing: we need to know the
variance of the parameter and its distribution if we are to successfully
determine whether the parameter we saw is different from zero. We
solve this problem by producing a sample of the statistics, which we
are assured by the CLT will be Normally distributed, with the variance
we will calculate below. The confidence intevals calculated here will
approach the true confidence interval for the statistic
as the sample size approaches the population size.

\paragraph{An important caveat} Bootstrapping from a sample will not fix
the errors in your sample. If your sampling technique isn't perfect---and
it isn't---then it won't capture the full variation in the data. That
means that the variances you calculate using bootstrap will be less than
the true variance. In a bind you'll just have
to state that and go on. Bootstrapping is a generally accepted technique,
and has reasonable persuasive power.

But having smaller variances makes
it easier to reject the null hypothesis, which is what your paper is
probably trying to do, so bootstrapping works slightly in your favor,
and against parsimony and skepticism. Therefore, if there is any way
of getting information about the variance of your variable without
bootstrapping, even if that estimate overstates the variance, then use
that instead of bootstrapping. \comment{Otherwise, you dishonor your name, and
bring shame to your research group.}


\subsection{Creating random samples} \index{bootstrap}
\index{jackknife|\textbf(}
The primary difference between bootstrapping and jackknifing is that
the bootstrap takes a series of draws with replacement from a data set,
while the jackknife takes a series of samles without replacement. Here,
I will discuss the jackknife.

Assume that we have a
data vector \cinline{gsl\_vector * data} and a function \cinline{double
calc\_statistic(gsl\_vec\-tor *da\-ta)} that finds some statistics. The
function \cinline{mean()} fits this description, as would a function to find
a single OLS coefficient.

\codefig{bootdraw}{A function to draw samples from the data, for use in a jackknife}

Then the first step in jackknifing is drawing some subset of the data,
without replacement. Drawing without replacement means that we need to
keep track of what has been drawn to date, and must check every new draw
to make sure that the new draw is not a repeat. Figure \ref{bootdraw} lists a function which
does all of this. It allocates and sets up a random number generator, then
makes a series of random draws from a uniform distribution in the range
[0, \cinline{data-$>$size}]. It then checks the list of indices which have
already been drawn. If it finds a match, then it invalidates the draw
by rolling back the counter by one, while if it does not find a match then it
adds the draw to the list of draws and the index to the list of indices.

We can then use these draws to calculate a list of parameter values, as in Figure \ref{bootvar}.
\codefig{bootvar}{A function to find the variance of a series of jackknife estimates of a statistic}

It is valid to use the standard deviation returned by this function 
in the normal way to construct confidence intervals and test
hypotheses about the statistic.

Again, Apophenia has you covered with a jackknifing function, whose
use could not be simpler. To produce the covariance matrix for the
parameters of a Poisson distribution for a given data set:
\begin{lstlisting}
apop_data *covar    = apop_jackknife(data, apop_poisson, NULL);
\end{lstlisting}
In fact, this is redundant, because the \cinline{apop\_pois\-son}
model already uses the \cind{apop\_jackknife} function internally,
so the usual \cinline{apop\_pois\-son.est\-i\-mate(data, NULL)}
will return an estimate with jackknifed variances.
\index{jackknife|\textbf)}

