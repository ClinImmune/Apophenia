\section{Why C?}

\index{statistics packages!rants regarding|(}
There are so many other languages out there in which you could do
statistics. Why use C instead of SAS, Stata, SPSS, S-PLUS, SSt, GAUSS, GAMS, GRETL,
MatLab, Minitab, Mupad, Mathematica, Limdep, Octave, R, or RATS? 
There are more than enough books that advocate for the use of such
languages; 
as one editor at a well-known scientific publishing company
explained to me: ``\dots most of the statistics [book] market is quite heavily
influenced by the software companies that service the
field.''  Thus, this is the only book to advocate statistical computing
with a general computing language, so I'm going to spend a few pages
motivating the choice as clearly as possible. Over the course of this, you should
also get a better idea of why C is the way it is, and why things that
seem annoying on the surface will pay off in the long run.
\ifbook
\subsection{Reason \#1: C will help you do better science.}
As noted above, it's no longer OK to use OLS for everything.
OLS, with all its assumptions, used to be the only technique that we had the computing
power to actually implement. But my four-year old laptop regularly executes
feats of computation that were entirely impossible fifty years ago, and your
computer can do the same.  {\it So why are
we still using theorems written to facilitate computation?} More importantly, why
are we using them in cases where their assumptions aren't true?

Unfortunately, the statistics packages are written around the
specialized, assumption-heavy theorems, and because people do what the
technology facilitates, people who use stats packages are very
likely to assume OLS is valid.  If OLS does not quite fit, they hit a
brick wall, and lack a simple way to go further. In the end, too many
will take the path of least resistance and just gloss over OLS's assumptions.

There is nothing more embarassing than a presenter who answers a question
about the assumptions or results of a model with `that's just Stata's
default'---or still worse, (and yes, I have heard this in a real live
presentation by a real live researcher) `I would have corrected this
anomaly in my data, but Stata didn't have a function to do that.' This
is beyond unpersuasive and into the realm of confidence-eroding.

Stats packages are not designed around the general results, though
it is technically possible to retrofit these packages to use them. Since
they are Turing-complete,\footnote{Alan Turing wrote down an imaginary
machine which could execute a dozen types of instruction.  All
modern programming languages implement these instructions in one way or
another, and are therefore equivalent to Turing's theoretical computer;
by transitivity, they are all equivalent to each other. With enough
perseverence, you could
write a C compiler in MatLab.} you could
write anything in them: maybe a word processor or a painting program. But
why? It's just as easy to write the functions in C using the packages I discuss
here, and the resulting program will be more robust and orders of
magnitude faster, as per Reason \#2.
	\else
[Reason \#1 has been omitted from this excerpt.]
	\fi

\subsection{Reason \#2: Stats packages will break your heart.} Stats packages
are wonderful at first, making it easy to sit down and start working
quickly. As you get better with the language, you will 
grow to depend on the stats package for more and more
things. And then, one day, you will get to a problem that is too far
out from what the language designers had in mind, or a problem that is
too large-scale for the language to handle. Your favorite language just
won't be able to do it, even after you spend hours trying to get around
the language's assumptions about what you mean and endless attempts to
optimize the code so it'll run a little bit faster. And after all that,
you'll have nothing but a broken heart.

A full discussion of programming languages is beyond the scope of this book, but
here are a few hints as to how statistics packages can become cumbersome with
time. 

The first is that some languages do not allow you to declare types. This
looks like a convenience at first---you will see that there are a
lot of declarations involved in a typical program, and it can be a
distraction. But the declarations allow the program to run significantly
faster. Some languages get around the type declaration question by simply
declaring everything to be the largest possible type (basically making
everyting a {\tt long double} array).  For very complex data types,
such as lists of lists, it is often difficult (and for exceptionally
perverse cases, impossible) to get the computer to correctly guess what the
type of a variable should be.

The second is that most languages do not have a call-by-reference
mechanism, which will be defined and discussed extensively in Section
\ref{pointers}. As you read \ifbook Chapter \ref{c_crash}\else this overview\fi, imagine that it ends
at Section \ref{prepointers} and you will have an idea of what most
stats packages are like.

Third, some stats packages have only two types of scope: local to
a function, and global. You will see that having many options for
intermediate levels of scope is a central theme to \ifbook Chapter \ref{c_crash}\else this overview\fi,
and this is because good control over a variable's scope is essential
to your sanity when writing programs with more than a few pages of
code. Again, this is something that you will not notice is missing until
you invest heavily in a language and begin writing lengthier analyses.

Finally, all stats packages are slower than C---often hundreds of times
slower. This won't be noticeable for a linear regression on a few thousand
observations, but for very large data sets, or for the maximum likelihood
methods discussed later in this book, this can mean literally days of
waiting instead of several minutes.  Why are stats packages all slower
than C? Because they are all written in C to begin with, so after they
do their preprocessing to determine variable types and translate their
structures into other structures, they just call a C function.

As you read \ifbook Chapter \ref{c_crash}\else this overview\fi, these
problems are worth bearing in mind. C may seem to have some ugly
features, but they will eventually save you heartbreak.
\index{statistics packages!rants regarding|)}

\subsection{Reason \#3: C is universal} 
The software I discuss in this book is available from {\tt www.gnu.org}, for the
system you are using, and for the system you will be using five years from now, for
free. There is no other language I could say that about with such confidence.

This is not only important because you may find yourself in front of
a different type of computer next year, but because we increasingly
expect that the data and analysis behind a work be publically available.
For example, it is a requirement for funding from the U.S. National
Science Foundation. But if your analysis uses a stats package which
isn't universally available, then you will break the hearts of all of
your fellow researchers who want to work with your analysis but for whom
it is logistically impossible to do so. Are you sure your colleague in
Madras can afford a SAS license?

C is also universal in the time domain. Code written in C thirty years
ago still runs today, and every operating system in existence today has a C
compiler available. Will people still be using STATA or R ten years from now?
That depends on the financial solvency of the STATA Corp and the
R Foundation and whatever turns out to be trendy five years from now.
Since C was written in 1972, dozens (maybe hundreds) of stats packages
have come and gone. Those who try to follow the trends for
some period of time have learned a half-dozen languages
and have on their hard drives dozens of scripts that won't run anymore.


\ifbook
\subsection{Reason \#4: C is on all levels at once} 
Connoisseurs of computing languages often refer to high-level and low-level languages. The low-level
languages are close to the machine, referring to individual memory
addresses and register operations, giving you perfect control but demand a lot
of work. The high-level languages do
complex things with one command, like {\tt regress(data)} to produce
pages of output, giving you no control but ease-of-use.

On this hierarchy, C is typically billed as a low-level language, but this is only
partly true. C can indeed be used as a rock-bottom low-level language,
with its bit-shifting operators and pointers to memory addresses, and
even though you will never use the bit-shifting, the pointers are an
integral feature. But on the other hand, there is a library of functions
to do whatever high-level operations you may have in mind, such as the
{\tt apop\_OLS.estimate(data)} function from the Apophenia library.

You get to pick the balance of laziness and precision that you desire. You
can write code to manipulate individual addresses, use the GNU Scientific
Library to manipulate matrices, or use Apophenia to estimate models---and
you can do it all in the same program.

The how-to code in this book is often repeated at multiple levels. I will first
show you the low-level way of doing things over the course of three
pages, and then tell you the single function call that will do all the work
for you. This is partly because of a didactic philosophy that you should
know what your black boxes are doing before you use them, and partly
to prepare you for when the black box doesn't do what you need. Because all of the
functions described here are open source, you can copy and paste the
functions into your own program and modify them to suit your needs
and data better; of course, this relies on your being able to understand
the code at lower levels than the function you are tearing apart.
\fi
