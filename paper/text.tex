\setcounter{chapter}{2}
\setcounter{section}{0}
\setcounter{subsection}{0}
\setcounter{ex}{0}
\chapter{Appendix \thechapter: Text processing} \label{textappendix}

If you are lucky, then your data is in exactly the format it needs to be
in to be read by your stats package, Apophenia, Graphviz, \&c.

By definition, you are probably not going to be lucky. This appendix will
explain how one modifies a text file to conform to an input standard. 

You will notice that the book so far has included a great deal on writing
text files via \ci{printf} and family, but not much on the process of
modifying existing files. That is because modifying files in place in
C is, simply put, frustrating. Something as simple as replacing \ci{10}
with \ci{100} requires rewriting the entire file from that point on.

Thus, this appendix will look at some means of modifying text via the
command line. Its goal, narrowly defined by the rest of the text, is to
show you how to convert a data file either into the input format required
by a stats package or into a command file in the language of Gnuplot,
a Graphviz-family tool, or SQL.

As with the rest of the analysis, you should be able to do this in a
fully automated manner. This is because you will no doubt receive a
revised data set next week with either corrections or more data, because
you may decide to split your data into a hundred subsets so manual
tweaking is no longer feasible, and because writing down a script
produces an audit trail that you or your colleagues can use to check
your work.

The primary technique covered in this appendix is the parsing of
\vocab{regular expressions}, wherein you specify a certain regularity,
such as `numbers followed by letters', and a program searches for that
regular expression in text and modifies it as per your instructions.

A secondary theme is the POSIX water metaphor. Data flows in a stream from
one location to another, burbling out of data files and piping through
filters like \bi{sed} (the stream editor).  Eventually, the stream of
data reaches its final destination: a graphic, a database, or another
file holding clean, filtered data.

Along the way, you will see how to effectively search your files. As
your projects get large, you will desire tools that find every use of
\ci{buggy\_variable} in your program or every reference to an author in
your documents. Regular expression tools will help you with this.

After some discussion of how one assembles a shell script from small
parts, this appendix will cover simple searching, as an introduction to
regular expressions, and then move on to the main program: writing
scripts to reformat text files into a format appropriate for your
data-handling systems.

\section{Shell scripts} As with Gnuplot or SQLite's command-line
utility, you can operate the \vocab{shell} (what many just call the command line)
by typing in commands or by writing a script and having the shell read
the script. Thus, you can try the commands below on the command line,
and when they work as desired, cut and paste them into a script as a permanent
record. 

Typically, your script will not just stop with reformatting text files:
your script will begin with some of the Perl or sed commands below to
reformat the data file, then call your C program to process the file, and
finally call Gnuplot to display a graph. 

In POSIX systems, you need to make a script executable before it can be
run on the command line.\footnote{This is not 100\% true: you can use
the shell's \cind{source} command to read in a text file of commands:
\bi{source myscript}. But if you are going to run the script more than a
few times, you may as well make it executable.} This is not the place
for a full POSIX tutorial, but \bi{chmod 755 myscript} or \bi{chmod +x
myscript} will do the trick. Having made the script executable, you
can call a script in the current directory (aka \bi{./}) from the shell
using \bi{./myscript}.

\subsection{Redirection} 
Each program has a standard input stream
and a standard output stream, named \bind{STDIN} and
\bind{STDOUT}.\footnote{There is also a third, \bind{STDERR}, to which
errors are written. To redirect \bi{STDERR}, use the form \bi{\&>}. For
example, try \bi{sed -p \&> err}, then open \bi{err} in your text editor
(or try the command \bi{cat err}).}

By default \bi{STDIN} and \bi{STDOUT} are the keyboard and screen. 
For example, \bind{sed} reads from \bi{STDIN} and writes to \bi{STDOUT},
so the command
\begin{lstlisting}
sed -n p
\end{lstlisting}
simply \ci{p}rints to the screen whatever is typed in. If you
try it, you will see that this means simply that \ci{sed} repeats
whatever you type.
\begin{lstlisting}
prompt> sed -n p
Hello.
Hello.
How are you?
How are you?
Stop imitating me.
Stop imitating me.
<ctrl>-D
\end{lstlisting}
Now for the redirection. A clause of the form \cind{> filename} tells the
system to write whatever it would have put on the screen to a file. Thus,
if you put the command \bi{sed -n p > outfile} on the command line, then
nothing will print to the screen, but whatever you type (until you hit
\bi{<ctrl>-D}) will be written to \bi{outfile}. That is, instead of
writing to \bi{STDOUT}, the system writes to \bi{outfile} (and you can
check this via \bi{cat outfile}).

As a variant, \bind{>>} \bi{outfile} will append to a file, rather than
overwriting it, as \bi{> outfile} would.

A \bind{<} tells the system that it should take input not from \bi{STDIN}
but from an input file. Thus, \bi{sed -n p < input\_file} will dump the
contents of \bi{input\_file} to the screen. 

\exercise{Use \bi{sed -n p} and input/output redirection to copy a file.}

Your final redirection option is the \vocab{pipe}. The pipe connects \bi{STDOUT}
for one program to \bi{STDIN} for another. 

Question: what exponents of four end in a six?  On page \pageref{getopt}
(and in the code supplement), you will find a program, \bi{getopt}, that prints
exponents to \ci{STDOUT}. Below, you will see that \ci{grep} will search
its input for a certain pattern; for example, \ci{grep "6\$" <infile} will
search \ci{infile} for lines ending in a six. Thus, we could redirect the
output for \ci{getopt} to a file, then input that file to \ci{grep}.
\begin{lstlisting}
./getopt 4 > powers_of_four
grep "6$" < powers_of_four
\end{lstlisting}
The pipe, \ci{|}, streamlines this by directly linking \ci{STDOUT} from
the first program and \ci{STDIN} to the second.
\begin{lstlisting}
./getopt 4 | grep "6$" 
\end{lstlisting}
This line prints the filtered output of \bi{getopt} to the screen, at
which point the pattern in the exponents is eminently clear.

The next section will cover a few tools that one can join together to
filter streams of text.

\paragraph{Streams flowing through C}

As you saw on pages \pageref{fprintf}{\it ff}, you can use \ci{fprintf}
to send data to a file or another program. You may have noticed the
close similarity between opening/writing to a file and opening/writing
to a pipe:  \cindex{pclose}\cindex{popen}\cindex{fprintf}
\begin{lstlisting}
FILE *f = fopen("write_to_me", "w");
FILE *g = popen("/usr/local/bin/gnuplot", "w");
fprintf(f, "The waves roll in,\n");
fprintf(g, "The waves roll out.\n");
fclose(f);
pclose(g);
\end{lstlisting}
If this code were in a program named \bi{water}, then the \ci{fopen}
and \ci{fprintf} instructions are analogous to 
\bi{water > write\_to\_me}. The \ci{popen} and \ci{fprintf} pair are
analogous to \bi{water | /usr/local/bin/gnuplot}.

This book has spent little time on the subject of reading data from
\bi{STDIN} (look up \ci{fscanf} in your favorite C reference), but by
changing the \ci{"w"}s to \ci{"r"}s in the above code, the code becomes
analagous to
\bi{water < write\_to\_me} and \bi{/usr/local/bin/gnuplot | water}.
[Assume that \bi{text\_script} is a Gnuplot script that instructs
Gnuplot to produce text.]
\begin{lstlisting}
FILE *f = fopen("read_from_me", "r");
FILE *g = popen("/usr/local/bin/gnuplot text_script", "r");
char input1[10000], input2[10000];
fscanf(f, input1);
fscanf(g, input2);
fclose(f);
pclose(g);
\end{lstlisting}

\exercise{Modify \bi{getopt.c} to filter its output through \bi{grep}.
\begin{itemize}
\item Popen \bi{grep} for writing.
\item Modify the \ci{printf} statement to an \ci{fprintf} statement.
\end{itemize}}

Finally, there is the \cind{system} function, which just runs its
argument as if it were printed on the command line.

[A clever example of \ci{system} will appear here.]

There are two difference between a \ci{system} command and a \ci{popen} command.
First, there is the fact that \ci{system}'s input and output are always
the keyboard and screen, while \ci{popen} allows I/O from within the program.
But also, \ci{system} will stop your program and wait for it to finish,
while \ci{popen} will open the pipe and then move on to the next step in
your program. So if the command has to finish before you can continue,
use \ci{system}, and if the command is something that should run in the
background, use \ci{popen}.

\summary{\item All programs have standard inputs and outputs, which are
by default the keyboard and screen.
\item Both \bi{STDIN} and \bi{STDOUT} can be redirected. \bi{STDIN} can
read from a file using the \bi{< infile} form; \bi{STDOUT} can write to
a file using the \bi{> outfile} form.
\item Programs can send their output to other programs using the pipe,
\bi{|}.
\item You can do redirection from inside C, using \ci{fopen} to effect
the command-line's \bi{< infile} and \bi{> outfile}, and \ci{popen} to
open a pipe.
}

\section{Some tools for scripting}
Depending on your system, you can type somewhere between a few hundred
and a few thousand commands at the command prompt. This section points
out a handful that are especially useful for the purposes of dealing
with data in text format.\footnote{I continue to assume that you know
how to manipulate files and directories themselves, via \bi{cp},
\bi{rm}, \bi{cd}, \bi{mkdir}, \bi{rmdir}, and family. If not, there are
an abundance of basic UNIX and POSIX tutorials online for reference.}
All of them have a multitude of switches, which you can see via \bi{man
head},  \bi{man sort}, et cetera. They are all POSIX-standard, so you
can expect that scripts based on them will be portable.

Most of these commands are in some ways redundant with methods
elsewhere in the book: you could use \bi{cut} below to pull one column
of data, or you could read the data into a database and \si{select}
the column; you could use \bi{wc} below to count data points, or use
\si{select count(*)} to do the same.\footnote{\index{join!command-line program}
There is even a \bi{join}
command, which will do database-style joins of two files. However, it is
hard to use for any but clean numeric codes. Try using \bi{join} to
merge \bi{data-wb-pop} and \bi{data-wb-gdp}.} Generally, 
command-line work is good for pure text manipulation and quick questions (Do I have the thousands 
of data points I was expecting?), while you will need to write a program 
for any sort of numeric analysis or to answer more detailed questions
about the data (How many rows are
duplicates?).\footnote{\ci{apop\_query\_to\_double("select count(*) from data") - 
apop\_query\_to\_double("select count(*) from (select distinct * from data)")}}

\subsection{\bind{cat}} The simplest thing one could do with a text file is 
to print it, and this is what \bi{cat} does. Thus, instead of opening a
file in your text editor, you can simply type \bi{cat file\_to\_read} on
the command prompt for a quick look.

The other use of \bi{cat}, for which it was named, is concatenation.
Given two files \bi{a} and \bi{b}, \bi{cat a b} lists \bi{a} and,
immediately thereafter, \bi{b}. This becomes especially useful with
redirection, as below.

\subsection{\bind{head}/\bind{tail}} \bi{head myfile} will print the
first ten lines of
\bi{myfile}, and \bi{tail myfile} will print the last ten. These are
good for getting a quick idea of what is in a large file.  Also,
\bi{tail -f myfile} will follow \bi{myfile}, first showing the
last ten lines, and updating as new lines are added. This can provide
reassurance that a slow-running program is still working.

\exercise{How would you get \bi{sed} to emulate the default behavior of
\bi{head}? }

\comment{
\exercise{Write a \bi{sed} script to emulate the default behavior of
\bi{head} and \bi{tail}. Use your favorite scripting language (Perl,
Python, \bi{bash}), or use C's \ci{popen} command.}
}

\subsection{\bind{sort}} This is as self-descriptive as a command can
get. For example, the \bi{data-wb-pop} file (in the code supplement)
is sorted by population; \bi{sort data-wb-pop} would output the file in
alphabetical order.

\exercise{Sorting \bi{data-wb-pop} like this sorts the two header lines
in with all the countries. Write a command that first calls \bi{sed} to
delete the headers, then pipes the output to \bi{sort}.}

\subsection{\cind{cut}/\cind{paste}} Almost all of the commands here
operate on rows; \bi{cut} and \bi{paste} operate on columns. Specify the
delimiter with the \bi {-d} flag, and then the field(s) with the \bi{-f}
flag (where the first column is column one, not zero). To get a list of
just countries from the World Bank data, try \bi{cut -d"|" -f 1
data-wb-pop}; to see just the population numbers, use \bi{cut -d"|" -f
2 data-wb-pop}.

\bi{paste} puts its second input to the right of its first input---it is
a vertical version of \bi{cat}.

\exercise{Use the command string from the last exercise to sort the
population and GDP data into two new files. \bi{cut} the second file
down to include only the column of numbers. Then use \bi{paste
sorted\_pop sorted\_gdp> combined\_data} to produce one file with both
types of data. Verify that the data is aligned correctly (i.e.,
that the Albania column does not list the GDP of Algeria.)}

\subsection{\cind{wc}} \index{counting words}\index{word count}
This program (short for word count) will count words, lines, and
characters. The default is to print all three, but \bi{wc -w}, \bi{wc -l},
and \bi{wc -c} will give just one of the three counts.

When writing a text document, you could use it for a word count as
usual: \bi{wc -w report.tex}. If you have a data file, the number of
data points is probably \bi{wc -l data} (if there is header data, you
will need to subtract those lines).

This program is especially useful in tandem with \bi{grep}. How many lines
of the \bi{data-wb-pop} file have missing data (which the WB indicates by
\bi{..})? \bi{grep "\textbs{}.\textbs{}." data-wb-pop} will output those lines
where the string \bi{..} appears; \bi{wc -l} will count the lines of the
input; piping them together, \bi{grep "\textbs{}.\textbs{}." data-wb-pop
| wc -l} will count lines with \bi{..}s.

\subsection{\cind{nl}} This command puts \ind{line numbers} at the
beginning of every line, which is sometimes useful. Remember that SQLite
puts a \sind{rowid} on every row of a table, that is invisible but
appears if explicitly \si{select}ed. But if you want to quickly put a counter
column in your data set, this is the way to do it.

%\subsection{\cind{uniq}}

\subsection{\bind{column}} Text data 
will either be easy to read for a computer or a human, but rarely both.
Say that a data file is tab-delimited, so each field has exactly one tab
between columns:
\begin{lstlisting}
Name<tab>Age
Rumplestiltskin<tab>78
Dopey<tab>35
\end{lstlisting}

This will read into a spreadsheet perfectly, but when displayed on the
screen, the output will be messy, since Rumplestiltskin's tab will not
be aligned with Dopey's. The \bi{column} command addresses exactly this problem,
by splitting columns and inserting spaces for on-screen human
consumption. For example, \bi{column -s"|" -t data-wb-pop} will format
the \ci{data-wb-pop} file into columns, splitting at the \bi{|}
delimiters. The first column will include the header lines, but you
already know how to get \bi{sed} to pipe headerless data into
\bi{column}.

\subsection{\bind{diff}} The \bi{diff} program prints the difference
between two files. This can quickly be overwhelming for files that are
significantly different, but after a long day of modifying files, you
may have a few versions of a file that are only marginally different. 
By the end of this chapter, that will be the case, so various
opportunities to use \bi{diff} will appear below.

%http://www.watsys.unh.edu/Darlene/TechToolsFiles/LammersUNIXDemo/UNIX_Intro.html
%http://www.die.net/doc/linux/abs-guide/textproc.html


\section{Regular expressions}
The remainder of this appendix will cover programs to parse regular
expressions.  Regular expressions are
their own language that provides a compact means of summarizing a text
pattern.  Many programs support regexes, including standard viewers
like \ttind{less}, a fair number of online search tools, and text editors
like \ind{vi} and \ind{EMACS}, so knowledge of regexes comes in handy
in a wide variety of situations. Entire books have been written on this
one simple subject, the most comprehensive being \citet{friedl:regex}.

\paragraph{\treesymbol Standard syntax, lack thereof} 
Unfortunately, there are many variants on the regex syntax,
since so many programs process them, and the author of each program felt
the need to make some sort of tweak to the standard.  Broadly, the basic
regular expression syntax derives from \bind{ed}, a text editor from back
when the only output available to computers was the line printer. Most
POSIX utilities, such as \bind{sed}, \bind{grep} or \bind{awk},
use this basic regex syntax. There is a modestly modified variant known
as \airq{extended regular expressions}. The scripting language Perl
introduced a somewhat expanded syntax for regular expressions with
significantly more extensions and modifications, and most post-Perl
programs adopted Perl-compatible regular expressions.

Different programs, and even different brands of the same
program, like GNU grep versus Solaris grep, have frustrating
differences: one may support the \ci{?} symbol and one may not; 
one takes \ci{+} as a plus sign and  \ci{\textbs+} as a special
character, while the other reads \ci{+} as special and \ci{\textbs+}
as a plain plus sign. This chapter covers Perl and GNU grep and sed as they exist as
of this writing, and you are encouraged to check the manual pages or
online references for the subtle shifts in backslashes among other
regular expression systems.

This chapter will use grep, sed, and Perl because it is trivial to
use them for regular expression parsing and substitution from the
command line. Other systems, such as C or \ind{Python}, require a regex
compilation step before usage, which is nothing but an extra step in a
script or program, but makes one-line commands difficult.

\subsection{The basic search}\label{grep}
The simplest search is for a literal string of text. Let us say that we
have a C program, and we are searching for every use of a variable,
\ci{var}. You can use the command-line program \ci{grep} (general
regular expression parser) to search for \ci{var} among your files. The
syntax is simple: \bi{grep var *.c} will search all files in the current
directory ending in \bi{.c} for the string \ci{var}, and print the result
on the command line.

\exercise{Let us say you would like some examples of how to use
\ci{printf}. Use \bi{grep} to search all of your .c files for uses
of \ci{printf}. 

The \ci{-C n} option (as in \ci{grep -C n}) outputs $n$ context lines
before and after the match; repeat your search with two context lines
before and after each \ci{printf}.  }


\index{regular expressions!bracket expressions}
\index{bracket expressions!in regexes}
\paragraph{Bracket expressions} Now we start to add special characters
from the regex language. The expression \ci{[fs]} will match either
\ci{f} or \ci{s}. Thus, the expression \ci{[fs]printf} will match both
\ci{fprintf} or \ci{sprintf} (but not \ci{printf}). Thus, \ci{grep
[fs]printf *.c} will find all such uses in your C files. More bits of
bracket expression syntax:

\begin{itemize}
\item You can use ranges: \ci{[A-Z]} searches for all capital letters,
\ci{[A-Za-z]} searches for all lowercase letters, and \ci{[0-9]} matches
any number. 
\item \index{\that!in regex brackets (negation)} Everything after a \ci{\that} is excluded. Thus, \ci{[\that{}fs]} matches
any single character except \ci{f} or \ci{s}, and
\ci{[a-z\that{}fs]} matches any lowercase letter
but \ci{f} or \ci{s}.
\item There are a few common sets of characters that are named. For
example, \bi{[[:digit:]]} will search for all numbers, \bi{[0-9]}. See
Figure \ref{regexchar} for a partial list. 
\end{itemize}

All of these can be combined into one expression. For example,
\bi{[eE[:digit:]\that{}13579]} will match any even digit or the letter \bi{e}.

\begin{figure}
\begin{center}
\fbox{
\begin{tabular}{rl}
\bi{[:digit:]}&   Numeric characters.\\
\bi{[:alpha:]}&   Alphabetic characters.\\
\bi{[:upper:]}&   Uppercase alphabetic characters.\\
\bi{[:lower:]}&   Lowercase alphabetic characters.\\
\bi{[:alnum:]}&    Alphanumeric characters.\\
\bi{[:blank:]}&   Space and tab characters.\\
\bi{[:space:]}&   Any whitespace, including space, tab (\bi{\textbs{}t}), newline (\bi{\textbs{}n}).\\
\bi{[:punct:]}&   Punctuation characters\\
\bi{[:print:]}&   Printable characters, including whitespace.\\
\bi{[:graph:]}&   Printable characters, excluding whitespace.\\
\end{tabular}
}
\end{center}
\caption{Some useful regular expression character sets.}\label{regexchar}
\end{figure}

Brackets can be a bit disorienting because there is nothing in the syntax
to indicate when a group ends or begins, and no matter how many groups are
included, the result still represents exactly one character in the text.
Also, the syntax inside brackets has nothing to do with the syntax
outside brackets, which can also be confusing. A \that{} inside brackets
means negation, while below you will see that a \that{} outside brackets
means the beginning of the line. [By the way,\index{\that!searching for} in the odd event that you are searching for the \that{} character, 
put it last in the bracket: e.g., \bi{grep "[\$*\that]" myfile}.]

\index{regular expressions!case sensitivity}
Regular expressions are vehemently case-sensitive. \bi{grep perl
search\_me} will not turn up any instances of \bi{Perl}. The first
option is to use the \bi{-i} command-line switch to search without case:
\bi{grep -i perl search\_me}. The second option, occasionally useful
for for more control, is to use a bracket: \bi{grep [Pp]erl search\_me}.

\paragraph{Alternatives} 
Recall that Apophenia includes various printing functions, such as
\ci{apop\_data\_print} and \ci{apop\_matrix\_print}. Let us say that you
would like to see all such examples. Alternatives of the form \airq{A or
B} are written in basic regex notation as \ci{(A|B)}. Notice how this
form analogizes nicely with C's \ci{(A||B)} form.

However, there are several complications. First, in the
\ci{grep} regex syntax (but not in Perl's), the actual form is not
not \ci{(A|B)} but \ci{\textbs(A\textbs|B\textbs)}---the
parens and pipe all need a backslash before them. For any given
implementation of regular expressions, some subset of \ci{+ ? | ( ) \{}
and \ci{\}} will be special characters; in others, the special characters are
\ci{\textbs+ \textbs? \textbs| \textbs( \textbs) \textbs\{} and \ci{\textbs\}}.
That is, if you were hoping a character would do something special and it
doesn't,  or if you type a character hoping
it would just be a literal \ci{+} or \ci{|} and you get an odd error,
the solution to both problems is probably to prepend the character with a backslash.

If you type \ci{$\backslash$|} on the command line, then it will send a
simple \ci{|} to grep. To send a literal backslash to grep, you will
need to double it. Further, all of this will confuse your shell unless
you put it in quotes. Having taken all these considerations into
account, you can now search for alternatives. This command will search
for both \ci{apop\_data\_print} and \ci{apop\_matrix\_print}:
\begin{lstlisting}
grep "apop_\\(data\\|matrix\\)_print" *.c
\end{lstlisting}

\paragraph{A few special symbols}
You sometimes won't care at all about a certain segment. A 
dot matches any character, and you will see below that a star 
repeats the prior atom. Therefore
\begin{lstlisting}
grep "apop_.*_print" *.c
\end{lstlisting}
will find any line that has \ci{apop\_}, followed by anything,
eventually followed by \ci{\_print}. Notice that, once again, the
symbols \ci{.} and \ci{*} mean different things in different contexts.
In a regex, the dot represents any character, and the star represents
repetition; on the command line (where wildcard matching is referred to
as \vocab{globbing}), the dot is just a dot, and the star represents any
character.

\index{\that!out of regex brackets (head of line)}
Finally, the caret and dollar sign indicate the beginning and end of the
line, respectively.  \ci{grep "\that{}int" *.c} will only match
lines where \ci{int} is right at the beginning of the line, and 
\ci{grep "\{\$" *.c} will only match open-braces at the very end of the
line. 

\index{regular expressions!white space}
A single space or tab are both characters, meaning that a dot will
match them. The atom \bi{\textbs{}W} will match any single space or tab,
and the atom \bi{\textbs{}w} will match anything that is not white space.
Since there are frequently an unknown bunch of tabs and spaces at the
head of code files, the correct way to search for all \ci{int}
declarations is therefore
\begin{lstlisting}
grep "^\W*int" *.c
\end{lstlisting}

\summary{
\item The quickest way to search on the command line is via grep. The
syntax is \bi{grep "regular expression" files\_to\_search}.
\item Without special characters, grep simply searches for every line
that matches the given text. To find every instance of \bi{fixme} in a
file: \bi{grep "fixme" filename}.
\item  A bracketed set indicates a single character.
    \begin{itemize}
        \item The set can include single characters: \bi{[Pp]erl} matches
both \bi{Perl} and \bi{perl} (though you maybe want a case-insensitive
search with \bi{grep -i}).
    \end{itemize}
%}
%\summarynoitems{(continued)
%\begin{itemize}
        \item The set can include ranges: \bi{[A-Za-z]} will match any
standard English letter.
        \item The set can exclude elements: \bi{[A-Z\that{}P-S]} will
find any capital letter except P, Q, R, and S.
\item Alternatives are expressed in the form \bi{(A|B)}.
\item Different systems have different rules about what is a special
character. The Perl form for alternation is \bi{(A|B)}, as above; the
grep form is \bi{\textbs(A\textbs|B\textbs)}.
\item A single dot (\bi{.}) represents any character including a single
space or tab, and grep understands \bi{\textbs{}W} to mean any white space
character and \bi{\textbs{}w} to mean any non-white space character.
%\end{itemize}
}

\subsection{Replacing}

Grep is wonderful for searching, but is a purely read-only program. If
you want to change what you find, you will need to use a more complex
program, such as Perl or \ttind{sed} (the stream editor). Sed it is
somewhat more versatile when used on the command line, but Perl
adds many very useful features to the traditional regular expression
parsing syntax. If you find yourself using regexes frequently, you may
want to get to know how they are handled in a full Perl-compatible regex
scripting system like Python or Perl.

\paragraph{Perl and sed syntax} 
Sed is certainly installed on your system, since it is part of the
POSIX standard; Perl is almost certainly installed, since many modern
system utilities use it. If it is not installed, you can install it via
your package manager.

Both programs generally expect that you will use a command file, but you
can also give a command directly on the command line via the \bi{-e}
command.

For example,
\begin{lstlisting}
perl -e "print \"Hello, world.\n\""
\end{lstlisting}
will run the Perl command \bi{print "Hello, world.\textbs{}n"}. Notice
that we had to use \bi{\textbs"} instead of a plain \bi{"} on the
command line to prevent the string from ending prematurely.

\bi{sed} always operates on an input file, so we might as well start by 
emulating grep:\footnote{As you saw in the \bi{sed} examples in the
section on redirection, the \ci{-e} flag is optional using this form,
but it never hurts.}
\label{sedintro}
\begin{lstlisting}
sed -n -e "/regex/p" < file_to_search
\end{lstlisting}
There are many things to note here. Sed likes its regexes between
slashes, and the \ci{p} is short for \airq{print}, so the command
\ci{/regex/p} means `print every line that matches \ci{regex}.'
Sed's default is to print every single input line, and then the print
command will repeat lines that match \ci{regex}, which leads for massive
redundancy. The \ci{-n} command sets sed to no-print mode, so only
matches print.

The basic syntax for a search and replace is \ci{s/replace me/with me/g}.
The slashes distinguish the command (\ci{s}), the text to search
(\ci{replace me}), the text for replacement (\ci{with me}), and the
modifiers (the \ci{g}; see box).

If you have only one file to scan, you can use these programs as
filters:
\begin{lstlisting}
perl -p -e "s/replace me/with me/g" <file_to_modify >modified_file
sed -e "s/replace me/with me/g" <file_to_modify >modified_file
\end{lstlisting}

\marginalia{6}{Why the \ci{/g}?}{Back when
regexes were used for real-time editing of files, it made sense to
fix only one instance of an expression on a line. Thus, the default was
to modify only the first instance, and one could specify replacing only
the second instance of a match with \ci{s/.../.../2}, the third instance
with \ci{s/.../.../3}, and all instances with \ci{s/.../.../g}. This is
still valid syntax that is occasionally useful, but when filtering a
data file, you will almost always want the \ci{/g} option.}

The \ci{-p} switch is the opposite of sed's \ci{-n} switch.
As opposed to sed, Perl's default is to never print
unless the pattern matches, which means that if you do not give it the
\ci{-p} switch, it will not pass over any line that does not match the regex.
With \ci{-p}, non-matching lines appear as-is and lines that do match
have the appropriate substitutions made, as we want. 
In this case, Sed is doing the right thing by default, and if you specify
the \ci{-n} switch, you will likely erase
most of your file. 


Another alternative is to replace-in-place, using the \ci{-i}
switch:\footnote{The \ci{-i} switch is not standard in \ci{sed}, but
works on GNU \ci{sed}, which you probably have. Bear this in mind if you
are concerned about a script's portability.}
\begin{lstlisting}
perl -p -i.bak -e "s/replace me/with me/g" files_to_modify
sed -i.bak -e "s/replace me/with me/g" files_to_modify
\end{lstlisting}
With the \bi{-i} option, Perl and sed do not write
the substitutions to the screen or the \bi{>} file, but
make them directly on the original file.
The \ci{.bak} extension tells Perl
and \bi{sed} to make a backup before modification that will have a \ci{.bak} extension.
You may use any extension that seems nice: \ci{-i\~{}} will produce
a backup of a file named \ci{test} that would be named \ci{test\~{}}.
If you specify no suffix at all (\ci{-i}), then no backup copy will be
made before the edits are done. It is up to you to decide when (if ever)
you are sufficiently confident to not make backups.\footnote{If editing a file in
place with C is so difficult, how does \bi{sed}, a C program, do it? By
writing a new file and then switching them when it is finished. So if you
are filtering a 1GB file `in place' with no backup and you do not have
1GB of free space on your hard drive, you will get a disk full error.}

Whether you use the in-place form or the filter form depends on whether
you want to keep the original file intact and write a new file (as this
form does) or you want to modify the original file while perhaps making
an unchanged backup (as the \ci{-i} form does).

\exercise{Create a file named \bi{about\_me} with one line, reading \ci{I am a
teapot.} Use either perl or sed to transform
from a teapot to something else, such as a kettle or a toaster. 
Verify your change using \bi{diff}.}

You are welcome to include multiple commands on the line, by the way.
In Perl, separate them with a semicolon, as in C. In sed or Perl, you
may simply specify additional \ci{-e} commands, that will be executed in
order---or you can just use a pipe.
\begin{lstlisting}
perl -pi.bak -e "s/replace me/with me/g; s/then replace this/with this/g" files_to_modify
perl -pi.bak -e "s/replace me/with me/g" -e"s/then replace this/with this/g" files_to_modify
sed -i.bak -e "s/replace me/with me/g" -e"s/then replace this/with this/g" files_to_modify

perl -p -e "s/replace me/with me/g" < modify_me | perl -p -e"s/then replace this/with this/g" >modified_version
sed "s/replace me/with me/g" <modify_me | sed "s/then replace this/with this/g"  >modified_version
\end{lstlisting}

\paragraph{Replacing with modifications} Parentheses, used above to
delimit conditional segments, can also be used to store sections for
later use. For example, say that your file reads \ci{There are 4 monkeys
at play}, but your copyeditor feels that the sentence as written is
imprecise. You forgot the number of monkeys, so you are tempted to use
the substitution \ci{s/[0-9] monkeys/Callimico goeldii/g}---but this will
lose the number of monkeys.

However, you can put a segment of the search term in parentheses, and
then use \ci{\textbs{}1} in sed or \ci{\$1} in Perl to refer to it in the replacement. Thus, the
correct command lines for replacing an unknown number of monkeys are:
\begin{lstlisting}
sed -i~ -e "s/\\([0-9]\\) monkeys/\\1 Callimico goeldii/g" monkey_file
perl -p -i~ -e "s/([0-9]) monkeys/\$1 Callimico goeldii/g" monkey_file
\end{lstlisting}
The \ci{\textbs{}1} or \ci{\$1} will be replaced by whatever was found in the
\ci{([0-9])} portion of the search.

If there are multiple substitutions to be made, you will need higher
numbers. Say that we would like to formalize the sentence \ci{the 7 monkeys are fighting the 4 lab
owners}. We could do this via:
\begin{lstlisting}
sed -i~ -e "s/\\([0-9]\\) monkeys are fighting the \\([0-9]\\) lab owners/\\1 Callimico goeldii are fighting the \\2 Homo sapiens/g" monkey_file
\end{lstlisting}

\subsection{Selecting in detail}
Let us say that values under ten in the data are suspect, and should be
replaced with \ci{"NaN"}. The search \ci{s/[0-9]/"NaN"/g} won't work,
because \ci{45} will be replaced by \ci{"NaN""NaN"}, since both \ci{4}
and \ci{5} count as separate matches. 

Let us say that values over ten are suspect. The search
\ci{s/[1-9][0-9]/"NaN"/g} won't work, because \ci{100} would be replaced by
\ci{"NaN"0}.

In short, to successfully search and replace, we need to be able to
specify a segment of text in great detail. This section will provide a
few more tools and a lot of notes about how one specifies exactly the
right text.

\paragraph{Repetition} 
Here are some symbols to match repetitions.
\begin{center}
\fbox{
\begin{tabular}{rl}
\ci{*}	& the last atom appears zero or more times\\
\ci{+}	& the last atom appears one or more times (GNU grep/sed: \ci{$\backslash$+})\\
\ci{?}	& the last atom appears zero or one times (GNU grep/sed: \ci{$\backslash$?})
\end{tabular}
}
\end{center}

To replace all of the numbers less than 100 in a file:
\begin{lstlisting}
perl -pi~  "s/([^0-9]|^)([0-9][0-9]\\?)([^0-9]|\$)/\\$1NaN\\$3/g" search_me
\end{lstlisting}
This is a mess, but a very precise mess. The first part,
\ci{([\that 0-9]|\that)} will match either a non-numeric character
or the beginning of the line. The second part,
\ci{([0-9][0-9]\textbs{}?)},
matches either one or two digits (but never three). The third part, 
\ci{([\that0-9]|\$)} will match either a non-numeric character
or the end of the line. Thus, we have precisely communicated that we
want something, then a number under 100, then something else.
Since the search string used three sets of parens, the output string
can refer to all three. It repeats the first and last verbatim, and
replaces the second with \ci{NaN}, as we had desired.

\exercise{Modify the search to include an optional decimal of arbitrary
length. Write up a test file and test that your modification works
correctly.}


\section{Adding and deleting}

Recall the format for the command to print a line from page
\pageref{sedintro}: \ci{/find\_me/p}. This consists of a location and a
command. With the slashes, the location is: those lines that match
\ci{find\_me}. You can also explicitly specify a line number or a range
of lines. To print line seven, use \ci{7p}. Just as the \ci{\$} indicates the
end of the line, as a line number it indicates the last line in the
file, so use \ci{sed -n "\$p" < infile} to print the last line of
\ci{infile}.  To specify a range, use a comma. Thus, 
\ci{sed -n "1,\$p" < infile} prints the entire file.

There are more commands than just \ci{p} for print. You could use \ci{d}
to delete, \ci{i} to insert above the given line, and \ci{a} to append
after the given line. \ci{d} will accept a range of
addresses, and generally behaves like \ci{p}.
But \ci{i} and \ci{a} will work on only one line at a time, so they may
not be preceded by a comma-separated range. They are immediately followed
by the text to insert, so like regexes, they have a disconcerting lack of
delimiters between the address, command, and text elements.

\begin{lstlisting}
#Add a pause after a Gnuplot data block
sed -i~ -e "/^e$/apause pauselength." plotfile
#Put the text plot '-' at the head of a file.
sed -i~ -e "1iplot '-'" plotfile
#Pretend missing data does not exist
sed -i~ -e "/NaN/d" plotfile
\end{lstlisting}

By the way, if you really want to get sed to print ``Hello, world'' you
can do it by inserting at one line and ignoring the rest of the file:
\begin{lstlisting}
sed -n -e "1iHello, world." < any_random_file
\end{lstlisting}

Perl can do all of these things easily from inside a Perl script,
but inserting and deleting lines from the command line is not as
pleasant as using \bi{sed}.\footnote{\label{dchperl}
A reader recommends the following for deleting a line:\\
        \bi{perl -n -e 'print unless /NaN/'}\\
For inserting a line:\\
        \bi{perl -n -e 'print; print "pause pauselength." if /\that{}e\$/'}\\
For adding a line at the top of a file:\\
        \bi{perl -p -e 'print "plot \'-\'\textbs{}n" unless \$a; \$a=1'}\\
}


\exercise{\label{classextwo} 
Refer to the exercise on page \pageref{classex}, which read in
a text file and produced a Graphviz-readable output file. That exercise
read the text to an \ci{apop\_data} set and then wrote the output, which
is sensible when pulling many classes from a database. But if you have
the text file \bi{data-classroom}, you can modify it directly into 
Graphviz's format. Write a sed script to:
\begin{itemize}
\item Delete the header line.
\item Replace each pipe with a \ci{->}.
\item Replace each number $n$ with \ci{node}$n$.
\item Add a header (as on page \pageref{graphhead}).
\item Add the end-brace on the last line.
\end{itemize}
Pipe your output through \bi{neato} to check that your processing produced
a correctly \bi{neato}-readable file.
}

\exercise{Turn the \bi{data-classroom} file into an SQL script to create
a table.
\begin{itemize}
\item Delete the header line.
\item Add a header \si{create table class(ego, nominee)}. [Bonus points:
write the search-and-replace that converts the existing header into this
form.]
\item Replace each pair of numbers \ci{n|m} with the SQL \si{insert into
class(n, m);}.
\item For added speed, put a \si{begin;}/\si{commit;} wrapper around the entire file.
\end{itemize}
Pipe the output to \bi{sqlite3} to verify that your edits correctly created and populated the table. 
}

\summary{
\item Your best bet for command-line search-and-replace is Perl or sed. Syntax:
\bi{perl -pi~ "s/replace me/with me/g" data\_file} or
\bi{sed -i~ "s/replace me/with me/g" data\_file}.
\item If you have a set of parens in the search portion, you can refer
to it in the replace portion by \ci{\textbs\$1}, \ci{\textbs\$2}, et
cetera.
\item The \ci{*}, \ci{+}, and \ci{?} let you repeat the previous
character or bracketed expression.
}

\section{More examples}

\paragraph{Quoting and unquoting}
Although the dot character seems convenient, it is almost never what you
want. Let us say that we are looking for expressions in quotes,
such as \ci{"anything"}. It may seem that this translates to the regular
expression \ci{".*"}, meaning any character, repeated zero or more
times, enclosed by quotes. Now consider this line: \ci{"first bit",
"second bit"}. You meant to have two matches, but instead will get only
one: \ci{first bit", "second bit}, since this is everything between the
two most extreme quotes. What you meant to say was that you want anything
that is not a \ci{"} between two quotes. That is, \ci{"[\that"]"}. 

Say that the program that produced your data put it all in
quotes, but you are reading it in to a  program that does not like
having quotes. Then this will fix the problem:
\begin{lstlisting}
perl -pi~ "s/\"([^\"])\"/\\$1/g" data_file
\end{lstlisting}
Notice that we need to indicate to the command line that the quotes are
not ending the Perl command, so they are all prepended with backslashes.

\paragraph{Getting rid of commas}
Some data sources improve human readability by separating data by
commas; for example, we see from \ci{data-wb-gdp} that the USA's GDP for
2005 was \$12,455,068 million. Unfortunately, if your program reads
commas as field delimiters, this human-readability convenience ruins
computer readability. But commas in text are entirely valid, so we want
to remove only commas between two numbers. We can do this by searching
for a number-comma-number pattern, and replacing it with only the
numbers. Here is the \ci{sed} command-line version of the process:
\begin{lstlisting}
sed -i~ -e "s/\([0-9]\),\([0-9]\)/\\1\\2/g" fixme.txt
\end{lstlisting}

\paragraph{Suspicious non-printing characters} Some sources like to
put odd non-printing characters in their data. Since they don't print,
they are hard to spot, but they produce odd side-effects like columns
in tables named \bi{pop$\square$\"O\'E$\square$tion}. It is a hard
problem to diagnose, but an easy problem to fix. Since \bi{[:print:]}
matches all printing characters, \bi{[\that{}[:print:]]} matches all
non-printing characters, and the following command replaces all
such characters with nothing: 
\begin{lstlisting}
sed -i~ -e "s/[^[:print:]]//g" fixme.txt
\end{lstlisting}

\paragraph{Text to database}\cindex{apop\_text\_to\_db}
The \bi{apop\_text\_to\_db} command line program (and its corresponding
C function) can take input from \bi{STDIN}. Thus, you can put it at the end of
any of the above stream to directly dump data to an SQLite database.

For many POSIX programs that typically take file input, the traditional
way to indicate that you are sending data from \bi{STDIN} instead of a text
file is to use \bi{-} as the file name. Thus, to pipe data from sed to a
database:
\begin{lstlisting}
sed "s/\([0-9]\),\([0-9]\)/\\1\\2/g" <fixme.txt | apop_text_to_db - datatab new.db
\end{lstlisting}

\comment{
\paragraph{Dealing with white space} \index{tabs!expanding}
Spaces versus tabs: a debate that will rage on forever. The problem is
that data may include small or large 

%sed -e"s/\W\\+/        /g" 
%sed -e"s/	\\+/ /g" 
}
 
More forthcoming.




\comment{
Let us say that we have comma-delimited text, and we need any element that
is not a number to be put in quotes. First, let's construct some
numbers. One type of number is just digits, perhaps preceded by
a sign: \ci{([+-]|)[0-9]+}. Another type of number includes a
decimal point, and at least one digit before the decimal:
\ci{([+-]|)[0-9]+\textbs{}.[0-9]*}. Another type has at least one digit after
the decimal: \ci{([+-]|)[0-9]*\textbs{}.[0-9]+}. Another type is in scientific
notation, with a sign, a single digit, then a decimal, then more digits, then an
\ci{e}, then a sign and more digits:
\ci{([+-]|)[0-9]\textbs{}.[0-9]*e[+-][0-9]*}.

We can use the \ci{(A|B|C)} form to combine these into a form that any number will match:
\ci{([+-]|)([0-9]+|{}[0-9]+\textbs{}.[0-9]*|{}[0-9]*\textbs{}.[0-9]+|{}[0-9]\textbs{}.[0-9]*e[+-][0-9]*)}.


Now, let us be precise about what
a non-numeric element is. It:
\begin{itemize}
\item begins with either a beginning-of-line or comma,
\item does not match the monolithic pattern above,
\item and ends with a comma or an end-of-line.
\end{itemize}

The first item translates to 


}
