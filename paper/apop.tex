\chapter{Apophenia} \label{apop} 

One could divide Apophenia's functions into two categories: haphazard
convenience functions, and a unified worldview of about how data is
analyzed. Some of the convenience functions have already appeared; this
chapter describes the unified world view. 

This may also be a good place to remind the reader that, as with
most of the stats packages of the world, Apophenia has two types of
documentation: the chatty, not-comprehensive overview you are reading
now and the comprehensive function-by-function reference. The reference
is autogenerated from the source code, and can be found online at
\url{http://apophenia.info/doc} or generated from your own copy of the
source using \binline{doxygen}.\footnote{doxygen is free software and
should be available via your package manager. If you have it installed,
run \cinline{make doc} in your source directory.}

Finally, Apophenia is evolving quickly, meaning that some of the details
below may be rewritten a few months from now, and there are still bugs
to be found. Take this not as a warning, but as an invitation: the code
base is entirely open, so you are invited to add new models, point out
bugs, and implement features so the package improves more rapidly.

\paragraph{Layers of abstraction} 
In grade school, we learned how to deal with numbers: adding,
subtracting, dividing. We were given pages of exercises where we had to
divide two numbers by hand.

In high school, we learned how to invert matrices. We were shown a
lengthy algorithm that took the process of adding and dividing real
numbers as given. We were free to use a calculator to divide numbers,
but executed the algorithm of manipulating submatrices by hand.

In statistics class, we learned how to run regressions.  Inverting a
matrix was indicated with a few strokes of the pen---$\Xv^{-1}$---and
the process of executing the algorithm (and its underlying additions and
divisions) left to a computer.

\index{abstraction, layers of}
These are three \vocab{layers of abstraction}: numbers, matrices, and
statistical models. The stacks-of-frames
system from Chapter \ref{c_crash} is a perfect way to implement
different layers of abstraction, as the \ci{gsl\_matrix\_add} function
calls C's built-in addition function, and the
\ci{gsl\_matrix\_HH\_solve} routine repeatedly calls functions on the
level of \ci{gsl\_matrix\_add}. 

\index{object-oriented programming}
The \ci{gsl\_matrix} and \ci{gsl\_vector} data structures were focal to
their layer of abstraction. This is an \airq{object-oriented}
means of implementing higher levels of abstraction: design an object that
holds a collection of items at a lower level of abstraction, and then
write companion functions named \ci{object\_add}, \ci{object\_alloc},
\ci{object\_copy}, et cetera, that allow the data structure to be
manipulated on its own level of abstraction.

\paragraph{An example}
Let us begin with an example of estimating a model at this level of
abstraction. All of the structures here will be discussed in detail
below.

Assume a
data set in a file, such as the \cinline{test\_data} file included with
Apophenia's source code, and that file has no row names but does have
column names.
\begin{lstlisting}[numbers=left, numberstyle=\scshape]
#include <apophenia/headers.h>

int main(){
    apop_convert_text_to_db("data","d",0,1,NULL);
    apop_data *data       = apop_query_to_data("select * from d");
    apop_estimate   *est  = apop_OLS.estimate(data, NULL);
    apop_estimate_show(est);
    return 0;
}
\end{lstlisting}

Line four first read the data into the database, and then line five pulls
it into an \cinline{apop\_data} set. 
Since we didn't pare down the data,
we didn't really need the database, and could have read the text file
directly into a \cinline{apop\_data} structure:
\begin{lstlisting}
    data       = apop_text_to_data("data",0,1);
\end{lstlisting}
Line six 
sends the data and the estimate to the \cinline{apop\_OLS.estimate}
function, which naturally returns an \cinline{apop\_estimate}
structure, which line seven then displays.

Feeling lazy? The program above was good form and demonstrated useful
features, but if we don't need the intermediate forms, the code below
will do the same thing in even fewer lines:

\label{oneliner}
\begin{lstlisting}
#include <apophenia/headers.h>
int main(){
    apop_estimate_show(apop_OLS.estimate(apop_text_to_data("data",0,1), NULL));
    return 0; }
\end{lstlisting}


\section{The structures}
Recall the one-sentence summary of statistical analysis from
the first page of Chapter \ref{intro}: estimate the parameters
of a model using data. The Apophenia library provides functions
and data structures at exactly this level of abstraction. The
three key objects defined that embody this description are the
\cinline{apop\_data}, \cinline{apop\_model}, and \cinline{apop\_estimate}
structures.

The basic story for a statistical analysis is that the researcher
assembles a data set into an \cinline{apop\_data} structure, then sends it to
an \cinline{apop\_model} so that the model's parameters can be estimated,
and that is returned in an \cinline{apop\_estimate} structure. Finally, the
researcher may then send the \cinline{apop\_estimate} through various
hypothesis tests.

Supporting these main structures are a few more structures you would only
have to worry about for fine tuning.  The \cinline{apop\_name} structure is
an organized list of row and column names. Functions that take an 
\cinline{apop\_data} set automatically handle the names for you. 
Some models, such as MLEs, require some parameters to run, in
which case you will need to fill out an \cinline{apop\_est\-i\-ma\-tion\_params}
form and hand it in to the model. Included in the
\cinline{apop\_est\-i\-ma\-tion\_params} is an
\cinline{apop\_inventory} structure that lists the elements
that an \cinline{apop\_estimate} will generate. No model produces
everything, and if you don't need covariances, why calculate them. If you
don't care about the estimation parameters, sending \cinline{NULL} will
work fine for most models. 

\subsection{Data} \cindx{apop\_data}{(textbf}
The \cinline{apop\_data} structure is the union of three data types:
the \cind{gsl\_vector}, \cind{gsl\_matrix}, and a table of strings. It
includes an \cinline{apop\_name} structure (see below), so you know to what
your data is referring.

The conceptual layout is given in Figure \ref{datalayout}. The vector,
columns of the matrix, and columns of text are all named. Also, all rows
are named, but there is only one set of rows, because the presumption is
that each row of the structure holds information about a single
observation.

Think of the vector as the $-1^{\rm st}$ element of the matrix, and the 
text elements as having their own addresses. For example, the vector may
represent the dependent variable, and the matrix may be the independent
variables. If there are categories, they could be held in the text area,
and then converted into dummies in the matrix using
\cind{apop\_produce\_dummies}. 


\def\atouch{\phantom {.}}
\renewcommand\arraystretch{1.1}
\begin{figure}
\hspace {-0.5cm}
\begin{tabular}{lc|ccc|ccccc|cccc}
\hhline{~~~-~~---~~---}
        &&& \multicolumn{1}{|c|}{``v''}   &&& \multicolumn{1}{|c}{``c0''} & ``c1'' & \multicolumn{1}{c|}{``c2''}  &&& \multicolumn{1}{|c}{``t0''} & ``t1'' & \multicolumn{1}{c|}{``t2''}    \\\hhline{~~~-~~---~~---}
\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch&\atouch\\\hhline{-}
\multicolumn{1}{|c|}{``r0''}&&&(0, -1)   &&& (0, 0) & (0, 1) & (0, 2) &&& (0, 0) & (0, 1) & (0, 2)\\ 
\multicolumn{1}{|c|}{``r1''}&&&(1, -1)   &&& (1, 0) & (1, 1) & (1, 2) &&& (1, 0) & (1, 1) & (1, 2)\\
\multicolumn{1}{|c|}{``r2''}&\atouch&\atouch&(2, -1)   &\atouch&& (2, 0) & (2, 1) & (2, 2) &\atouch&\atouch& (2, 0) & (2, 2) & (2, 2)\\\hhline{-}
\end{tabular}
\caption{The vector is column -1 of the matrix, while the text gets its
own numbering system. Row names are shared by all three
elements.}
\label{datalayout}
\end{figure}

Should you wish to access the individual elements of the \cinline{apop\_data} structure, here is the declaration:

\begin{lstlisting}
typedef struct apop_data{
    gsl_vector  *vector;
    gsl_matrix  *matrix;
    apop_name   *names;
    char        ***categories;
    int         catsize[2];
} apop_data;
\end{lstlisting}



You can easily operate on the individual elements of the structure:
if the \cinline{matrix\_man\-ip\-u\-late} function requires a
\cinline{gsl\_ma\-trix}, but you are using an \cinline{apop\_da\-ta}
structure, then you can call
\cinline{matrix\_man\-ip\-u\-late(my\_data-$>$matrix)}. Similarly, you
can
manipulate the names and the table of text data directly. The size of the text
data is stored in the \cinline{catsize} element. Sample usage:

\begin{lstlisting}
int r,c;
apop_data   *set = get_category_data(...);
for (r=0; r< set->catsize[0]; r++){
    for (c=0; c< set->catsize[1]; c++){
        printf("%s\t", set->categories[r][c]);
    }
    printf("\n");
}
\end{lstlisting}

There is no consistency-checking to make sure the number of row names,
the \cinline{vector->size}, or  \cinline{matrix->size1} are equal.
If you want to put a vector of fifteen elements and a $10 \times 10$
matrix in the same structure, and only name the first two columns, you
are free to do so.

Further, the typical case is that not all elements are assigned 
values at all; \cind{apop\_data\_alloc} initializes most elements as
\cinline{NULL}. If you just want a \cind{gsl\_vector} with
names, then you can use the \cinline{apop\_data} structure as such,
by leaving 
\cinline{your\_data->matrix == your\_da\-ta->categories ==
NULL}.\footnote{The seasoned C programmers will recognize such usage as 
similar to a \cind{union} between a \cinline{gsl\_vector}, a
\cinline{gsl\_matrix}, and a \cinline{char} array. 
\index{object-oriented programming}
C$^{++}$ programmers
will observe that the structure allows a form of polymorphism, because
you can write one function that takes an \cinline{apop\_data}
as input, but operates on one or both of a \cinline{gsl\_vector} or a
\cinline{gsl\_matrix}, depending on which is not \cinline{NULL} in
the input.}

\exercise{\label{quadqtwo}On page \pageref{quadq}, you wrote a function to find the quadratic
form $\Xv'\Yv\Xv$, where $\Xv$ and $\Yv$ are both matrices.
But often,  we need the quadratic form for a vector and matrix, $\xv'\Yv\xv$. The
math is the same, but we need two functions: one that takes a
\ci{gsl\_matrix} and one that takes a \ci{gsl\_vector}. 

You already have a \ci{quadratic\_form} function for matrices.
Make a copy and modify the copy to take a vector as the first argument:
\ci{double *vector\_quadratic\_form(gsl\_vector *x, gsl\_matrix
*y)}.

Now that you have both functions, you will easily be able to write a
function with header \ci{double data\_quadratic\_form(apop\_data *x, apop\_data
*y, apop\_data *xyx)} to call either subfunction as appropriate.  
If \ci{x->matrix == NULL}, then find the quadratic form using
\ci{x->vector}, set \ci{xyx} to a 1-D matrix with the value of
$\xv'\Yv\xv$ and return the \ci{double} value.

If \ci{x->matrix != NULL}, then find the quadratic form using
\ci{x->matrix}, set \ci{xyx} to the quadratic form, and return \ci{GSL\_NAN}.
}


\comment{
Categories are not particularly well-supported, because there is not
much analysis that one could do with them---they are primarily useful
for dissecting data on the SQL side. But one common use is to 
take a column with, say, five categories,
and produce four columns of dummy variables.}

There are
various functions for manipulating \cinline{apop\_data} sets. You will
first
create the data set, probably with \cind{apop\_query\_to\_data}, but perhaps
with \cind{apop\_matrix\_to\_data}, \cind{apop\_vector\_to\_data}, or
creating a blank slate with \cind{apop\_data\_alloc}.
  
\paragraph{Forming \ind{partitioned matrices}}
\cindex{apop\_data\_copy}
You can copy the entire data set, 
stack two data matrices one on top of the other (stack rows), 
stack two data matrices one to the right of the other (stack columns),
or stack two data vectors:
\begin{lstlisting}
apop_data *newcopy = apop_data_copy(oldset);
apop_data *newset_tall = apop_data_stack(oldset_one, oldset_two, 'r');}
apop_data *newset_wide = apop_data_stack(oldset_one, oldset_two, 'c');}
apop_data *newset_vector = apop_data_stack(oldset_one, oldset_two, 'v');}
\end{lstlisting}

All of these operations make a full copy of the data being stacked, without
erasing the original data sets, so in each case
you will be taking up twice as much memory
at the end of the function until you call
\cinline{apop\_data\_free(oldset\_one); apop\_data\_free(oldset\_two)}.\footnote{That is, 
if you are stacking matrices, you will get an \cinline{apop\_data} set with a
\cinline{NULL} vector and category grid, but a copy of the matrix data; 
if you are stacking vectors, you will get an \cinline{apop\_data} set with a
\cinline{NULL} matrix and category grid, but a copy of the vector 
data.}\cindex{apop\_data\_free} 

As
noted earlier, you are generally better off doing data manipulation
in the database. If the tables are in the database instead of
\cinline{apop\_data} sets the two stacking commands above are equivalent
to \sinline{select * from oldset\_one union select * from oldset\_two}
and \sinline{select t1.*, t2.* from old\-set\_one t1, old\-set\_two t2},
respectively.

Since the \cinline{matrix} element of the \cinline{apop\_data} structure
is a \cinline{gsl\_matrix}, you can use any of the tools from Chapter
\ref{linear_algebra} to dissect it, and similarly for the
\cinline{vector} element.
There are eight additional functions for setting and getting an element from an
\cinline{apop\_data} set using the names. Let \airq{t} be a title and
\airq{n} be a number; then you may refer to the row-column coordinate
using the $(n,n)$, $(t,n)$, $(n,t)$, or $(t,t)$ form:
\begin{lstlisting}
apop_data_get(your_data, i, j);
apop_data_get_tn(your_data, "rowname", j);
apop_data_get_nt(your_data, i, "colname");
apop_data_get_tt(your_data, "rowname", "colname");
apop_data_set(your_data, i, j, new_value);
apop_data_set_tn(your_data, "rowname", j, new_value);
apop_data_set_nt(your_data, i, "colname", new_value);
apop_data_set_tt(your_data, "rowname", "colname", new_value);
\end{lstlisting}
Notice that the first form, \cinline{apop\_data\_get},
has an abbreviated name, and for matrix data is identical to
\cinline{gsl\_matrix\_get(your\_data->matrix, i, j)}. 

As above, you can think about the vector as the -1$^{\rm{st}}$ element
of the matrix, so if $j < 0$ in any of the above functions, e.g.
\cinline{apop\_data\_get\_tn(your\_data, "rowname", -1)}, then the
function operates on the \cinline{apop\_data} structure's vector rather
than the matrix.

\cindex{apop\_data\_get...}
\cindex{apop\_data\_set...}

\paragraph{Dot products} \label{apopdot} In Chapter \ref{linear_algebra}, you saw the
GSL's rather messy functions to take dot products of matrices and
vectors. The \cind{apop\_dot} function handles most of the mess for you.
It takes up to four arguments: two \ci{apop\_data} structures, and one
flag for each matrix 
indicating whether it should be transposed or not. For example, if \ci{X} is a matrix,
then 
\begin{lstlisting}
apop_dot(X, X, 1, 0);
\end{lstlisting}
will find $X'X$: we are taking the dot product of \ci{X} with itself,
and the first version is transposed and the second is not.

Since an \ci{apop\_data} set may be either a vector or a matrix, this
function handles all four of matrix $\cdot$ matrix,
matrix $\cdot$ vector, vector $\cdot$ matrix, and vector $\cdot$ vector.
If a data set has a matrix then the matrix is used, and if it does not
then the vector component is used.

There should be exactly as many transposition flags as
matrices.\footnote{Yes, C lets you have a variable number of function
arguments. See \vocab{variadic functions} in your favorite comprehensive
C reference.}
If the first element is a vector, it is always taken to be a row;
if the second element is a vector, it is always a column. In both cases,
if the other element is a matrix, you will need one transposition flag
to indicate whether the matrix should be transposed.

If both elements are vectors, then you are probably better off just
using  \cind{gsl\_cblas\_ddot}, as per page \pageref{ddot}, but if you use
\ci{apop\_dot}, the output will be an \ci{apop\_data} set that has
a vector element of length one.

Why do you have to tell a computer whether to transpose or not? Some
feel that if you
send a \ci{1} to indicate transposition when you meant \ci{0} (or vice versa), the system should be able to
determine this. Let us say that you have a $1\times 10$ vector that you
will multiply against three data sets, where the first is $8 \times 10$,
the second is $15 \times 10$, and the third is $10 \times 10$. You write
a simple \ci{for} loop:
\begin{lstlisting}
for(i=0; i<3; i++)
    out[i] = apop_dot(data[i], v, 1);
\end{lstlisting}
At \ci{i=0}, a `smart' system realizes that you committed a faux pas:
an $8 \times 10$ matrix dot a $10 \times 1$ column vector works without
transposition. So it corrects you without telling you, and does the same
with \ci{data[1]}. With \ci{data[2]}, the transposition works, since
there are both ten rows and columns. So \ci{out[0]} and \ci{out[1]} are
correct and \ci{out[2]} is not. Good luck catching and debugging that.

To give an example of linear algebra with \ci{apop\_data} structures,
recall the Markov chain example on page \pageref{markovone}. Here is the
program redone using \ci{apop\_dot}. As you can see, it is much shorter
and easier to read: \label{markovtwo}\lstinputlisting{sources/markov2.c}

 \cindx{apop\_data}{)textbf}

\exercise{In the exercise on page \pageref{quadqtwo}, you wrote
a general function for calculating quadratic forms using the GSL's BLAS
functions. Rewrite it using the header \cinline{apop\_data
*quadratic\_form(apop\_data *x, apop\_data *y);} where \ci{x} may either
include a matrix element or a vector element.}

\subsection{Models}
The \cinline{apop\_model} structure encapsulates a description of the world
in which the data and the parameters produce observed outcomes. The
\cinline{apop\_mo\-del.\-est\-i\-mate()} method\footnote{When a fuction
is inside a structure (and therefore called using the dot notation of a
structure subelement) we call it a \vocab{method}.} takes in data and
produces an \cinline{apop\_est\-i\-mate}.\footnote{Many statistics
packages include a model structure that describes only linear models.
``Linear'' models can include a wide range of nonlinear features, but
they are still a subset of measure zero within the class of models as
described here. Currently, Apophenia has no plans to include a summary
syntax for describing linear models; the reader who has a linear model
to be estimated via OLS or GLS is advised to instead manipulate the
data set to the appropriate form and then apply the \cinline{apop\_OLS}
or \cinline{apop\_GLS} models.}

\marginalia{14}{Patterns in static}{\index{Apophenia!definition}{\sl Apophenia} is a term from the
psychology literature referring to the human tendency to see patterns in
static. Good data description seeks out patterns in existing data; good
hypothesis testing does not seek out patterns but aims to reject or fail
to reject observed patterns. Hypothesis testing is thus an attempt to
fight against apophenia (where it is known as the Type I error).

The Apophenia library is so named because the word has a pleasant ring, is a
statistics-related term, and is not an acronym.}


Frequently, a model is a probability distribution. The data is assumed
to have been drawn from a given distribution and the question is
only what distributional parameters best fit; e.g., assume the data
is Normally distributed and find the mean and variance.

One could also use the \cinline{apop\_model} to describe 
non-statistical models involving optimization subject to constraints;
see the example of Section \ref{econ101}.

There are three possibilities:

1. You need to use a standard model included in Apophenia; see page
\pageref{modellist} for a list. In this case, you can simply call the
model, as described below.

2. You need to use a standard model not included in Apophenia. In this
case, you will need to write the model, then submit it to Apophenia's
maintainers for inclusion in the library. Return to possibility \#1.

3. You have a data-specific model, in which case you will again need to
write your own. This is simply a matter of filling out a lengthy form,
whose details are covered in Section \ref{writeyourown}. Filling out the form takes more effort than writing free-form code, but standardization has its benefits: just as putting
your data into the \ci{gsl\_vector} form allowed you to use operations
on the vector level of abstraction such as \ci{gsl\_vector\_add},
once your model is in the \ci{apop\_model} form, you can operate on
the model level of abstraction. In Chapter \ref{mle}, you will see how
to apply a half-dozen different optimum-searching methods to find the
likelihood-maximizing parameter values for your model, and the Monte
Carlo functions of Chapter \ref{boot} will estimate characteristics of
the model parameters with one function call.

The \cinline{apop\_model} also includes a
number of additional functions that may be useful for additional analysis,
such as a likelihood function that could be used for ML estimation or
for estimating the Hessian, and a random draw generator. Some effort
has been made to ensure that the prepackaged models include as many of
these auxiliary functions as possible; if you are writing your own,
there is no requirement that you provide all functions, and the \cinline{apop\_maximum\_likelihood} and \cinline{apop\_numerical\_hessian}
functions do a good job of filling in blanks.

\subsection{Estimates} 
%\index{apop\_estimate@\cinlinetwo{apop\_estimate}|(textbf}
\cindx{apop\_estimate}{(textbf}
The \cinline{apop\_estimate} structure returns all the data one would want
from a regression or ML estimation, including the parameters estimated,
the variance/covariance matrix, the predicted values, et cetera. The structure
includes instances of almost all of the other structures listed here, so
that you will have a link to the data and model, and a copy of the
estimation parameters that produced the original estimate. Within the
estimation parameters one will find an inventory of
what the \cinline{apop\_est\-i\-mate} contains.

Here is the current definition of the \cinline{apop\_estimate} structure. You can see that it errs on the inclusive side.
\begin{lstlisting}
typedef struct apop_estimate{
    apop_data   *parameters, *dependent, *covariance;
    double      log_likelihood;
    int         status;
    struct apop_data   *data;
    struct apop_model  *model;
    struct apop_estimation_params  estimation_params;
} apop_estimate;
\end{lstlisting}

The \cinline{parameters} structure primarily holds the estimated
parameters of the model in the \cinline{parameters->vector}
element. As noted earlier, the parameter estimation process and the
hypothesis testing process are entirely separate. Apophenia generally
keeps to this: functions with \airq{estimate} in the name do not
test hypotheses, and functions with \airq{test} in the name estimate
only those parameters needed for testing. But there is one exception
to this. It is such a common custom to test whether every estimated
parameter is by itself significantly different from zero that many
consider an estimation incomplete without this test. Therefore, if
\cinline{estimation\_params->uses.confidence==1} (which it is by default), then 
each row of \cinline{parameters->matrix} will hold the $t$ statistic,
$p$ value, and other useful test parameters regarding the corresponding
element of \cinline{parameters->vector}.

The \cinline{dependent} matrix is three columns, the first named for
your dependent variable, the second named
\cinline{predicted}, and the third \cinline{residual}. 
If this is a model with a single dependent and many
independent variables, then the first column is the actual data. Let our
model be $\Yv = \betav \Xv + \epsilon$. The first column is the $\Yv$
value, the second column is the
predicted values, $\betav \Xv$, and the third column is the residuals:
$\epsilon$. The third column is therefore always the first minus
the second, and this is typically how that column was calculated
internally. There is thus currently no way to get just the predicted
but not the residuals or vice versa.

The \cinline{status} element is primarily for maximum likelihood
estimations, which can fail to converge. If \cinline{status != 0},
then the MLE failed and the estimate should not be relied on.

The \cinline{apop\_est\-i\-mate} tries to be self-contained, including
everything one would need to re-run an estimation, such as copies of the
original model and parameters. In fact, on page
\pageref{restart}, the \cind{apop\_estimate\_restart} function will be
able to derive a new \cinline{apop\_est\-i\-mate} using only an old
\cinline{apop\_est\-i\-mate} as an input. 

However, since we assume that the data set is a million entries, it
would be impractical to save a copy in the \cinline{apop\_est\-i\-mate}.
Therefore, the other elements should be copied in, but
\cinline{your\_estimate.data} is merely a spare
pointer, pointing to the block of memory where your data is located. If
you destroy your data using this pointer, then you have just destroyed
your original data set, and vice versa.\footnote{Notice also that the
parameters and model are copied in, but their elements may be copies of pointers, so
you must take care when modifying the version of the objects in the main
program or in the estimate that the other version does not suffer
undesirable side-effects. Of course, replacing the pointers in the copy
of a structure with a pointer to new data will not affect the pointer or
its pointed-to data in
the original structure.}
%\index{apop\_estimate@\cinlinetwo{apop\_estimate}|)textbf}
\cindx{apop\_estimate}{)textbf}


\summary{
\item Code-writing often breaks down into layers of abstraction. In
this case, C provides structures to represent numbers (\ci{float},
\ci{int}) and functions to operate on those structures (\ci{ + - * pow()}); the GSL
provided structures to represent vectors and matrices, and functions to operate on those structures
(\ci{gsl\_matrix\_sum}); Apophenia provides structures to represent
models and estimates, and functions to operate on them.
\item The \ci{apop\_data} structure combines a vector, matrix, text
array, and names for all of these elements.
\item The \ci{apop\_model} aggregates methods of producing 
estimates of parameters from data.
\item The \ci{apop\_estimate} structure embodies parameter estimates,
and all that one would need to describe those parameter estimates, such
as the variance-covariance matrix.
}

\subsection{\treesymbol{} The supporting cast}
Generally, the structures in this section are used as elements of the main
structures above, and are handled automatically as necessary. However,
they are readily accessible, and if you would like finer control of how
estimates are made or results printed, you can manipulate these
directly.

\paragraph{Names}
The \cinline{apop\_name} structure has four components: a single vector
name, a list of column
names, a list of row names, and a list of category (text) variable
names. It is intended to accompany the \cinline{gsl\_matrix} structure,
which holds all the other information about a data array such as the
number of rows and columns. 

As in figure \ref{datalayout}, the three elements do not have separate lists of names: the presumption
is that all of the elements of an \cind{apop\_data} structure are part
of a partitioned matrix, so the first element of the vector, the first
row of the \cinline{gsl\_matrix}, and the first row of the category matrix all represent a single observation, whose name is \cinline{your\_data->rownames[0]}.

You won't see an \cinline{apop\_name} structure by itself very often;
usually it is embedded in an \cinline{apop\_data} structure. But its
dimension is entirely independent of the \cinline{apop\_data} structure's
data matrices, and you can operate on the \cinline{apop\_name} structure
directly to add or retrieve names.

For example, to get the
column number of a variable in which you are interested, use \cind{apop\_name\_find}, e.g.:
\begin{lstlisting}
int column_number   = apop_name_find(my_data->names, "ages", 'c');
gsl_vector age_vector = gsl_matrix_column(my_data->matrix, column_number).vector;
printf("mean age: %g\n", apop_vector_mean(&age_vector));
\end{lstlisting}
As above, you can also use \cind{apop\_data\_get\_nt} to pull a single
element given a row number and a column name.

\cinline{apop\_name\_find} and the \ci{apop\_data\_get}/\ci{set} family accept two wildcard characters to simplify
searching for an element. The underscore will match any single
character, and the \% will match any number of characters. Also, the
search is case-insensitive. Thus, \cinline{"p\_val\%"} will match
\cinline{P value}, \cinline{p-val} and \cinline{p.values}. The function
achieves this magic by using SQLite's implementation of the \sind{like}
operator; see the SQLite online reference for fine-grained details.

\exercise{If you have one column named \ci{t1} followed by one named
\ci{T1}, you're in trouble, since \ci{apop\_name\_find} only returns
the first case-insensitive match, so there is no way to retrieve
the location of \ci{T1}.

Write a function \ci{int name\_find(apop\_name *n, char *findme, char type)} that
does an exact, no-wildcard, case-sensitive search, returning the 
first element of the name structure that matches \ci{findme}. If
\ci{type=='c'} search column names, if 
\ci{type=='r'} search row names, and if
\ci{type=='t'} search category (text) names.}

The easy way to add names to a data set is to use the 
\cind{apop\_query\_to\_data} function. It takes an SQL query and returns
the data set with column names neatly stored in
the \cinline{names} element of the returned data set.

If you want to do it yourself, the set of names from the last query can
always be retrieved via a call to \cind{apop\_get\_names}.

If you have a data set with a blank set of names, such as one
produced via \cind{apop\_matrix\_to\_data},
you may use \cind{apop\_name\_add} to add one name at a
time, e.g.:
\ns{5} \begin{lstlisting}
apop_data newset    = apop_matrix_to_data(a_gsl_matrix);
apop_name_add(newset->names, "col0",'c');
apop_name_add(newset->names, "col1",'c');
apop_name_add(newset->names, "row0",'r');
apop_name_add(newset->names, "Victor the vector",'v');
\end{lstlisting}

\paragraph{Inventory}
The \cinline{apop\_inventory} structure serves two purposes. It is an input
to an \cinline{apop\_model}, that tells the function what output you
would like the \cinline{apop\_estimate} output to include.  Alternatively, you
can just set it to a \cinline{NULL} pointer, and the functions will return
everything apropos.

The output from these functions also includes an inventory, 
giving a list of the elements of the structure which are
actually in use. 

The inventory has one binary element for each element of the \cinline{apop\_estimate} structure.

If the \cinline{apop\_inventory} will be sent in to a regression/MLE
function, set the appropriate element to either zero or one if you would
like the function to return the designated \cinline{apop\_estimate} element.

The \cinline{apop\_estimate} structure itself has an \cinline{apop\_inventory}
element named \cinline{uses} embedded within it. Those elements for
which \cinline{uses.elmt} are zero are unallocated pointers (so be careful:
precede any pointer use with an \cinline{if(est\-i\-mate->uses.el\-e\-ment)} clause).

It may sometimes be useful to manipulate the \cinline{apop\_estimate} structure's
internal \cinline{apop\_inventory} element to your own benefit. For
example, if you set \cinline{est-$>$uses.co\-var\-iance = 0} before calling
\cinline{apop\_print\_estimate(est, NULL)}, then the covariance matrix won't get
printed. But if you then call \cinline{apop\_estimate\_free(est)},
then the covariance matrix won't get freed, either.

\paragraph{Estimate parameters}
The \cind{apop\_estimation\_params} are the details for how an \cinline{apop\_est\-i\-mate} should do its work; currently it is mostly just the specifications
for tolerances, step sizes, starting points, et cetera, for \cinline{apop\_max\-i\-mum\_like\-li\-hood}. It also includes an \cinline{apop\_inventory}.  

You have two options: the first would be to just send your estimation
routines a \cinline{NULL} every time. The other would be to allocate an
\cinline{apop\_estimation\_params} structure using 
\begin{lstlisting}
apop_estimation_params *ep = apop_estimation_params_alloc();
\end{lstlisting}
Once it is allocated to reasonable defaults, you may then modify
individual elements one by one, such as \cinline{ep->step\_size = 1e-4}.
If you don't use the \cind{apop\_estimation\_params\_alloc} function,
then odd things may happen; for example, the inventory may not be
allocated.

\section{Estimating a model}
\index{Yule distribution} \index{Waring distribution}
\index{Zipf distribution} \index{Exponential distribution}
\index{Normal distribution} \index{Gamma distribution}
\index{Poisson distribution} \index{Probit} \index{Logit}
\index{Ordinary Least Squares} \index{Generalized Least Squares}
\label{modellist}
Here are the models that currently ship with Apophenia:\\
\cinline{apop\_exponential} and \cinline{apop\_exp\-o\-nen\-tial\_rank}, \\
\cinline{apop\_gamma} and \cinline{apop\_gamma\_rank}, \\
\cinline{apop\_normal} (or \cinline{apop\_gaussian}, as you prefer), \\
\cinline{apop\_OLS}, \\
\cinline{apop\_poisson}, \\
\cinline{apop\_logit}, \\
\cinline{apop\_probit}, \\
\cinline{apop\_waring} and \cinline{apop\_waring\_rank}, \\
\cinline{apop\_yule} and \cinline{apop\_yule\_rank}, \\
\cinline{apop\_zipf} and \cinline{apop\_zipf\_rank}.

Some of these are full models, some are distributions, some are
estimated via closed-form calculations and some via MLEs. However, all
of them can be estimated via a form such as
\begin{lstlisting}
apop_normal.estimate(data,  NULL);
\end{lstlisting}

The optional parameter, set to \cinline{NULL} here,
is an \cinline{apop\_\-est\-i\-ma\-tion\_\-par\-a\-met\-ers} object; see
the online reference of the individual models for details of the
parameters one could set.

\paragraph{Data formats} \label{dataformats} \index{data!format}
The default, for models such as \cinline{apop\_OLS} or
\cinline{apop\_probit}, is that each row of the data is assumed to be one
observation, the first column of the data is the dependent
variable, and the remaining columns are the independent variable.

For the models that are merely a distribution, the rule that one row equals one observation is not necessary, so the data matrix can have
any form: 1 $\times$ 10,000, or 10,000 $\times$ 1, or 100 $\times$ 100.
This provides maximum flexibility in how you produce the data.

\paragraph{\treesymbol{} Data formats: networks} \index{network analysis}
Those models with variants ending in \cinline{\_rank} are typically used
in network analysis. For example, let us say that we have a classroom
where every student wrote down the ID number his or her best friend,
and we tallied this list of student numbers:\\
1 1 2 2 2 2 3 4 4 4 6 7 7 7.\\ 
First, we would need to count how often each student appeared:\\

\begin{tabbing}
id\_no \= count\\
2 \> 4\\
4 \> 3\\
7 \> 3\\
1 \> 2\\
3 \> 1\\
6 \> 1.
\end{tabbing}
In SQL: \sinline{select id\_no, count(*) as ct from surveys group by id\_no
order by ct}.

The first option would be to pass this data to
the \cinline{\_rank} version of the model, so the row above would be:\\
4 3 3 2 1 1.\\
Each row of the data set would be one classroom like the above, and the
column number represents the ranking being tallied.

Alternatively, one could 
write down one entry listing the rank for each observation. There would
be four 1s, three 2s, three 3s, et cetera:\\
1 1 1 1 2 2 2 3 3 3 4 4 5 5.\\
Here, order does not matter.  This data set can be passed to the
non-\cinline{\_rank} versions, such as \cinline{apop\_zipf} to fit a
Zipf distribution.

Both data formats will produce the same output; the one you use will
depend on the format in which the data was given to you.


\summary{
\item In many cases, a data structure consists of an observation on each
row and a variable on each column. If the model includes a dependent
variable, it should be the first row.
\item Given a prepackaged model, you can estimate the parameters of the
model by putting your data into an appropriate \ci{apop\_data}
structure, and then using the \ci{apop\_your\_model.estimate(data,
NULL)} function. This will produce an \ci{apop\_estimate} that you can
interrogate using the methods that follow.
}


\section{Output and interrogating an estimate}  \label{testoutput}
Now that you have run an estimation function to produce an 
\cinline{apop\_\-est\-i\-mate}, you want to ask it some questions. As
above, only the most basic hypothesis tests are included in the
estimate. Instead, you can pass the estimate object to a function that
will test a hypothesis. For example, the \ttind{apop\_estimate\_F\_test}
takes in an \cinline{apop\_estimate} and puts out the result of an
F test, and the \ttind{apop\_estimate\_correlation\_co\-ef\-ficient}
will produce a table including $R^2$, adjusted $R^2$, \ind{SSE}, SST,
and SSR. See page \pageref{randfexercise} for details. \index{R squared@$R^2$}
\index{SSE} \index{SSR}

The output is an \cinline{apop\_data} structure. Often, the rows are
names of the variables in your original data set, and the columns are
statistics. Note that this often means what had been a column name in the 
original data set is now a row name. 


For example, here is the 
\cinline{apop\_data} ouptut from the \cind{apop\_t\_test}
function:

\begin{center}
\begin{tabular}{|ll|}
\hline
mean left - right     &-0.268533\\
t statistic           &-23.673530\\
df                    & 1998\\
p value, 1 tail       & 0.000000\\
confidence, 1 tail    & 1.000000\\
p value, 2 tail       & 1.000000\\
confidence, 2 tail    & 0.000000\\
\hline
\end{tabular}
\end{center}
\hspace\baselineskip

Below, you will see various means
of printing the entire \cinline{apop\_data} structure, or you can use
the 
\cind{apop\_data\_get\_tn} from above to pull a single named element, e.g.:
\ns{2}\begin{lstlisting}
double pval = apop_data_get_tn(test_output, "p_val%", -1);
\end{lstlisting}

\paragraph{Output} 
Alternatively, you can print the entire  \cinline{apop\_data} structure.
Most of the useful data types have
a print function, and given the package-type-operation naming scheme,
you can basically guess their names: \cind{apop\_data\_print},
\cind{apop\_matrix\_print}, \cind{apop\_vector\_print}. 

These printing functions are actually three-in-one functions: you can
dump your data to either the screen, a file, or the database. You select
the output via the \cind{apop\_opts} structure, which is where all of
Apophenia's global options are stored. Early in putting together an
analysis, you will want to print all of your results to screen, and then
later, you will want to save temporary results to the database, and then
next month, a colleague will ask for a text file of the output; you can
make all of these major changes in output by changing 
one character in your code.

The four choices for the \index{apop\_opts!output\_type@\cinline{output\_type}}\cinline{apop\_opts.output\_type} 
variable are:
\begin{lstlisting}
apop_opts.output_type   = 's';  //default: print to screen.
apop_opts.output_type   = 'f';  //print to file.
apop_opts.output_type   = 'd';  //store in database.
apop_opts.output_type   = 'p';  //write to the pipe in apop_opts.output_pipe.
\end{lstlisting}

The screen output will generally be human-readable, meaning different
column sizes and other notes and conveniences for you at the terminal to
understand what is going on. The file output will generally be oriented
toward allowing a machine to read the output, meaning stricter formatting.

The second argument to the output functions is a string.  Output to
screen ignores this; if outputting to file, this is the file name;
if writing to the database, then this will be the table name.

If outputting to file, the name can be \cinline{NULL}, in which case,
the output will be printed to STDOUT (if you aren't familiar with STDOUT,
then it is the screen), but in the machine-friendly format instead of
the human-friendly form.  This is what you will use if you are using a
command-line \ind{pipe} to send output from an Apophenia-based program
to another program. If your program itself uses a pipe opened via
\cind{fopen}, then the name argument is ignored and output is sent to
the \ci{FILE} pointer in \ci{apop\_opts.output\_pipe}; see page
\pageref{pipeexample} for an example.


File names tend to have periods in them, but periods in table names
produce difficulties.  When printing to a database, the file name thus
has its dots stripped: \cinline{out.put.csv} becomes the table name
\cinline{out\_put}, with the ending elided.

Since the name argument is irrelevant to printing to screen, and
Apophenia endeavors to facilitate laziness, there are functions
corresponding to the above \cinline{apop\_type\_print} functions that will
dump to the screen, by basically just setting the output type to \cinline{'s'}, e.g.:
\ttindex{apop\_vector\_print} 
\ttindex{apop\_matrix\_print}
\ttindex{apop\_data\_print} 
\ttindex{apop\_vector\_show} \ttindex{apop\_matrix\_show}
\ttindex{apop\_data\_show}
\begin{lstlisting}
apop_vector_show(a_vector);
apop_matrix_show(a_matrix);
apop_data_show(data);
\end{lstlisting}

\summary{
\item Most testing routines will put output into an \ci{apop\_data} set.
\item You can pull named items from a data set (such as an estimation
output) using
\ci{apop\_data\_get\_tn}.
\item You can print an object to the screen, the database, or a file using \ci{apop\_...\_print}.
\item For the lazy, you can show an object on the screen using \ci{apop\_...\_show}.
}

\comment{
\section{Histograms} In the chapters that follow, histograms will often
play an important role. The histogram is almost a \ind{probability mass
function}: what percentage of the :



}
\section{Command-line utilities}
Apophenia includes a handful of \ind{com\-mand-line utilities} for
situations where there is no need to write a full-blown C program. For
all of the utilities below, you can use the \binline{-h} parameter to
get detailed instructions (e.g., \binline {apop\_db\_to\_cross\-tab
-h}).

Three are simply for handling SQLite databases.  
\cind{apop\_text\_to\_db} reads a text file into a database table,
\cind{apop\_merge\_dbs} will send tables from one database to
another, and
\cind{apop\_db\_to\_cross\-tab} will take a table from the SQLite
database and produce a crosstab. All of these are simply wrappers for
the corresponding Apophenia functions, as seen in Chapter \ref{sql}.

Finally, for numerical analysis, there is a client/server program,
\binline{apop}.  With the command \binline{apop
start dataset.db}, the program installs itself in memory.
Subsequent commands are clients to this server. For
example, the user may call \binline{apop query\_to\_data agedata
"select * from ages"}, and the server would run the query and create an
\cinline{apop\_data} set named \cinline{agedata}. The data set resides in
memory, waiting for further commands to operate on it.

For example, the following could be run from the command line:
\begin{lstlisting}
apop start dataset.db
apop query_to_data agedata "select * from ages"
apop estimate_OLS est agedata 
apop estimate_print est
apop stop
\end{lstlisting}

Since all of the handling of \cinline{gsl\_matrix}es,
\cinline{apop\_data} sets, and \cinline{apop\_estimate}s is handled by
the server, and all output is plain text, one only needs
basic text-parsing to fold the input and output of these functions into
scripts in languages such as Perl or Python. \index{Perl} \index{Python}

\comment{
\section{\treemarker Modern C} Here are a few notes on the ideas behind
Apophenia's design, which may be of interest to end-users. The executive
summary: the library takes a relatively modern approach to C coding, 
oriented toward facilitating quick statistical queries without hampering
those who need to be more careful in management of data and memory.

\paragraph{Facilitate laziness} First,
default values are oriented toward the lazy. Notably, any
\cinline{model.estimate} function should be able to accept
\cinline{NULL} for the \cinline{estimation\_params} argument. This makes
it easy for those who want quick results to get their results, and those
who want control to specify what they need.

\paragraph{Memory usage} Pointers are good for you, but their management
can be an annoyance. Simply by being in C, Apophenia requires that the
user understand pointers. Many coders who know pointers insist that
most people are too dumb to understand them. But if a person can
understand the concept of projecting a data matrix onto an arbitrary
basis space, he or she probably has enough grey matter to work out that
data and the address of data can be manipulated separately.

However, there are ways to facilitate the process of dealing with memory
allocation and deallocation for the lazy.

The GSL is careful to never allocate large
spans of memory internally, and does not return large blocks of memory
outside of routines with \cinline{alloc} in the name. This imposes work
on the user, however, because so many functions must be preceded with
several lines of memory allocation. Under the \airq{facilitate laziness}
rule, Apophenia takes the opposite approach: it freely allocates memory behind
your back, although this is documented for every function that does so,
and many functions, such as the estimation routines, return potentially
very large blocks of memory. That means that the declaration and the
estimation can be on one line, or the returned value can be nested in
other functions:
\lstset{numbers=left, numberstyle=\scshape}
\begin{lstlisting}
apop_estimate_print(apop_OLS.estimate(data, NULL));
(or)
apop_estimate *e = apop_OLS.estimate(data, NULL);
\end{lstlisting}
\lstset{numbers=none}
Copy commands and tests also return a pointer to newly-allocated data,
again allowing the user to declare and assign on the same line.

\paragraph{Stats scripts are often short}
The reader will note that the first line in the example above
produces a memory leak, since the \cinline{apop\_estimate} can't be
deallocated. But if the whole program is one line, as in the example on
page \pageref{oneliner}, then it doesn't matter. The typical computer
today has around a gigabyte of memory, while many data sets are only a few
hundred observations. That means that if every single allocation in the
analysis results in a memory leak, the memory lost will still be marginal.

\paragraph{Data sets are big, everything else is tiny}
If a million two-by-two matrices are never deallocated, most
users won't even notice the difference.

We can expect that anything to be called in an MLE will be millions of
times, and we can expect that any data set is a million rows, and so we
must be careful with memory for such situations. But for most other
processes, the assumption that there is a billion times more available
memory than the function needs is probably true.


\paragraph{New languages} Computer scientists love writing new
languages.  One author has compiled a list of about
2,500.\footnote{\url{http://people.ku.edu/~nkinners/LangList/Extras/langlist.htm}}
The wisdom of the ages has shown that every language with pretensions
to being the One True Language is eventually superseded by another
language with the same pretensions. There are certainly aspects of
statistics that would benefit from a specialized syntax, but 


The
generally discredited \vocab{Sapir-Whorf hypothesis} claims that how we
think is influenced by the language we speak. 

\paragraph{Model description} Estimation and testing are separate.

}


