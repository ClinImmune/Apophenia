\newif\ifbook \booktrue

%@- This is so lgrind will get along with makeindex.

\ifbook
	\chapter{C} \label{c_crash}
\else
	\long\def\comment#1{}
	\documentclass[12pt]{article}
	\usepackage{amsfonts}  %for mathbb
	\setlength{\topmargin}{-0.5cm}\setlength{\textheight}{8.6in} 
    \setlength{\oddsidemargin}{0in} 
    \setlength{\textwidth}{6.1in} 

	\usepackage[nolineno,noprocindex]{lgrind}

    %indexing:
    \usepackage{multicol, makeidx}
    \makeindex
    \def\ind#1{\index{#1}#1}
    \def\ttind#1{\index{#1@{\tt #1}}{\tt #1}}
    \def\ttindex#1{\index{#1@{\tt #1}}}
    \def\ff#1{#1 {\it ff}} %e.g. \index{pointers|ff}

	\begin{document}
	\title{A crash course in C}
	\author{B Klemens}
	\maketitle


Dear Reader:\\
This is a crash course in C intended for a book on statistics using the
GNU Scientific Library (the GSL).  Since it basically stands alone as a
C tutorial, I offer it to you as such. I haven't edited this from
its chapter form, so it refers to sections outside of this tutorial,
for which I apologize. Although written for researchers programming
statistical tests, it will be useful to any of you who have done some
programming in a scripting language and would like to get to know C.

\vskip 1cm

\section{C}
\fi

\comment{The next bit defines the code figures.
I'm using lgrind now; it's pretty standard.
The first argument to codefig will be
both the name of the file and the label the figure will have; the 
second argument will be caption for the figure.
}

\long\def\codefig#1#2{
	\begin{figure}
	\hrule\vskip4pt
	\input sources/#1.tex
	\hrule

	\caption{#2}\label{#1}
	\end{figure}
}

\long\def\codefigbyinclusion#1#2#3{
	\begin{figure}
	\hrule\vskip4pt
	#1
	\hrule

	\caption{#3}\label{#2}
	\end{figure}
}

\long\def\codefig#1#2{\lagrind{sources/#1.tex}{#2}{#1}}


This chapter will bring you up to speed on C.  
My hope with this chapter is both to discuss where to put your semicolons
and how things are generally done in C. Don't feel compelled to memorize
everything here (using {\tt malloc} three times in a sentence, for
example), since the manual is always there for you to read.  It is not
a comprehensive tutorial: GNU C recognizes 33 key words and this book
will only use 18 of them. For example, we won't be using bit-shifting
operators, so I'm not going to tell you what they are here.

Try typing {\tt C tutorial} into your favorite
search engine; you should get a few hundred very practical tutorials
that start simple and focus on where to put semicolons. This document
complements those practical tutorials by focusing on the structure of
a C program and the logic that motivates that structure. 

The first part (up to Section \ref{pointers})
is all about functions, which are mostly self-contained pieces of code,
but which call and are called by other functions. I will discuss how
those functions are declared and defined, where to put them, and how the
computer goes about keeping track of functions which call functions that
call other functions. The second part, pointers, discusses C's method
of circumventing this neat functional structure by directly handling
parts of the computer's memory without C's automatic memory allocation
and deallocation getting in the way.

\subsection{Text files} C programs are files of text, and all of your work
will be manipulations of text, so it is in your long-run best interst to
get a good \ind{text editor}. At the very least, you will get error messages
listing line numbers, so if your text editor can't tell you which is
line 105, you will need to get a new one.

The two most popular are emacs and vi. Emacs is better for people who
prefer to have everything under one roof, while vi is better for the
minimalists. Both involve a learning curve, meaning that they will be
difficult to use at first, will require reading the manual, and will
in the long run save you hours over using simpler text editors. Some
implementation of both is available for all computer types, and you are
encouraged to start learning one or the other now.

\ifbook \else 
	\input why_c.tex
\fi

\section{Variables have to be declared} \index{declaration!of variables}
You would never use $x$ or $z$ in a paper without first declaring,
say, `let $x \in {\mathbb R}^2$ and $z \in {\mathbb C}$'. You could
leave the reader to guess at what you mean by $x$ by its first use,
but some readers would misunderstand, and your referee would wonder why
you didn't just come out and declare $x$. C is a strict referee, and
requires that you declare the type of every variable before using it.
The delcaration consists of listing the type of the variable and then
the variable name, e.g.:

%\begin{verbatim}
%[
int a_variable, counter=0;
double stuff;
%]
%\end{verbatim}

Your basic options for variable types are {\tt int, float, double,
long double} and {\tt char}. \ttind{int} is for integers;
\ttind{float} is a floating-point number, aka a real number.\footnote{The
computer represents a real using the form $n \times 10^k$, where $n$
represents the number with the decimal point in a fixed location,
and $k$ represents the location of the decimal point.  Multiplying by
ten doesn't change the number $n$, it just causes the decimal point to
float to a different position.} Sometimes you'll need more precision,
and so you have \ttind{double}, which are double-precision real numbers,
and {\tt long double}, which you can think of as quadruple-precision
reals. \ttind{char} are characters.	\ttindex{long}

There are other basic types, which aren't worth caring about.

Notice that we can initialize a few variables of the same type on one
line, and could initialize {\tt counter} to zero right when we declare it. The other
variables (such as {\tt a\_variable}) have unknown value right now. Assume nothing about
what's contained in a declared but uninitialized value.

By the way, notice that the variable names are words, not letters. Using
English variable names is the number one best thing you could do to make your code
readable---imagine how much of your life you've spent flipping back
through journal articles trying to remember what $\mu$, $M$, and $m$
stood for. Why impose that on yourself?

\paragraph{Arrays} An \ind{array} is a numbered list of items of the same type. To declare a list of a hundred
integers, you would use:\\
{\tt int a\_list[100];}\\
Then, to refer to the items of the list, you would use the same square brackets. For example, to assign
the value seven to the last element of the array, you would use: {\tt a\_list[99]= 7;}. Why is 99 the last
element of the list? Because the index is an {\sl offset} from the first element. The first element is
zero items away from itself, so it is {\tt a\_list[0]}, not {\tt a\_list[1]} (which is the second element).
The reasoning behind this system will become evident in the section on pointers.

Arrays of arrays simply require more indices:\\
{\tt int a\_2d\_list[100][100];}\\
and the elements of this array are referred to using the same system: what we generally think of as the
upper-left corner of the array is {\tt a\_2d\_list[0][0]}, down to the lower-right, {\tt a\_2d\_list[99][99]}.

\comment{
How do you know how large an array is? By looking at the declaration. There is no {\tt sizeof(array)}
function to tell you how you had declared the array.
}

\paragraph{Declaring types}\ttindex{typedef} \index{declaration!of types} 
You can define your own
types. For example, these lines will declare two (badly names) triplets
of numbers, {\tt a} and {\tt b}:

%\begin{verbatim}
%[
typedef double triplet[3];
triplet	a, b;
%]
%\end{verbatim}

This is primarily useful for designing
complex data types which are collections of many subelements. \ttindex{struct}
For example:

%\begin{verbatim}
%[
typedef struct complex{
    double real;
    double imaginary;
} complex;

complex a, b;
%]
%\end{verbatim}

You can now use {\tt a.real} or {\tt b.imaginary} to refer to the
appropriate constituents of these complex numbers. Why is the word {\tt
complex} repeated twice? Because you are first declaring a struct of
named {\tt complex}, and then you are defining a type named {\tt
complex} that expands to {\tt struct complex}. This is your first hint that C is
neither Beautiful nor Perfect; just follow the template there and nobody
gets hurt. Here's another example:  

%\begin{verbatim}
%[
typedef struct person{
    char first_name[100], last_name[100];
    float height, weight;
    int age;
} person;

person survey_data[200];
%]
%\end{verbatim}

Structs are syntactically simple, so I have little to say about them here,
but much of good programming goes in to designing structs that make sense
and are a good reflection of reality.  For example, the GSL has defined
a large number of structures for us, such as the {\tt gsl\_matrix}
structure, which provides a few conveniences over using raw arrays as
described above.

\section{C is functional}

That is, every line of your programs will be either a declaration or a
function. The declarations, as you saw, have some arbitrary rules but
are basically easy.  Writing functions that are preeminently useful will
be the focus of the rest of the book.

\paragraph{The form of a function}

A function takes some inputs, does something to them, and returns an
output. In the process, the inputs may also be changed, but that's a
topic we'll return to later.  You'll need to declare the type of all of
the inputs, and since some sort of output is returned, you'll need to
declare the type of the function's output. Figure \ref{dosomething} shows a complete program.

\codefig{dosomething}{A complete program}

All of the details of this program will become clear in due time, but
right now I will focus on the functions.

Every complete program will have a function named \ttind{main}, which
is where the program will begin.  So when this program runs, the computer will
ignore the function {\tt do\_something}, instead starting its work halfway
down this program, where it finds the {\tt main} function head: {\tt int main(void)}. 
It will then start working, first reading the
delarations of {\tt output}, {\tt first}, {\tt second}, and {\tt third}.

Then it will get to the part where it is told to assign something to
{\tt output}, and to do that it will need to evaluate  the meaning of
{\tt do\_something(first, second, third)}. This is a {\em function call}, which commands the program to
halt whatever it's doing and start working on evaluating the function {\tt do\_something}.
The value of {\tt first} = 7.3 will
be plugged in to {\tt a}, and similarly for {\tt b} and {\tt c}. Then
the computer will calculate the value of {\tt d} = 3.3 + 2 = 5.3, and
will then return the value of {\tt a/d} = 7.3/5.3 $\approx 1.337$ to the
main program. The main program can now pick up where it had left off,
by assigning 1.337 to {\tt output}, and then printing this output to the
screen (using the rather ornery line beginning with {\tt printf}).

The most important points to note here are the formats of the function
and its call. The first line of the function itself consists of a type
and then a name and then a list of parameters in parentheses. 
The list of parameters will be a type, an arbitrary name, and a comma
to separate these type-name pairs.  The call simply consists of the
function name followed by the matching number of parameters in parentheses.

There is a lot of consistency-checking going on between the function as written
and the call for the function: there have to be three variables in the parentheses following the name,
and they have to be of the right type. The return value here is going to be assigned to a floating-point
variable, so it too has to be floating-point (barring the exceptions of Section \ref{casting}). Such
consistency-checking is a good thing, and the compiler will either warn you or halt if you fail any
of these checks.

By the way, these consistency checks don't care about the length of
your arrays. In function declarations, you can use {\tt int an\_array[ ]}
with a blank instead of a length. \index{array!declaration} \index{declaration!of arrays}

\paragraph{Declaring a function; black boxes} \index{declaration!of functions}
Since there are all these consistency
checks to be done, the compiler will want to know about the function
before it is called. One way to ensure this is to make sure that
the function always comes before its calls in whatever file you're
working on. This is error-prone and gauche; the better way to do it is
by declaring the function, just as you declare variables before using
them. The declaration looks exactly like the first line of the function
itself, except with a semicolon at the end:

%\begin{verbatim}
%[
float do_something (float a, float b, int c);
%]
%\end{verbatim}

If you have a declaration line at the top of the program file, you don't
have to worry about where the function is actually defined---as
you'll see below, there are some cases where you may not even have the
function's code at all. 

We can think of functions as black boxes, which take some sort of input and produce some sort of output.
The {\tt main} part of the program above didn't care what {\tt do\_something} actually did, and had no
involvement with the function except to dump in inputs and receive an output. As you can see, the
declaration line thus gives 100\% of what the program needs to call and use the function (i.e., the name,
the number and type of inputs, and the type of output). This allows for
a separation of function code and function use we'll make endless use of below.

The function-as-black-box idea also offers some general principles for
writing your code and deciding what gets put into each function. Think
about the individual steps your program will be doing, and put each
of those steps into a function. When writing a function, you
can put the rest of the program out of your mind and focus on making
sure that the black box you're working on does exactly what it should
to produce the right output. When all of the black boxes have been written to
your satisfaction, then writing the main program, no matter how complex,
will simply be a series of function calls.

Next month, when you have to do a similar analysis with slightly different
data, you'll have a set of black boxes to reuse. Since the boxes didn't
depend on the calling program, they can be recycled in your new program
by just including the appropriate headers (plus some details below).

You want your black boxes to be entirely predictable and error-free, and the best
way to do this is to keep them small and autonomous. A function which is more than a
screen-full of text can always be broken down into a few subfunctions,
thus improving the robustness of the code and giving you more black boxes which could be reused in the
future.

\paragraph{The \ttind{return} statement}  There's no need to restrict ourselves to just one {\tt return}
per function, which allows for very useful trickery. First, you may have a function whose type is 
\ttind{void}, meaning that nothing at all will be returned. Such functions will be useful for
side-effects such as changing the values of the inputs (see Section \ref{pointers}) or printing data to
the screen or an external file. You can also have functions which take no inputs, so any
of the following are valid declarations for functions:

%\begin{verbatim}
%[
void do_something(float a);
float do_something_else(void);
float do_something_else();
%]
%\end{verbatim}

The last two are equivalent, but you can't forget the parentheses entirely---then the compiler would
think you're talking about a variable instead of a function.

Alternatively, you may want to have multiple {\tt return}s in the
function. The first one the program hits upon will be the only one that
the program ever sees. For example, If the variable {\tt c} turns out to
be one in the following, then this function will return the ratio of {\tt a} and {\tt d}, and otherwise it
will return their product:

%\begin{verbatim}
%[
float do_something (float a, float b, int c) {
    if (c == 1)
        return a/b;
    else
        return a * b;
}
%]
%\end{verbatim}


\paragraph{The \ttind{main} function}

All programs must have one and only one function named {\tt main},
which is where the program will begin executing. The consistency checks
are now with the operating system that called the program, which will
expect {\tt main} to be declared in one of two forms:

%\begin{verbatim}
%[
int main(void);
int main(int argc, char **argv);
%]
%\end{verbatim}

Without further ado, I will ignore the second form, and will assume that all programs throughout this
book will have a {\tt main} function with no arguments.

The return value of {\tt main} is read by the operating system, and is usually ignored. However, some
use it as a signal:  returning 0 means that all went well, and returning a positive number means that
something went wrong.



\section{Function contents}

So, what should you actually put in those wonderful functions? Well, most of the work you'll be doing are
simple assignments:  \index{arithmetic} \index{assignment|see{=}} \index{=}
%\begin{verbatim}
%[
ratio = a / b; 
%]
%\end{verbatim}
will find the value of {\tt a} divided by {\tt b} and put the value in ratio. Notice that there's a
semicolon at the end of the line; you'll need a semicolon at the end of everything but the few
exceptions I mention below. All of the usual operations work: {\tt + - / *}, and so do some of the more
obscure ones, like {\tt a \% b} for $a$ mod $b$. \index{mod|see{\%}} \index{\%}

\subsection{Incrementing}\index{incrementing} It is incredibly common to have an operation of the form {\tt a = a + b;}---so
common that C has a special syntax for it: {\tt a += b;} This is slightly less readable, but involves less
redundancy. All of the above arithmetic operators can take this form, so each of the following lines show two
equivalent expressions: \\
%[
a -= b;     a = a - b;
a *= b;     a = a * b;
a /= b;     a = a / b;
a %= b;     a = a % b;
%]
\comment{
{\tt a -= b;  \phantom{Hello.}   a = a - b;\\
a *= b;  \phantom{Hello.}  a = a * b;\\
a /= b;  \phantom{Hello.}  a = a / b;\\
a \%= b;  \phantom{Hello.}  a = a \% b;\\}

{\tt a++; /*is equivalent to*/ a = a + 1;\\
a--; /*is equivalent to*/ a = a - 1;}
}
Finally, the most common operation among these is incrementing or decrementing by one, and so C offers the
following syntax for still less typing:\footnote{There is also the pre-increment form, {\tt ++a} and
{\tt --a}. Pre- and post-incrementing differ only when they are being used in situations that are bad style and should
be avoided. Leave these operations on a separate line and stick to whichever form looks nicer to you.} \\
%[
a++; /*is equivalent to*/ a = a + 1;
a--; /*is equivalent to*/ a = a - 1;
%]



\subsection{Conditions} 	
\label{forloops} \index{conditionals} \index{boolean expressions} \index{logical expressions} 
\ttindex{<} \ttindex{>} \ttindex{==}
Another set of operators are comparison and logical operators, such as {\tt (a > b)},
{\tt (a < b)}, or {\tt (a == b)}. All of these evaluate to either a one or a zero, depending on whether the
comparison is true or false. Notice that last one, comparison for equality, involves {\sl two} equals
signs in a row. One equals sign {\tt (a = b)} will assign the value of {\tt b} to the variable {\tt a}, which is not what
you'd intended. gcc will warn you in most of the cases where you're
probably using the wrong one, and you should heed its warnings. `Greater than or equal to' is {\tt (a >=
b)}, and `less than or equal to' is {\tt (a <= b)}.

Logical operations have similar definitions: \ttindex{\&\&} \ttindex{"|"|} \index{and|see{\&\&}}
\index{or|see{$"|"|$}} \index{not|see{"!}} \index{"!}
`And' is {\tt (a \&\& b)}; `or' is {\tt (a || b)}; `not {\tt a}' is {\tt (!a)}.
The `and' and `or' operations have a convenient feature: if {\tt a} is sufficient to determine whether
the entire expression is true, then it won't bother with {\tt b} at all. For example:
%\begin{verbatim}
%[
#include <math.h>    //sqrt
((a < 0) || (sqrt(a) < 3))
%]
%\end{verbatim}
will always work: if {\tt a} is less than zero, then the evaluation of the expression is done (it's true),
so the square root won't have to be calculated, avoiding any
square-root-of-a-negative error. [Notice that the {\tt sqrt()} function
isn't a fundamental part of C---you need to include an external header to get the declaration; see below.]

Why all the parentheses? First, parentheses indicate the order of operations, as they do in pencil-and-paper
math. Since all comparisons evaluate to a zero or a one, both {\tt ( (a > b) || (c > d) )} and 
{\tt (a > (b || c) > d)} make sense to C. You probably meant the first, but unless you have
the order-of-operations table memorized, you won't be sure which of the two C thinks you mean by\\ {\tt
(a > b || c > d)}.

Second, you will occasionally use these in normal arithmetic or an assignment. This line:
\begin{verbatim}
b = c == d;
\end{verbatim}
is correct: if {\tt c} equals {\tt d}, then {\tt b} will be one, otherwise {\tt b} will be zero. But
it's visually a bit off-putting, and in a more complex example gets very confusing. Using
\begin{verbatim}
b = (c == d);
\end{verbatim}
makes this ornery statement a touch more readable.

The primary use of these conditionals is in flow control: causing
the program to repeat some lines until a condition is true, or execute some lines only if a condition is
false.  In all of the cases below, you will need parentheses around the conditions, and if you forget,
you'll get a confusing compiler error.

\subsection{If-then-else statements} Here's the syntax for conditional evaluations: \ttindex{if}

\begin{verbatim}
#include <math.h>
if (a > 0)
    { b = sqrt(a); }
else 
    { b = 0; }
\end{verbatim}
So if {\tt a} is positive, then {\tt b} will be given the value of {\tt a}'s square root; if {\tt a} is
zero or negative, then {\tt b} is given the value zero. Notice all those brackets: the condition to be
evaluated is always in parentheses following the if statement, and there should be curly brackets around
the part that will be evaluated if the condition is true, and around the part that will be evaluated if
the condition is false. You can exclude the curly braces if they surround exactly one line, but this
will at some point confuse you and cause you to regret leaving them out.
You can exclude the `else' part if you don't need it (which is common, and much less likely to confuse you).

Also, notice the semicolons, wich come after every line in the program that isn't flow control. The {\tt
if (a > 0)} statement doesn't do anything by itself, just direct flow, so there must be no semicolon following
it.

\subsection{Loops} There are three types of loops, and they are slightly redundant. The simplest is a while
loop. Here's a while loop to print `hello' on the screen five times: \index{loops} \ttindex{while}

%\begin{verbatim}
%[
#include <stdio.h>
int i = 0;
while (i<5){
    printf("Hello.\n");
    i++;
}
%]
%\end{verbatim}

The interpretation is rather straightforward: while the expression in parentheses is true (musn't forget
the parentheses), execute the instructions in brackets.

Cases like the example above, where we have a counter which we increment, are so common that they have
their own special syntax. The following \index{for@{\tt for}} loop does exactly what the while loop above did:

%\begin{verbatim}
%[
#include <stdio.h>
int i;
for (i=0; i<5; i++){
    printf("Hello.\n");
}
%]
%\end{verbatim}

Comparison with the above tells us when the three subelements in the parentheses are evaluated: the first
part is evaluated before the loop runs; the second part is evaluated after each iteration of the loop; the
third part is evaluated at the end of each loop---effectively just before the second part is evaluated.
This is certainly counterintuitive, but after the section on arrays, you'll become very used to the form.

Finally, if you want to guarantee that the loop will run at least once, you can use a \ttind{do-while} loop (with a semicolon after the {\tt while}):

%\begin{verbatim}
%[
#include <stdio.h>
int i = 0;
do {
    printf("Hello.\n");
    i++;
} while (i<5);
%]
%\end{verbatim} 

\subsection{Comments} \index{commenting code|(}
Put a long block of comments 
at the head of a file and at the head of each function to describe what
the file or function does, using complete sentences.
\begin{verbatim}
/* Long comments begin with a slash-star,
   continue as long as you want, and end 
   at the first star-slash:   
   */
\end{verbatim}
The primary audience of your comment should be you, six months from
now. When you're shopping for black boxes to plug in to your next project,
or reauditing your data after the referee finally got the paper back
to you, a note to self at the head of each function will pay immense
dividends.


The stars and slashes are also useful for `commenting out' code. If you'd
like to temporarily remove a few lines from your program to see what'd
happen, but don't want to delete them entirely, simply put a {\tt /*}
and a {\tt */} around the code, and the compiler will think it's a
comment and ignore it.

However, there is a slight problem with this approach: what if there's a comment in what you'd just
commented out? You'll have a sequence like this in your code: 
%\begin{verbatim}
%[
/* line A; 
   /* line B */ 
   line C; 
*/
%]
%\end{verbatim}
We had hoped that all three lines would be commented out now, but the compiler will ignore everything
from the first {\tt /*} until it sees the first {\tt */}. That means Line A and Line B will be ignored,
but {\tt line C; */} will be read as code---and malformed code at that.

You will always need to watch out for this when commenting out large blocks of code. But for small
blocks, there's another syntax for comments:
\begin{verbatim}
this_is_code;    //Everything on a line after two slashes 
                 //will be ignored.
                 //Use this form for short comments.
\end{verbatim}
This is good for commenting individual lines of code which deserve a note.\footnote{The two-slash
comment style is actually not C, it's C$^{++}$. But it's so useful that gcc accepts it without so much as
a warning. If you're not using gcc, you may have to use the {\tt /*} --- {\tt */} format for comments
everywhere.}\index{commenting code|)}

\subsection{Type casting}\label{casting} \index{casting|see{type casting}} \index{type!casting|(} An arithmetic operation on two integers returns an integer. This works fine for
addition, subtraction, and multiplication, but is a horrible inconvenience for division.\\
%[
int num = 7;
int den = 2;
float ratio = num / den;
%]
In this example, {\tt ratio} will equal {\tt 3.0}, which is probably not what you had intended. 
First, since {\tt num} and {\tt den} are both integers, the operation
{\tt num / den} will also produce an integer: the actual ratio with the
fractional part dropped.

Then, the compiler will assign this to {\tt ratio}. This is a switch in type: we just got an integer (3)
and are assigning it to a floating-point variable. Clearly, this assignment is trivial and not a problem.
But going the other way will produce problems, since everything after the decimal point will be
dropped.
Also, the range of {\tt float}s, {\tt double}s, and {\tt int}s don't match, so you may get unpredictable
results with large numbers even when there is nothing after the decimal point.


If, despite all these warnings, you're confident that you want to assign a variable of one type
to a variable of another, then you can do so by putting the type to
re-cast the variable into in parentheses before the variable name. For
example, {\tt (int) ratio} will cast what was a floating-point number to an integer. 
If you want to assign a floating-point real to an integer for some reason, then you should explicitly tell
the compiler that you meant to do this by making the cast yourself: using the declarations above, 
you could assign {\tt num = (int) ratio;}, for example. 

This solves the division-by-integers problem: \\
{\tt ratio = (float) num / (float) den;}\\
does the division of two real numbers, which will produce a real output: {\tt ratio} will equal 3.5, as we
had expected.


One use for the two types of division is to check whether a variable is evenly divisible by a number. Here
is a function that does so:\footnote{In practice, you can check evenness
with {\tt GSL\_IS\_ODD}, or {\tt GSL\_IS\_EVEN}:\\ 
{\tt \#include $<$gsl/gsl\_math.h$>$}\\
if (GSL\_IS\_EVEN(an\_integer))\\
\phantom{hello.}{\tt do\_something();}
}

%\begin{verbatim}
%[
int is_even(int number){
/* Return one if number is even, zero if number is odd.  */
   if ( counter/2 == (float) counter / 2.0 )
        return 1;
   else 
        return 0;
}
%]
%\end{verbatim}
Notice that 2 is an {\tt int}, while 2.0 is a {\tt float}. This provides
a relatively painless way to solve the problem that {\tt 7/2=3}: just
remember to always include a decimal point in your constants, because
{\tt 7.0/2.0 = 3.5}, as intended. Get into this habit now,
because unintended roundoff is a very hard-to-debug error.

Finally, note that when casting from {\tt float} to {\tt int}, numbers
are truncated, not rounded.  The following function uses type casting
to correctly round off numbers:

%\begin{verbatim}
%[
int round(float unrounded){
/* Input a floating-point number and output the number
   rounded to the nearest integer.  */

    if (unrounded > 0)
         return (int) (unrounded + 0.5);
    else
         return (int) (unrounded - 0.5);
}
%]
%\end{verbatim}
\index{type!casting|)}   



\subsection{Frames and scope} \index{frames|(} \index{scope|(}
When a function is called, the computer creates a
{\sl frame} for that function. Into that frame are placed any variables
that are declared at the top of the file in which the function is defined,
including those in files which were {\tt \#include}d (see below); and copies of
variables which are passed as arguments. 

The function is then run, using the variables it has in that frame,
blithely ignorant of the rest of the program. It does its math, making a
note of the return value it calculates (if any), and then destroys itself
entirely, erasing all of the variables created in the frame and copies
of variables which had been put in to the frame. Variables which were not
passed as an arugment but which were put in the frame anyway ({\sl global
variables}; see below) come out unscathed, as does the return value, which
is sent back to the function which had called the frame into existence.

One way to think about this is in terms of a stack of frames. At the
base of the stack is the {\tt main} function, which is always the first
called. When it calls the {\tt do\_something} function, then a new frame
is created and is put on top of the stack, and if {\tt do\_something}
were to call the {\tt is\_even} function, then that function's frame would be laid on top
of the frame for {\tt do\_something}. All processing happens exclusively in
the topmost function on the stack---the rest of the program might as
well not exist. When the topmost frame is done, and the frame and its
internal variables are destroyed, then the calling function is back at
the top of the stack, and can continue to work. Eventually, the {\tt
main} function will finish its work, and will be destroyed, leaving an
empty stack and a finished program.

The creation and destruction of frames, and all of the associated
memory allocation and deallocation, are entirely the responsibility of
the computer.  \index{frames|)} 

\paragraph{Scope}	\label{scope}

When one function is running, only the variables in that frame are
`visible', and all of the variables in the rest of the program are 
dormant.  This is a good thing, since you certainly don't want to have
to always bear in mind the current state of  all the variables in your program,
the GSL, the standard library, and who knows what else.

A variable's {\sl scope} is the set of functions which can see the
variable. A variable declared inside a function is only visible inside
that function.  If a variable is declared at the top of a file, then
that variable is {\tt global} to the file, and any function in that
file can see that variable. If declared in a header file (see below),
then any function in a file which {\tt \#include}s that header  can see
the variable.\footnote{The curly braces, {\tt \{} and {\tt \}}, can be
used to define a smaller level of scope: variables defined just after a
{\tt \{} have scope until the ending {\tt \}} and no further. This is
generally bad form: your code will be more readable if you just move
that subsection to a separate file.}

The strategy behind deciding on the scope of a variable is
to keep it as small as possible. If only one function uses a variable,
then by all means declare the variable inside the function.
If a variable is used by only a few functions,
then declare the variable in the {\tt main} function and pass it as an
argument to the functions which use it. If a variable is used throughout
a single file, then let it be globally available throughout the file, by
putting it at the top of the file, outside all the function bodies. Finally,
if a variable is used throughout all parts of the program, then declare it in
the header file, so that it will be globally available in every
file which {\tt \#include}s that header file (see below).\footnote{If
you are familiar with object-oriented languages, note that C can effect
much of the encapsulation of those languages using separate files. Think
of one file as an object: all variables declared inside the file are
private, and all those declared in the header file are public. Similarly,
only those functions which have a declaration in the header file can be
called outside of the file.}

There is often the temptation to declare every variable as global, and
just not worry about scope issues. This makes maintaining and writing
the code difficult: are you sure a tweak you made to the black box named
{\tt function\_a} won't change the workings inside the black box named
{\tt function\_b}? Next month, when you want to use {\tt function\_a}
in a new program you've just written, you'll have to verify that nothing
in the rest of the program affects it, so what could have been a question
of just cutting and pasting a black box from one file to another has
now become an involved analysis of the original program.  \index{scope|)}

\paragraph{Static variables} There is one exception to the rule that
all local variables are destroyed: you can define a {\tt static}
variable. When the function's frame is destroyed, the program makes a
note of the value of the  static variable, and when the function is called
again, the static variable will start off with the same value
as before. This provides continuity within a function, but the scope
of the variable remains restricted to the function alone.

Static variable declarations look just like other declarations but with
the word \ttind{static} before them. You can also put an initialization on
the declaration line, which will only be taken into consideration the
first time the variable is used. Here is a function to enter a hundred
people into a database:
%\begin{verbatim}
%[

//Here is an abbreviated person type
typedef struct ppp{
    char name[100];
} person;

//Here is the global variable which will be storing values:
person survey_data[100];

//Here is the function which will add names to the survey_data array:
void add_a_person(char *name){
    static int count_so_far = 0;
    survey_data[count_so_far] = name;
    count_so_far++;
}
%]
%\end{verbatim}

The first time this function is called, {\tt count\_so\_far} will be initialized
at zero, the name passed in will be put in {\tt survey\_data[0]}, and {\tt
count\_so\_far} will be incremented to one. The second time the function is
called, the program will remember that {\tt count\_so\_far} is one, and will thus
put the second name in {\tt survey\_data[1]}, where we would want it to be.


\paragraph{Call-by-value} \index{call-by-value}
A common error is to forget that global variables are put in all function frames,
but only {\sl copies} of the variables in the function's
argument list are put in the frame.  Figure \ref{callbyval} shows a sample program.

\codefig{callbyval}{A function using call-by-value}

When the {\tt doubling} function is called, it puts a copy of {\tt a} into {\tt a\_c} and a copy of {\tt b}
into {\tt b\_c}. It gives {\tt a\_c} the value of twice {\tt b\_c} and the returns that value. But {\tt a}
itself didn't change at all, even though {\tt a\_c} did change. Meanwhile, {\tt int globe} is not a copy of
itself, but the real thing, so when it is changed inside the function, it changes globally.
Here's the output you'd get:
%\begin{verbatim}
%[
doubling returns 4
a= 1
globe= 4
%]
%\end{verbatim}

This may make global variables tempting to you, but resist. Section \ref{pointers} will give a better
alternative.

\section{Compiling and running}

Once we've written a complete program, it'd be nice to know how to run the
thing. You do so by processing the text you've just written with a
preprocessor, a compiler, and a linker. These subprograms are all rolled
into one program, typically just called `the compiler', and the entire
process is colloquially referred to as `compilation'. The compiler I use
throughout this book is the GCC, the GNU Compiler Collection, which will
compile C as well as a few other languages. I'll use {\tt gcc} (herein
lower case to refer to the command you'll be typing) because it's probably
the most universally available program in the world today---and it's free.


\subsection{Getting it} If you are using a UNIX-like system, you probably already have \ttind{gcc} on your
computer.

Mac and Windows users will need to download a copy; see {\tt gcc.gnu.org}
for details. Windows users have two options: one is to get Mingw,
which provides a compiler and not much else. You can also try Dev-C++, which is an integrated development
environment (an IDE) which gives you a familiar set of windows in which to write, compile, and debug your
programs. A copy is currently availaable at {\tt http://www.bloodshed.net/dev/devcpp.html}.
Many other IDEs are available, for any graphically-oriented operating system, of varying quality.

The other option is to get Cygwin, from {\tt cygwin.com}. Cygwin is
free, has a pleasant installation program, and provides an entire
UNIX subsystem, with the attendant compilers, editors, and so on. Be
sure to select gcc and the GSL under the development subsection in the
installation.

Mac OS X users will be using the terminal to do most of the work below.

Herein, I will assume that you have a working copy of {\tt gcc}, {\tt
gdb}, et cetera, and it is on the search path for executables on your
system. If this is not the case, then abundant help is available, either
from your local computer guru or from your favorite search engine.

\paragraph{The \ind{libraries}} This book makes heavy use of the GNU Scientific Library and the SQLite library.
Both of these are available online (ask your search engine for the location) in various formats. For Linux users,
there are RPMs available. The GSL is one of the packages available in the Cygwin installation. If no easy
package is available for your system, then you will need to compile the program from source. Fortunately,
you have a working copy of {\tt gcc} on your system, so this is easy. The steps are:\\
$\bullet$ Download the source code, and unpack it, usually with {\tt tar xvzf package.tgz} .\\
$\bullet$ Go in to the directory which you just unpacked ({\tt cd directory\_name}).\\
$\bullet$ Run {\tt ./configure; make; make install} to configure and install the library.\\
$\bullet$ On some systems, you will need to modify the LIBPATH environment variable. 
On a UNIX-like system, you will need something like\\ {\tt 
        LD\_LIBRARY\_PATH=/usr/local/lib:\$\$LD\_LIBRARY\_PATH} in your {\tt .bashrc} file.

\subsection{Compiling}	\index{compilation} 

\paragraph{A brief conceptual overview} The best thing about C is that most
of the functions you may need to write have already been written. The
process of compilation is designed to make it as easy as possible for
you to include these existing functions in your own code.

Say that somebody has written a file named {\tt gsl\_matrix.c} which
includes a set of black-box functions to handle matrices.
As discussed above,
that file will include declarations (of types, variables, and functions)
and the definition of the functions themselves. The custom is to separate
the two: all of the declarations will be put in a {\sl \ind{header file}}
named {\tt gsl\_matrix.h}, and all of the functions will be translated
into a machine-readable {\sl \ind{object file}}, {\tt gsl\_matrix.o}.

Then, you the user will include the header file in your program. You can then
use the functions, types, and variables defined therein with abandon.
You will then be able to compile your program into its own object file,
and all of the consistency-checking will come out OK, because all of your
terms will have been properly defined either in your program or in the
header file. Finally, the program will link together your object file,
which gives machine-code for your own functions, to {\tt gsl\_matrix.o},
which gives machine code for the matrix functions. After everything is
tied together, you'll have an executable program which the machine can
understand and run.

Notice that you didn't even need {\tt gsl\_matrix.c} to make this work;
on many systems, the source code for the libraries you call
won't even be on the system. All you need are the 
header files to write and compile your code, and the
object files to link to.



\paragraph{What to type}
The typical method of compiling is:

\begin{verbatim}
gcc  -g -Wall file1.c file2.c -lgsl -o run_me
\end{verbatim}

The program is {\tt gcc}; it includes code that you wrote in {\tt file1.c} and {\tt file2.c}; it
includes the library {\tt gsl} (which we'll use throughout this book); and it will output an executable
program named {\tt run\_me}. You can then type {\tt ./run\_me} to execute the program you just wrote. 

The {\tt -g} adds \ind{debugging} symbols; see below.  The {\tt -Wall} line
indicates that the compiler should give you warnings about code that
may not be what you'd meant. You should always run gcc with this option,
and you should always heed its warnings, since it recognizes errors with
uncanny precision.

This is a lot to type, so there is a separate program, {\tt make},
which is designed to facilitate compiling. After setting up a Makefile
to describe your project, you'll be able to type in {\tt make} instead
of the mess above. See Section \ref{make} for details.

\paragraph{The output} One of two things will happen. The most likely is that you have an error somewhere
in your code, and the compiler will tell you so. Sometimes, a short program will produce more errors than
there are lines of code, which can be disheartening. But just begin with the first error in the list, and
go from there---often subsequent errors are bogus side-effects of the first error. Multiple windows come in handy here:
put your code in one window and compile in another, so you can see the errors and source code at the same time.

The other possibility is that there were no errors at all. The compiler will not give you positive feedback
in this case, instead simply returning you to the command prompt. But if you then look in your directory
(with {\tt ls}), then you'll see that you now have your original {\tt .c}
files, but also new files with a {\tt .o} ending and the {\tt run\_me}
executable program. You can type {\tt ./run\_me} and see your program
work. [Unless you're a star programmer, it will still somehow fail. To
continue fixing it, you will need to run the program under the debugger;
see section \ref{debug}.]

\paragraph{The preprocessing step}
As noted above, {\tt gcc} takes your code through three steps.
The first step is \ind{preprocessing},
which does nothing but take text you wrote and convert it into more text.

The preprocessor has a dozen things it can do, but you will basically only care about one of them: \ttind{\#include}. 
[The runner-up is {\tt \#define}, which is discussed on page \pageref{macros}.]

When the preprocessor is processing the file {\tt main.c} and sees the line
%\begin{verbatim}
%[
#include "a_file.h"
%]
%\end{verbatim}
it finds the file {\tt a\_file.h} and dumps the entirety of the file,
verbatim, into {\tt main.c} at that point in the file. Of course, you'll
never see this (unless you run {\tt gcc} with the {\tt -E} flag); the
preprocessor just passes the expanded code to the compiler.

The most common use for this feature (and I encourage the reader to
only use it for this purpose) is to include declarations of variables
and functions. The custom is to put all of the delcarations for {\tt some\_functions.c} in a {\sl \ind{header file}}, to be named {\tt some\_functions.h}.
The motivation for this will be discussed further in the context of the
linking step below.  

All libraries that you will download from elsewhere will include a header file.
To include it, you'll need to put a line like this at the top of your C file:
%\begin{verbatim}
%[
#include <gsl/gsl_matrix.h>
%]
%\end{verbatim}
The angle-brackets tell the compiler that instead of looking in the
current directory, as it did for {\tt "a\_file.h"} above, it should
look in the standard library path. Generally, use {\tt "my\_file.h"} for
header files you've written and {\tt <their\_file.h>} for header files installed elsewhere
in your system.

Every snippet of code in this book has an include line if it would be
necessary to run the program.  However, this didactic convenience is
terrible style: you should have all of your headers at the top of the
file, and although it doesn't hurt to include a header file many times,
there's certainly no benefit to doing so.


\paragraph{The compilation step} 
The \ind{compilation}
stage consists of taking each {\tt .c} file in turn and writing
a machine-readable object file: {\tt file1.c} will result in {\tt
file1.o}, and {\tt file2.c} will compile to {\tt file2.o}. These \index{object files} are
self-encapsulated files which include a table of all of the symbols
declared in that file (functions, variables, and types), and what (most of) those
symbols mean---the actual code which embodies these functions, variables,
and types, translated into a form the computer can interpret.

At this point, the compiler has run consistency checks on each file separately,
and will complain if any of them fail. That is, if you call a function,
there has to be a declaration (or the function itself) somewhere in the
file that tells the compiler what that function should look like. But 
given that information, it doesn't need the function itself in order to
do the consistency checks and compilation. This allows you to declare
and call functions which are not in your code. You'll simply have a
dutiful machine-readable notice in the middle of the function you wrote:
`At this point, you'll need to run the {\tt do\_something} function,
sending it the values {\tt first}, {\tt second}, and {\tt third}, and
you'll get a {\tt float} back from the function in return'. This is
all the information {\tt gcc} needs to compile a consistent object file---but
clearly, if the program is to run, it will need to include the actual
instructions embodied in the symbol {\tt do\_something}.

\paragraph{The \ind{linking} step}
The next step in the process is linking, in which the program takes all
of those declarations and finds the actual objects to which they refer. It
is the process of reconciling all of the symbol tables to ensure that when
{\tt file1.c} promises that there is a function named {\tt do\_something}
that will return a floating-point real number, that {\tt do\_something}
is actually defined,  probably in {\tt file2.c}.

Alternatively, the function you call could be in a library written by
somebody else.  For example, the {\tt -lgsl} flag tells the compiler that
you may be calling functions in the GSL library, so if it sees a function
declared in your code but can't find the function's definition in your
code, then the linker should check the GSL library for the definition.


\index{include@{\tt include}|see{{\tt {\#include}}}}
\paragraph{Finding files to include}
There are a wealth of pre-compiled object files in existence already,
some available online and some on your hard drive right now.  The first
part of the art of C programming is knowing what files are out there that have
functions that will facilitate your work. There
are a few sources of information which will be of primary utility to you
(besides this book, of course).

The first is the standard library. Being standard, this was
installed on your computer along with the compiler. You may have the
documentation on your hard drive: try {\tt info glibc}. If this doesn't
work, a search for GNU C library documentation should find you a copy
online. It's worth giving the documentation a skim so you know which wheels not to reinvent.

The second is the GNU/UNESCO website, which holds a huge array
of libraries, all of which are free for download. Go to {\tt
http://www.gnu.org}, click the `download' link, and then the `software
libraries' link. You'll find a library for almost anything you would
ever need.

The second part of the art of C programming is taking into account that
the functions you write will be useful for later on. Your work will often
go along the same lines in all of your projects: getting data from the
same sources, or consistently searching for the same effect in a
variety of places. Bear this in mind as you write functions, so that they
are as general and self-contained as possible, so you'll be able to call
them from your next project. The wisdom of the ages shows that if you're
careful writing your first few programs, then your later programs will
take very little time to get up, running, and doing exactly what you want.

Thus, you may want to start writing your own libraries. It's a simple
process: simply put all of your functions relating to a certain topic
into a file named {\tt topic.c}, and put the useful declarations into a separate header file named {\tt
topic.h}. 


\paragraph{C files as modules}
Recall that a variable which is not declared inside a function has scope for the rest of the file in
which it was declared. That means that if a variable is declared in {\tt normit.c}, then all the variables
inside that file can use the variable, but to other {\tt .c} files, the variable is
a private, hidden part of {\tt normit.c}. Of course, the functions and variables of {\tt normit.c} have
to interact with the rest of the world somehow, so those variables and functions which should be
publically avaliable should be put in a file {\tt normit.h}. You'll {\tt \#include "normit.h"} at the head
of {\tt normit.c}, and also at the head of all other files which may want to use the tools included in
the {\tt normit.c} file.

Just as we could take a function as a black box, whose internal workings
we don't care about, we can now take {\tt normit.c} as a black box,
whose only visible parts are those listed in {\tt normit.h}. For the functions, the public part is the
header line listing the type of the variable and its inputs; for the C file module, the public part is
the header file. 

As noted above, modules and functions are most effective and  reuseable when as few
subparts are visible as possible; bear this in mind when deciding whether to put a variable or
function's declaration in the header file, where it will be public, or at the top of the code file,
where it will be private, internal workings.\comment{C$^{++}$ programmers will recognize this setup as
very analagous to that of an object: in a simple sense, both C modules and C$^{++}$ objects are a level
of intermediate scope between the global level and the functional level. Here is an approximate translation from
object-oriented language to C implementation in more detail:\\
object	= code file\\
private var/function	=var/function declared inside {\tt module.c}\\
public var/function	=var/function declared inside {\tt module.h}\\
friend			=module which includes {\tt module.c} instead of {\tt module.h}\\
}

 \label{prepointers}\section{Pointers} \label{pointers} \index{pointers|ff}

Pointers are the thing that really distinguishes C from scripting
languages and stats packages. They are also what makes C fast and
flexible. If you've never dealt with them before, you will spent some
quantity of time puzzling over them, and then you'll wonder what all the
fuss is about. 

They are used to do two things in C: handle references and implement arrays.

\paragraph{More on \ind{frames}: \ind{call-by-reference} v \ind{call-by-value}}

As discussed above,
when you call a function, the computer sets up a separate frame
for the function. Into that frame, it puts {\it copies} of all of the
variables that have been passed to the function. The function then does its
thing and produces a return value. Then, the entire frame is destroyed,
including all of the copies of variables therein. A copy of the return value gets
sent back to the main program, and that's all that remains of the defunct
frame. 

This setup, known as call-by-value since only values are passed to the
function, has good and bad features. The main good feature is that you
don't have to coddle your variables in the function: you can tear them to
pieces, knowing that you're not losing any data outside the function. It
allows for a more stable implementation of the programming language. But if {\tt a}
is an array of ten thousand {\tt double}s, then making a copy every time
you call a common function will take a noticeable amount of time. Also,
you'll often want your function to change the variables that get
sent to it.

This is where pointers come in. A pointer is the address of a piece of
data. After all, when you declare {\tt int a}, then the computer is
going to put {\tt a} somewhere in memory. Perhaps with a microscope,
you could even find it: there on the third chip, two hundred transistors
from the bottom. You could point to it.

Of course, the computer, lacking a finger with which to point, will use
an illegible hexadecimal address, but you will never have to deal with
the hexadecimal directly, and lose nothing by ignoring the implementation
and thinking of pointers as just a very precise finger.

This fixes the problem of changing variables within a function. The
trick is that instead of sending the function a copy of the variable,
we send in a copy of a finger pointing to the variable. There are now
two fingers, original and copy, pointing to the same spot. The
function can then find the data to which its copy of a finger is pointing,
and make modifications there; when the copy of a finger is removed on the
function's exit, the changes made to the data aren't undone.
The original finger (which hasn't changed and is pointing to the same
place it was always pointing to) will now be pointing to a modified value.
Figure \ref{callbyref} gives a sample program which does this.

\codefig{callbyref}{Call-by-reference}

You can see that the code has stars everywhere. These
indicate that there are pointers involved, but their use is a bit inconsistent.
For full clarity, here are the rules:
\begin{itemize}
\item To declare a pointer to an integer, use {\tt int * a}.
\item Outside the declarations, to refer to the integer being pointed to, use {\tt * a}.
\item Outside the declarations, to refer to the pointer itself, use {\tt a}.
\end{itemize}
If this seems sensible to you, great. If it doesn't, memorize it. 

Notice also that spaces don't matter, so use whichever of {\tt int *
a}, {\tt int* a}, or {\tt int *a} you like best. The star also still means multiply; if you think
there's ambiguity, use parentheses.

Returning to the code in Figure \ref{callbyref}, in the {\tt main} function, {\tt a} is a pointer,
the address of an integer, as indicated by the star in its
declaration. To print the integer being pointed to, we use {\tt *a}. 

When we declare {\tt int * a\_c} in the definition of the doubling
function, then this means that the variable {\tt *a\_c} will be an
integer, so by inference, {\tt a\_c} by itself is a pointer to an
integer.\footnote{Referring to the number the pointer points to is
known as {\sl dereferencing}.\index{dereferencing} I won't use the term, but some error
messages will.}

Now for the call-by-reference trick.
When the call to {\tt doubling} is made, we pass {\tt a}, which is a
pointer, not an integer. The computer builds itself a frame, using a copy
of {\tt a}---that is, a copy of the address of an integer. Both {\tt a} (in the {\tt main} frame) 
and {\tt a\_c} (in the {\tt doubling} frame) now point to the same piece of data.
The line {\tt
*a\_c = b\_c * 2} tells the computer to go to the address {\tt a\_c}, and put into that slot of
memory the value {\tt b\_c * 2}. When the frame is destroyed (and {\tt
a\_c} goes with it), this won't be undone: that slot of memory will still
hold the value {\tt b\_c * 2}.  So the output to this program would be:
\begin{verbatim} 
4 
4 
\end{verbatim} 
because {\tt *a}---the integer {\tt a} points to---has changed as a
side-effect to calling the {\tt doubling} function.

\paragraph{Dealing with memory} Now for the initialization of the pointer:\\ \index{declaration!of pointers}
\index{pointers!declaration}
{\tt int *a =} {\tt malloc(sizeof(int));}.\\
Malloc is short for `memory allocate'. Just as we have no idea what
is in an {\tt int} variable before we declare it, we have no idea what address {\tt a} points to until we
initialize it. The function {\tt malloc()} will do the low-level work of finding a free slot of memory,
claiming it so nothing else on the computer uses it, and returning that address. We send to \ttind{malloc}
the quantity of memory we need, which in this case is the size of one integer: {\tt
sizeof(int)}. Every use of the {\tt *alloc} functions discussed here will have a {\tt sizeof} somewhere in
the argument.\ttindex{sizeof}

This is where the finger metaphor breaks down a little, since there are actually three characteristics
to a given pointer: the location (where the finger is pointing), the type (here, {\tt int}), and the
amount of memory which has been reserved for the pointer ({\tt sizeof(int)} bytes---enough room for one
integer). The location is up to the computer---you should never have
to look at hexadecimal addresses. But you need to bear in mind the type
and size of your pointer. If you treat the data pointed to by an {\tt
int} pointer as if it's pointing to a {\tt float}, then bad things will
happen; if you put twenty variables into a space allocated for fifteen,
then bad things will happen. See below.

By the way, notice that {\tt int *a = 7} will fail---the initialization on the declaration line is for
the pointer, not the value the pointer holds. One convenient function which partly helps with this is
\ttind{calloc}:
%\begin{verbatim}
%[
#include <malloc.h>  //calloc
    int *a = calloc(1, sizeof(int));
%]
%\end{verbatim}
which you can read as `clear and allocate': it will run {\tt malloc}
and return the appropriate address, and will also set everything in
that space to zero, running {\tt *a = 0} for you. Notice the syntax,
which requires that we explicitly state that we want one space, the
size of an integer. You need to give more information than {\tt malloc}
because the process of putting a zero in a {\tt float} pointer may be
different from putting a zero in a {\tt int} pointer. Thus {\tt
calloc} requires two arguments: {\tt
calloc(number\_of\_elements\_i\_want, sizeof(type\_of\_elements))}.

Finally, both allocation and de-allocation are now your
responsibility. The de-allocation comes simply by calling {\tt free(a)} \ttindex{free}
when you're done with the pointer {\tt a}. You don't actually need to free variables at the end of {\tt
main}, because when you leave your program the operating system will clean up for you, but being explicit
about when you de-allocate is good form.

\paragraph{The joy of segfaults} \index{segmentation fault} \index{segfault|see{segmentation fault}}
When you initialize a non-pointer variable, say {\tt int a}, then all of
the care and feeding of that variable is the compiler's responsibility:
it has to allocate memory for {\tt a}, check whether the variable is
in scope, and it has to free the memory when the frame that {\tt a}
was declared in is destroyed.

When you initalize a pointer, you bear full responsibility for the area
of memory you are about to point to. You have to allocate and de-allocate
it, but since C won't deallocate the memory when leaving a frame, you
can use this to your advantage, as above.

But what happens when you fail in your duties and forget to allocate
memory? One possibility is that {\tt a} happens to point to a space
which has something that can be interpreted as an integer. When you refer
to {\tt *a}, the computer will search the location {\tt a}
points to, return whatever junk is found there, and will process that
junk like nothing ever happened. Alternatively, {\tt a} could be the
{\sl null pointer}, \index{pointers!null} which by definition points to nothing, in which
case the program will immediately halt with the complaint `attempting to
dereference a null pointer'. Finally, {\tt a} could point to an area of
protected memory, such as the memory that's being used for the operating
system or your dissertation. In this case, referring to {\tt *a} will
halt the program with the greatest of haste, before it destroys something
valuable. This is a {\sl segmentation fault}, since you attempted to refer
to memory outside of the segment that had been allocated for your program.

A segfault means that you mis-coded something, and 
is by far the clearest way for the computer to tell you so. Some higher level
programs brag about how they never segfault: when you refer to something
outside of what you'd expected, they will catch it and usually just
allocate that space for you, basically running {\tt calloc} behind your
back. Then the program will give you an answer which may or may not look
correct, and which you may or may not notice before you present to the
grantmaking board. 

\section{The debugger} \index{debugging|(} \index{gdb@{\tt gdb}|see{debugging}} \label{debug}
Which brings us to the debugger. The debugger will run the program for
you, taking notes on the variables therein. When your program segfaults,
the debugger will let you look at where you
are in the program and see the value of every variable declared at that
spot. This beats inserting little {\tt print} statements all over your
code by a mile [1.6 km].

To debug the program {\tt run\_me} under the debugger, type {\tt gdb
run\_me} at the command line.  You'll be given the gdb prompt.

If you know the program will segfault, then at this point, just run the program
by typing {\tt run}, and wait for it to break. When it does, you'll be
returned to gdb's prompt, so you can interrogate the program.

The first thing you'll want to know is where you are in the program. You
can do this with the {\tt backtrace} command, which you can abbreviate to
either {\tt bt} or {\tt where}. It will show you the stack of function
calls that were pending when the program stopped.  The first, frame
\#0, is always {\tt main}, where the program started. If {\tt
main} called another function, then that will be frame \#1, et cetera.
Often, your program will break somewhere in the internals of a piece of
code you didn't write, such as in a call to {\tt mallopt}. Ignore those:
you did not find a bug in {\tt mallopt}. Find the last line that's in
the code that you wrote.

At this point, the best thing to do is look at a listing of your code
in another window and look at the line the debugger pointed out. Often,
knowing which line is wrong is enough to make the error painfully obvious.

If the error is still not evident, then go back to the debugger and look
at the variables. You need to be aware of which frame you're working in,
so you know which set of variables you have at your disposal.  You
will default to the last frame in the stack; to change to frame number
three, give the command {\tt frame 3}.

Once you're in the frame you want, get info about the variables. You can
get a list of the local variables using {\tt info locals}. You can get
information about the arguments to the function using {\tt info args}
(though this information is already in the frame description). Or, you
can print any variable that you think may be in the frame using {\tt
print var\_name}, or more briefly, {\tt p var\_name}. 

GDB has its own syntax for viewing the contents of an array. If you'd
like to see the first five elements of the array {\tt items}, then use:
{\tt p *items@5}.

Sometimes, you will swear up and down that the line the program segfaulted on is
entirely correct; in that case, the memory had probably been corrupted earlier and
you'll need to use {\tt valgrind} (see page \pageref{valgrind}) to find the error.

\paragraph{Breaking the program} If your program is doing things wrong but isn't kind
enough to segfault, then you'll need to find places to halt the program
yourself. Do this with the {\tt break} command. For a program with only
one file of code, simply give a line number: {\tt break 35}. With many
files, you may need to specify a file name: {\tt break file2.c:35}. You
may also want the program to only break under certain conditons, such
as when an iterator reaches 10,000. GDB lets you do this by specifying
conditions: {\tt break 35 if counter>10000}.

All breakpoints are given a number, which can be listed by giving the
plain command {\tt break}. You can delete breakpoint number three with
the command {\tt del 3}.

Once you've set the breakpoints, {\tt run} will run the program until it
reaches a breakpoint, and then you can apply the interrogation techniques
above. You may want to carefully step through from there; {\tt s}
will step to the next line, which could mean backing up in the current
function or going to a subfunction. Alternatively, {\tt next} or {\tt
n} will step through the function (which may involve backtracking) but
will run without stopping in any subframes which may be created
(i.e., if subfunctions are called).  {\tt until} or {\tt u} will keep
going until you get to the next line in the function, so the debugger
will run through subfunctions and loops until forward progress is made
in the function.  Finally, {\tt c} will continue along until the next
breakpoint or the end of the program. This is also a good place to
point out that just hitting $<$enter$>$ will repeat the last command,
so you won't have to keep hitting {\tt n} to step through many lines.


\paragraph{Visual shells} There are a number of graphical shells built
around gdb, which list local variables and let you click on parts of
your code to set breakpoints. I won't discuss their operation here, since 
it is just like that described above for the command-line debugger, except
it involves using the mouse more. There is currently a list of graphical
front-ends available at\\ {\tt http://sources.redhat.com/gdb/links/}.
\index{debugging|)}

\section{Arrays and other pointer tricks} \label{for_loops} \index{array}

An array is a sequence of one type of item, such as a thousand {\tt int}s. Here is some sample code:
%\begin{verbatim}
%[
int array_length=1000;
int *squares = malloc (array_length * sizeof(int));
int i;
for (i=0; i < array_length; i++)
      {squares[i] = i * i;}
%]
%\end{verbatim}
The syntax for declaring the array exactly matches that of allocating
a single pointer, except we needed to allocate a block of size 1000
{\tt * sizeof(int)} instead of just a single {\tt sizeof(int)}. 

To refer to the {\tt i}th element of the array, we simply use square
brackets: {\tt squares[i]}. Notice what the for loop reveals about
the indices: they begin at zero, and never reach the actual size of
the array. The array index is the {\sl offset} from the beginning of
the array, so the first element is tautologically zero steps from the first element,
the second element is one step from the first, et cetera. 

Recall that, above, we had allocated arrays in this form:\\
{\tt double a\_thousand\_doubles[1000];}\\
the difference is that this is an automatically allocated array, just
as {\tt int i} is automatically allocated, and therefore
the allocation and de-allocation of the variable is the responsibility
of the compiler---notably, it is automatically destroyed when the frame
holding it is destroyed. In function arguments, you can use the same
syntax as with pointers: 
\\ {\tt int a\_function(double *our\_array)}\\
and
\\ {\tt int a\_function(double our\_array[])}\\
are equivalent.
But be careful with this: if you {\tt free()} an automatically allocated
array, or assign it a new value with {\tt malloc()} then you're stepping
on C's turf, and will get a segfault.

\paragraph{The ampersand}\index{\&} Every variable has an address, whether you
declared it as a pointer or not. The ampersand finds that address: if
{\tt count} is an integer, then {\tt \&count} is a pointer to an integer.
You won't need to use the ampersand very often at all, and 
an ampersand will never appear in a declaration.

\paragraph{Scope issues}\index{scope} As you will recall, a copy of a variable is sent to a function, not the variable
itself, and this created problems for changing the variable in the main program. Also, when the function
leaves, all of the variables declared in the function are destroyed,
but changes made elsewhere in memory over the course of the function
are not undone. Here is a function that gets all of this wrong, whose overall hope is to subtract twenty
from the contents of {\tt an\_array}. It would be called with {\tt things\_not\_to\_do(an\_array)}.
%\begin{verbatim}
%[
int things_not_to_do(int *an_array){
int *another_array, i;
another_array = malloc(1000 * sizeof(int));
for (i=0; i<1000; i++)
    another_array[i] = an_array[i] - 20;

an_array = malloc(1000 * sizeof(int));
for (i=0; i<1000; i++)
    an_array[i] = another_array[i];
}
%]
%\end{verbatim}

First, what happens to {\tt another\_array} when this function
ends? The pointer is destroyed, but the changes made to memory using
the pointer---reserving space for a thousand integers and filling it
with values---are not undone. However, since the pointer was destroyed,
you have no way to refer to this block of memory anymore.  This is a
{\sl memory leak}:\index{memory leak} a bit of memory which is allocated and then lost.

Second, {\tt an\_array} is not a pointer sent in from outside the
function---it is a copy of a pointer sent in from outside. This is not
a problem at all if we never change the pointer, but the command {\tt
an\_array = malloc (...)} changed the value of our copy {\tt an\_array}
to a new location in memory.  Again, the copy is destroyed at the end
of the function, having allocated a block of memory we will never be
able to recover.

Here is a function which corrects these errors:

%\begin{verbatim}
%[
int still_inefficient_but_works(int **an_array){
    int *another_array, i;
    another_array = malloc(1000 * sizeof(int));
    for (i=0; i<1000; i++)
        another_array[i] = *an_array[i] - 20;

    free(*an_array);
    *an_array = malloc(1000 * sizeof(int));
    for (i=0; i<1000; i++)
        *an_array[i] = another_array[i];
    free(another_array);
}
%]
%\end{verbatim}

The memory leak with {\tt another\_array} was alleviated by simply calling {\tt free()} at the end of the
function. The problem with changing the value of the pointer was solved by sending the function a pointer
to the pointer. This is exactly analagous to the previous problem: we wanted to change the value of an
integer, so we sent the function a copy of a pointer to the integer; here we want to change the value of a
pointer, so we send in a copy of a pointer to the pointer. Notice also that once we give {\tt *an\_array}
a new value, we've lost the means of referring to the area of memory pointed to by the original value of
{\tt *an\_array}. This is another memory leak, which we prevent by {\tt free}ing {\tt *an\_array} before
changing it.

Here are two equivalent alternatives for calling the function:
%\begin{verbatim}
%[
int *some_numbers = malloc(array_size * sizeof(int));
//fill some_numbers with values
still_inefficient_but_works(&some_numbers);

int **some_other_numbers;
*some_other_numbers = malloc(array_size * sizeof(int));
//fill some_other_numbers with values
still_inefficient_but_works(some_other_numbers);
%]
%\end{verbatim}

\subsection{Arrays of structs}	
Before, when we had defined the \ttind{struct} for complex numbers, we would refer to its elements using a
dot, such as {\tt a.real} or {\tt b.imaginary}. For a pointer to a structure, we use {\tt ->} instead of 
a dot.  Here are some examples using the previous definition of the {\tt complex} structure.
%\begin{verbatim}
%[
complex *ptr_to_cplx = malloc (sizeof(complex));
ptr_to_cplx->real = 2;
ptr_to_cplx->imaginary = -2;
complex *array_of_cplxes = malloc (30 * sizeof(complex));
array_of_cplexes[15]->real = 3;
%]
%\end{verbatim}

If you get an error like ``request for member `real' in something not a structure or union'' then you're
using a dot where you should be using \ttind{->} or vice versa. Just switch to the other and try again.


\subsection{Reallocating} If you know how many items you will have
in your array, then you probably won't bother with pointers, and will
instead use the {\tt int fixed\_list[300]} declaration, so you can leave
the memory allocation issues to the computer. But if you try to put 301
elements in the list (which, you will recall, means putting something
in {\tt fixed\_list[300]}), then you will be using memory which the
machine hadn't
allocated for you---a segfault.

If you're not sure about the size of your array, then you'll need to
expand the array as you go. Here's a snippet of code to show you the syntax:
%\begin{verbatim}
%[
#include <malloc.h>     //malloc and realloc
complex *data_array = malloc (sizeof(float));
int data_count = 0;

while (!end_of_file){
    data_count++;
    data_array = realloc(data_array, data_count * sizeof(float));
    data_array[data_count - 1] = read_in_data_from_file();
}
%]
%\end{verbatim}

We first use {\tt malloc} in the initialization of {\tt data\_array}
to ensure that the variable points to a real location in memory. Then
we start reading data from the file. Every time we are about to draw
more data into the array from the data file, we use \ttind{realloc} to
allocate a new block of memory that would be of sufficient size. The first
argument to {\tt realloc} is the pointer whose space you need resized,
and the second argument is the new size.  The first part of this new
block of memory will be the {\tt data\_array} so far, and the end will
be an allocated but garbage-filled space ready for us to put data into.

\section{Strings} \index{strings|ff}

Strings such as {\tt "hello"} are implemented as arrays of individual characters, followed by an invisible
null character, written as {\tt $\backslash$0}. This means that you have to think in terms of arrays when dealing
with strings. For example:
%\begin{verbatim}
%[
char hello[20];
char *hello2 = "Hi.";
hello = "Hi there."; //This will crash.
hello = hello2;      //Won't crash, but still wrong.
%]
%\end{verbatim}

As with arrays of integers, we can specify a list to put in to the array when we initialize the array, but
not later.

The standard library gives us a number of convenience functions that facilitate dealing with strings; the
most useful would be {\tt strcpy}; see also {\tt sprintf}, below.
%\begin{verbatim}
%[
#include <string.h>
strcpy(hello, "Hi there."); //the right way.
strcpy(hello, hello2);      //Also correct.
%]
%\end{verbatim}

The note above about skimming the standard library documentation is especially apropos here, since the
standard library has functions for the most common tedious string operations.

\paragraph{Printing} \index{printing|see{{\tt printf}}}
C's standard printing functions are much like the rest of the language: not very attractive, initially
unintuitive, but in the end not a bad way of doing things. 

Each of the functions below are based on a
format string, which can include plain text and a few placeholders for numbers or other strings. For
example, {\tt "person \%s is number \%i in line$\backslash$n"}. The percent signs are place-holders for values that we
will specify later. Here are the odd characters you will need for almost all of your work:

\begin{tabular}{rl}
{\tt \%i}	& insert an integer here\\
{\tt \%g}	& insert a real number here\\
{\tt \%s}	& insert a string here\\
{\tt $\backslash$n}	& begin a new line\\
{\tt $\backslash$"}	& a quote that won't end the string\\
$\backslash$(newline)	& continue the string on the next line
\end{tabular}

There are {\sl many} more format specifiers, which will give you a great deal of control; you may want
them when printing tables, for example, and can refer to any of a number of detailed references when you
need these. [The `g' in {\tt \%g} stands for `general format', by the way.]

Of course, we need to specify {\sl which} integer, real, or string to insert, and the list of names
follows directly after the format string. For example:
%\begin{verbatim}
%[
#include <stdio.h>
printf("person %s is number %i in line\n", 
                          name, position);
%]
%\end{verbatim}
This chapter (and the book) is filled with examples of \ttind{printf}; you may want to find a few and
verify that they will indeed print what they promise to.

\paragraph{printing to strings} Once you have the format for {\tt printf} down, you can use exactly the
same syntax to dump text to a string instead of to the screen. Here's an example for the {\tt sprintf}
(string-print-formatted) function:
%\begin{verbatim}
%[
#include <stdio.h>
char write_to_me[1000];
sprintf(write_to_me, "person %s is number %i in \
                             line\n", name, position);
%]
%\end{verbatim}
This function behaves just like {\tt printf}, but you need to specify
a string to print to before specifying the format string. 

You could even use {\tt sprintf} to implement a version of {\tt strcat}. Continuing the above example:
%\begin{verbatim}
%[
sprintf(write_to_me, "%sAlso, person %s is number %i in line\n",\
                          write_to_me, name, position);
%]
%\end{verbatim}
The first {\tt \%s} will evaluate to the original value of {\tt write\_to\_me} from above, and the next
sentence will be added on to that.

Writing to files also uses the same syntax, as you'll see in Section \ref{asst_conversions}.

\section{Other auxiliary programs} I've already talked about the debugger; here
are a few more programs that will make your life as a programmer easier.

\subsection{Make} \label{make} \index{make@{\tt make}|(}
Once your program has many sections (or sooner), you will want to use
{\tt make} to automate the process of turning your mess of files into
a C program. Typically, you have ten {\tt .c} files, which will compile
to ten {\tt .o} files, which will then be linked into one executable.
 {\tt make} is a program entirely separate from C, but which
is always found wherever compilers are.

The idea is that you describe your project using a
text file named {\tt Makefile} (capital M). The file will specify a
series of dependencies: {\tt file1.o} depends on {\tt file1.c}, but does
not depend on {\tt file2.c}, while {\tt run\_me} depends on both {\tt
file1.o} and {\tt file2.o}.  Then, it specifies what actions need to be taken
when a file is dependent on something which has changed.  For example,
here is a Makefile for a program named {\tt run\_me}, which has two {\tt
.c} files and one header file:

\begin{verbatim}
OBJECTS = file1.o file2.o           #User-defined
PROGNAME = run_me                   #User-defined
CFLAGS = -g -Wall
LINKFLAGS = -L/usr/local/lib -lgsl -lgslcblas -lsqlite
COMPILE   = gcc $(CFLAGS) -c $< -o $@

$(PROGNAME): $(OBJECTS)
        gcc $(CFLAGS) $(OBJECTS) $(LINKFLAGS) -o $(PROGNAME)

file1.o: file1.c my_headers.h       #User-defined
        $(COMPILE)
file2.o: file2.c my_headers.h       #User-defined
        $(COMPILE)
\end{verbatim}

The white space at the beginning of the indented lines is a single tab, not a bunch of spaces.
C doesn't care about this, but {\tt make} does.

At the top are a list of variables, such as the list of object file names, the final program, et cetera.
When {\tt make} encounters {\tt \$(PROGNAME)}, it will insert the value of the variable {\tt PROGNAME} in that
slot, so the line 
\begin{verbatim}
gcc $(CFLAGS) $(OBJECTS) $(LINKFLAGS) -o $(PROGNAME)
\end{verbatim}
will translate into
\begin{verbatim}
gcc  -g -Wall file1.o file2.o -lgsl -o run_me
\end{verbatim}
which looks an awful lot like what we had typed before (but not quite---this does the linking step only).

The remainder of the file are dependency lists and commands. Begin
with the second set: {\tt file1.o} depends on {\tt file1.c} and {\tt
my\_headers.h}, meaning that if either file is newer than {\tt file1.o}
(as indicated by the time stamp), then you will need to recompile {\tt
file1.o}. {\tt make} will do this by using the command which begins with
{\tt gcc} in the subsequent line. No need to go in to the details, but
this line will expand to {\tt gcc -g -Wall -c file1.c -o file1.o}. This
is the compilation step, without the linking. {\tt file2.o} has similar
dependencies.

The first dependency set says that {\tt \$(PROGNAME)}---that is, {\tt
run\_me}---depends on all of the object files. Meanwhile, the object files
depend on the {\tt .c} files and {\tt my\_header.h}, as above. So when
you edit {\tt file1.c} and then type {\tt make} at the command prompt,
{\tt make} will see that {\tt file1.o} is now out of date and needs
recompilation. This change cascades: {\tt run\_me} is now out of date,
and needs to be re-linked.

Notice that {\tt file2.o} didn't get recompiled, since it is still
up-to-date. Thus, not only will {\tt make} save you typing, it will also
save you time, since you will usually be hacking at one file at a time,
so there's no point waiting for the other object files to recompile
to exactly what they were before. Also, many programs will let you run
make from within the program. {\tt gdb} lets you do this (although on
the more primitive operating systems [Windows], you'll get errors),
as will most implementations of {\tt vi} and {\tt emacs}.

The above will serve as a Makefile for your own projects; just change
the lines marked as user-defined to fit your own file names, adding or
subtracting files in the second dependency set based on how many {\tt
.c} files you have. Don't forget to indent with a tab, not spaces. You
may also need to change the {\tt LINKFLAGS} line if you get errors from
the linker about symbols not found. But once you have a {\tt Makefile}
in the directory which correctly describes the dependencies, you'll
be able to compile quickly with a simple {\tt make} instead of the
cumbersome command line above.
\index{make@{\tt make}|)}

\subsection{Memory debugger} \index{memory debugger|see{valgrind}} \index{valgrind|(}
\index{segmentation fault} \label{valgrind}

The setup is this: you make a mistake in memory handling early in the program, but
it's not fatal. Later on in the program, you do something innocuous and get a
segfault. This is a pain to trace using {\tt gdb}, but fortunately there's a
better way. {\tt valgrind} will run your program in anal-retentive mode, and check
every memory operation. If anything breaks the rules, you'll get the location, in
the form of a backtrace with line numbers, very much like the backtraces familiar
from {\tt gdb}.

The usage is simple: {\tt valgrind my\_program}. If you have a prodigious amount
of errors, you may want to tack on the {\tt --logfile=problems} option. It doesn't
quite print to the file name you give; do a directory listing after you run {\tt
valgrind} to see where it goes.  Your final option is to pipe the standard
error to a file: in the bash shell, which you're probably using: {\tt
valgrind my\_program 2> problems}.

\subsection{Revision control} \index{revision control|see{CVS}} \index{CVS|(}
The idea behind revision control is that your project lives in a
repository. When you want to work on the thing, you check out a copy
of the project, and when you're done making changes, you check them back
in to the repository and can delete the copy.  The repository makes a note
of every change you made, so you can check out a copy of your program as
it looked three weeks ago as easily as you could check out a current copy.

This has pleasant psychological benefits. Don't worry about experimenting
with your code: it's just a copy, and if you break it you can always check
out a fresh copy from the repository. Also, nothing matches the confidence
one gets from making major changes to the code and finding that the
results still match the results from last month to four decimal places.


Finally, revision control packages facilitate collaboration with
coauthors. If your changes are sufficiently far apart (e.g., you're
working on one function and your coauthor on another in the same file),
then the package will merge all changes to a single working copy. If
the package can't work out how to do that, it will give you a clearly
demarcated list of changes for you to accept or reject.

This method also works for any other text files you have in your
life, such as papers written in Latex, XML, or any other text-based
format. For example, this book is under revision control.

The standard revision control software (at the moment) is CVS, available at {\tt
http://cvshome.org}. It includes a detailed manual describing set-up and
operation from the command line. There are also graphical shells, such as tkCVS.
CVS is gradually being replaced by Subversion; you may or may not have a copy of
it on your system now.
\index{CVS|)}

\subsection{Help} \index{help, getting}
You probably have have all the manuals for the programs listed in this
chapter on your hard drive now. Most of them are in \TeX info format,
which you can read by commands such as {\tt info gcc}, {\tt info make},
or {\tt info cvs}. If you have trouble navigating in the {\tt info}
program, then you can get help with {\tt info info}.

There are manual pages for most of the C functions in the standard libraries. Try
{\tt man printf} or {\tt man atoi}, for example.

This help may not be available on every system---it's a bit of
a crapshoot. But all of these documents are online. Just enter the
command you would have typed at the command line into your favorite
search engine. A search for {\tt info gsl} or {\tt info printf} will
turn up exactly the documentation that is missing from your system,
formatted for the web.

\section{Advanced topics}
This optional section includes some things that are very commonly used among
C programmers but are entirely optional. You can get very far without
knowing any of the following, and much of it is generally considered to
be bad style.

\paragraph{The obfuscatory if} There's another way to write an \ttind{if} statement. The following are equivalent:
%\begin{verbatim}
%[
if (a < b)
      a;
else
      b;
%]
%\end{verbatim}
and\\ 
\comment{ {\tt (a < b) ? a : b;} .\\}
%@+
@(a < b) ? a : b;@ .\\
%@-
Both have all three components: first the condition, then the `what to do if the
condition is true' part, and then the `what to do if the condition is false'
part. However, the first is more-or-less legible to anybody who knows basic English,
and the second takes the reader a second to parse every time he or she
sees it. I include the second form here only because you may see it in
other people's code; use it at your own risk.


\paragraph{Macros} \label{macros} 

The other main use of the preprocessor is to define macros, which take
a bit of text and expand it to more text. The most common example is
expanding\\
{\tt MIN(a,b)}\\
to:\\
{\tt if (a <b) a; else b;} .\\

But there are endless pitfalls to using macros, and since it's often
difficult to visualize how a complex macro will expand, debugging
a macro---or working out that it's the macro that's broken---is
difficult.  If you do write macros and need to debug them, the {\tt -E} flag to {\tt gcc} will run only the \ind{preprocessor}, so you can
see what expands to what.

Here, by the way, is the actual code for the {\tt GSL\_MIN} macro;
it follows the first rule of macro writing, which is that everything
should be in parentheses:\\
\comment{{\tt \#include <gsl/gsl\_math.h>\\
\#define GSL\_MIN(a,b) ((a) < (b) ? (a) : (b))} \ttindex{GSL\_MIN}\\}
%[
#include <gsl/gsl_math.h>
#define GSL_MIN(a,b) ((a) < (b) ? (a) : (b)) 
%]
\ttindex{GSL\_MIN} \ttind{GSL\_MAX} is similarly defined.


The one and only one thing that a macro can do better than a function is
take a type as an argument. This takes advantage of the fact that the preprocessor 
just shunts characters around and doesn't know what its arguments represent.
For example, later you will see this form for reallocating a pointer to an array of {\tt int}s:\\
{\tt var\_array = realloc(var\_array, new\_length * sizeof(int))}.\\
With this macro:\\
%(
#define REALLOC(ptr, length, type) ptr = realloc(ptr, length * sizeof(type))
%)
\\the above line could be rewritten as:\\
%[
REALLOC(var_array, new_length, int);
%]
This macro gives you one more moving part that could break (and which
now needs to be {\tt \#include}d with every file you use it in), but
may make the code more readable.

\comment{{\tt \#define REALLOC(ptr, length, type) ptr = realloc(ptr, length * sizeof(type))}\\
{\tt REALLOC(var\_array, new\_length, int);}\\}

Finally, notice that the custom is to put macro names in caps.  You can
rely on this in code you see from others, and are encouraged to stick
to this standard when writing your own.

\paragraph{Labels} A line of code can be named, by simply providing a
name with a colon after it. You can then jump to that line via \ttind{goto}. Here is a code snippet that presents the basic idea, with a line labelled {\tt outro}:
%[
for (i=0; i< vector_size; i++){
    if (a_vector[i] > b){
        out = a;
        goto outro;
    }
}
out = b;

outro:
free(a_vector);
free(another_vector);
return out;
%]
The goto is reviled by modern computer scientists as terrible style, so
it appears infrequently. However, redundant code is also bad style. 
In the above example, getting rid of the goto would require
copying the various memory-freeing
tasks at the end of the function into the center of the {\tt for} loop.
Linus Torvalds, the author of the Linux kernel, recommends the {\tt
goto} to eliminate redundancy as above; other authors choose to never use
{\tt goto}.

An alternative is \ttind{break}, which cuts out of the innermost loop in
which it is located. Here is code that would work like the above:
%[
for (i=0; i< vector_size; i++){
    if (a_vector[i] > b){
        out = a;
        break;
    }
}
if (out != a)
    out = b;
free(a_vector);
free(another_vector);
return out;
%]

\paragraph{Switch} The \ttind{switch} statement is a clean way to
branch among many options. First, you will need a variable indicating
a single character. For example, the {\tt get\_opt} function from the
standard library will parse command line arguments; then the {\tt switch}
command will branch depending on the value returned:
%[
char c;
c = get_opt(...);
switch(c){
   case 'v':
        verbose++
        break;
   case 'w':    
        weighting_function();
        break;
   case 'f':      
        fun_function();
        break;
}
%]
So when 
{\tt c == 'v'}, the verbosity level is increased,
when {\tt c == 'w'}, the weighting function is called, 
et cetera.

Note well the abundance of {\tt break} statements.  The {\tt switch}
function just jumps to the appropriate label (recall that the colon
indicates a label) and then picks up from there---and continues. Thus,
if there were no {\tt break} after {\tt verbose++}, then the program
would merrily continue on to execute {\tt weighting\_\-function} and so
on. This is called {\sl fall-through}.

Most C tutorials include some creative example where this
fall-through is desirable, but they are all pretty contrived, and the
reader who uses {\tt switch} statements will want to take especial care
to have {\tt break}s at the end of every {\tt case}.  The {\tt break}
at the end of the list of {\tt case}s is extraneous, but there is a good
chance that you will add to your list of {\tt case}s, at which point
the {\tt break} will prevent a fall-through bug.

An alernative to the {\tt switch} is a simple series of {\tt if}s:
%[
char c = get_opt(...);
if (c == 'v'){
        verbose++
} else if (c == 'w'){
        weighting_function();
} else if (c == 'f'){
        fun_function();
}
%]
There is more redundancy here---the name {\tt c} is repeated three times
where in the {\tt switch} setup it was used once---but there is no risk
of fall-through mistakes.


\paragraph{Optimization} \index{optimization}
The \ttind{gcc} compiler can do a number of things to your code to make it
run faster. For example, if you assign {\tt a = b + c}, it may replace
every instance of {\tt a} with {\tt b + c}, or it may change the order
in which lines of code are executed. To turn on \ind{optimization},
use the {\tt -O3} flag when compiling with {\tt gcc}. [That's an `O'
as in optimization, not a zero. There's also an {\tt -O1} and an {\tt
-O2}, but as long as you're optimizing, why not go all out?]

The problem with optimization, however, is that it makes debugging
difficult. The program jumps around, so you're constantly surprised when
you step through the code, and when you ask to print the value of {\tt
a}, you'll get an error that there's no such variable defined.

It also sometimes happens that you didn't do your memory allocation duties
quite right, and things went OK without optimization, but suddenly the
program crashes when you have optimization on; the debugger will be some
help, but you may just have to re-scour your code to find the problem.

So if you feel that optimization will help (and it sometimes does not),
then turn it on only when you are certain that your program works and
you'll never need to debug it again.

Finally, you may run into authors who give you advice about how to write
faster code, telling you to use loops here and unroll them there, make
frequent use of the \ttind{inline} keyword, or order your commands based
on memory usage instead of human logic. Ignore them. It is much more
valuable to minimize the time you spend deciphering and debugging your
code than run time.  Write code to maximize readability for yourself
and your fellow humans. If you want optimization, {\tt gcc -O3} will
do almost all of these rearrangements for you.

\label{end_c_crash}
\ifbook \else
\printindex

\end{document}
\fi
