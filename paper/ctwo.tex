\chapter{\treesymbol More C tools} \label{ctwo}

If you have a good handle on Chapter \ref{c_crash}, then you already
have what you need to write some very advanced programs. But C is a
world unto itself, with hundreds of utilities to facilitate better
coding and many features for the seasoned programmer.

This chapter covers some of the additional details of C and its
environment. You can read the rest of the book without reading this
chapter, but it discusses some features and tools that you may
eventually find to be useful. The statistician reader can likely get by
with just a skim over this chapter, but readers working on simulations
or agent-based models will almost certainly need to use the structures
and techniques described here.

\section{Syntactic sugar}   
There are several ways to do almost everything in Chapter \ref{c_crash}.  For
example, one could write the three lines
\begin{lstlisting}
b = (i > j); 
a += b;
i++;
\end{lstlisting}

as the single expression \ci{a += b = i++ > j;}. The seventh
element of the array \ci{a} can be called \ci{a[6]},
\ci{*(a + 6)}, or even (for the truly perverse) \ci{6[a]}.  Some people find one-liners and pointer arithmetic
to have \ae{}sthetic appeal, and there are even cases where they may
be clearer than the more common methods. But they are an easy way to
write impossible-to-debug code, and require mastery of a great number
of details of C internals that are wholly unnecessary otherwise.

This optional section includes some of the more common alternatives that
are commonly used among C programmers. You can get very far without
knowing any of the following, and some of it is generally considered to
be bad style. The reader whose interest is piqued and would like to
learn more about how C works and about the many alternatives that I
did not mention here is referred to the authoritative and surprisingly
readable reference for the language: \cite{kandr:c}.

\paragraph{The obfuscatory if}\ckeyind{if} There is another way to write an \ci{if} statement. The following are equivalent:
\begin{lstlisting}
if (a < b)
      a;
else
      b;
\end{lstlisting}
and
\begin{lstlisting}
(a < b) ? a : b;
\end{lstlisting}
Both have all three components: first the condition, then the `what to do if the
condition is true' part, and then the `what to do if the condition is false'
part. However, the first is more-or-less legible to anybody who knows basic English,
and the second takes the reader a second to parse every time he or she
sees it. 

The condensed form is primarily useful because you can put it on the
right side of an assignment. For example, in Listing \ref{birds.c}, you will see the 
following snippet:
\begin{lstlisting}
if (gsl_rng_uniform(r) > 0.5)
    out->type  = 'd';
else
    out->type  = 'h';
\end{lstlisting}
It calls the GSL's random number generator to produce a random uniforn
number between zero and one, and if the draw is greater than ${1\over 2}$,
then \ci{out->type} is set to \ci{'d'}; else it is set to \ci{'h'}. With
the obfuscatory if, these four lines can be reduced to one:
\begin{lstlisting}
out->type  = gsl_rng_uniform(r) > 0.5 ? 'd' : 'h';
\end{lstlisting}

\paragraph{Macros} \label{macros} \vocabmarker{macro}

As well \ci{\#including} files, 
the preprocessor also can define macros, which take
a bit of text and expand it to more text. The easiest form is in
defining constants, such as 
\begin{lstlisting}
#define ARRAY_SIZE 10
\end{lstlisting}
Notice that you do not use an equals sign with \ci{\#define}s.  You may
have encountered the detail of C that all global varaibles must have
constant size (due to how the compiler sets them up). Thus, if you
attempt to compile the following program:
\begin{lstlisting}
int array_size  = 10;
int a[array_size];

int main(){
    return;
}
\end{lstlisting}
you will get an error like \bi{variable-size type declared outside of
any func\-tion}.

The easy alternative is to simply leave the declaration at the top of
the file but move the initialization into \ci{main}, but you can also
fix the problem with \ci{\#define}. The following program will compile
properly, because the preprocessor makes sure that the compiler never
even sees \ci{ARRAY\_SIZE}.
\begin{lstlisting}
#define ARRAY_SIZE 10;
int a[ARRAY_SIZE];

int main(){
    return;
}
\end{lstlisting}


You can also \ci{\#define} functions. The most common example is expanding\\
\ci{MIN(a,b)}\\
to:\\
\ci{if (a $<$ b) a; else b;} .

But there are endless pitfalls to using macros, and since it is often
difficult to visualize how a complex macro will expand, debugging
a macro---or working out that it is the macro that is broken---is
difficult.  If you do write macros and need to debug them, the \ci{-E}
flag to \ci{gcc} will run only the \ind{preprocessor}, so you can see
what expands to what.

Here, by the way, is the actual code for the \ci{GSL\_MIN} macro from
the \ci{<gsl/gsl\_math>} header file;
it follows the first rule of macro writing, which is that everything
should be in parentheses:\\
\comment{\ci{\#include <gsl/gsl\_math.h>\\
\#define GSL\_MIN(a,b) ((a) < (b) ? (a) : (b))} \cindex{GSL\_MIN}\\}
\begin{lstlisting}
#define GSL_MIN(a,b) ((a) < (b) ? (a) : (b)) 
\end{lstlisting}
\cindex{GSL\_MIN} \cind{GSL\_MAX} is similarly defined.


The one and only one thing that a macro can do better than a function is
take a type as an argument. This takes advantage of the fact that the preprocessor 
just shunts characters around and doesn't know what its arguments represent.
For example, recall the form for reallocating a pointer to an array of \ci{int}s:\\
\ci{var\_array = realloc(var\_array, new\_length * sizeof(int))}.\\
With this macro:
\begin{lstlisting}
#define REALLOC(ptr, length, type) ptr = realloc(ptr, length * sizeof(type))
\end{lstlisting}
the above line could be rewritten as:\\
\ci{REALLOC(var\_array, new\_length, int);}\\
This macro gives you one more moving part that could break (and which
now needs to be \ci{\#include}d with every file), but
may make the code more readable.
\comment{\ci{\#define REALLOC(ptr, length, type) ptr = realloc(ptr, length * sizeof(type))}\\
\ci{REALLOC(var\_array, new\_length, int);}\\}

Finally, notice that the custom is to put macro names in caps.  You can
rely on this in code you see from others, and are encouraged to stick
to this standard when writing your own.

\paragraph{Labels and \ci{break}}\ckeyind{goto} 
A line of code can be named, by simply providing a
name with a colon after it. You can then jump to that line via \ci{goto}. Here is a code snippet that presents the basic idea, with a line labeled \ci{outro}:
\begin{lstlisting}
for (i=0; i< vector_size; i++){
    if (a_vector[i] > b){
        out = a;
        goto outro;
    }
}
out = b;

outro:
free(a_vector);
free(another_vector);
return out;
\end{lstlisting}
The goto is reviled by modern computer scientists as terrible style, so
it appears infrequently. However, redundant code is also bad style. 
In the above example, getting rid of the \ci{goto} would require copying
the various memory-freeing tasks at the end of the function into the
center of the \ci{for} loop.  Linus Torvalds,\index{Torvalds, Linus}
the author of the Linux kernel, recommends the \ci{goto} to eliminate
redundancy as above; many other authors choose to never use \ci{goto}.

\ckeyind{break}
An alternative is \ci{break}, which cuts out of the innermost loop in
which it is located. It is primarily useful when searching through an
array for an item. Once you have found what you are looking for, there
is no need to continue looping to the end of the array.
Here is code that would work about like the above:
\begin{lstlisting}
for (i=0; i< vector_size; i++){
    if (a_vector[i] > b){
        out = a;
        break;
    }
}
if (out != a)
    out = b;
free(a_vector);
free(another_vector);
return out;
\end{lstlisting}

\paragraph{Switch}\ckeyind{switch} The \ci{switch} statement is a
clean way to branch among many options. First, you will need a variable
indicating a single character. For example, Listing \ref{getopt} (page
\pageref{getopt}) uses the \ci{getopt} function to read command line
arguments. That function will return a single character, and then a
\ci{switch} statment can branch depending on the value returned.
\lstset{texcl=true} %For this whole section.
\begin{lstlisting}
char c;
c = get_opt(...); //See Section \ref{paramsec} for details.
switch(c){
   case 'v':
        verbose++
        break;
   case 'w':    
        weighting_function();
        break;
   case 'f':      
        fun_function();
        break;
}
\end{lstlisting}
\lstset{texcl=false}
So when 
\ci{c == 'v'}, the verbosity level is increased,
when \ci{c == 'w'}, the weighting function is called, 
et cetera.

Note well the abundance of \ci{break} statements.  The \ci{switch}
function just jumps to the appropriate label (recall that the colon
indicates a label) and then picks up from there---and continues. Thus,
if there were no \ci{break} after \ci{verbose++}, then the program
would merrily continue on to execute \ci{weighting\_function}, and so
on. This is called {\sl fall-through}. The
reader who uses \ci{switch} statements will want to take care
to have \ci{break}s at the end of every \ci{case}.  The \ci{break}
at the end of the list of \ci{case}s is extraneous, but there is a good
chance that you will add to your list of \ci{case}s, at which point
the \ci{break} will no longer be extraneous and will prevent a fall-through bug.

An alternative to the \ci{switch} is a simple series of \ci{if}s:
\begin{lstlisting}
char c = get_opt(...);
if (c == 'v'){
        verbose++
} else if (c == 'w'){
        weighting_function();
} else if (c == 'f'){
        fun_function();
}
\end{lstlisting}
There is more redundancy here---the name \ci{c} is repeated three times
where in the \ci{switch} setup it was used once---but there is no risk
of fall-through mistakes.

\summary{
\item Short if statements can be summarized to one via the \ci{condition
? true\_value : false\_value} form. 
\item You can use the preprocessor to  \ci{\#define} constants an short
functions. 
\item A line can be a label via the \ci{label\_name:} form. This can be
used for \ci{goto}s or for \ci{switch} statements. 
\item You will never need any of these bits of syntax, but may find them to be convenient.
}


\section{Function pointers} \index{function pointers}
A data point \ci{d} is stored somewhere in memory, so we can refer to
its address, \ci{\&d}. Similarly, a function \ci{f} is stored somewhere
in memory, so we can refer to its address as well.

What is a pointer to a function good for?  It lets us write
Functions that will accept any function pointer and then use the
pointed-to function.\footnote{Functions calling functions is already
confusing enough, so for this section I will capitalize \airq{Function}
to indicate a parent function that takes a function (lower case) as an
input. This is merely typography, and you will see that there is no real
difference between a parent Function and any other.} For example, a
bootstrap Function could take in a statistic-calculating function and
a data set and then return the variance of the statistic, or a Function
could search an input function for its largest value over a given range.

\subsection{Types} Before we can start writing Functions to act on
functions, we need to take the type of input function into
consideration, because not every function makes sense in every context. Say
that we want to write a Function that will take in an array of
\ci{double}s plus a function, and will apply the function to every
element of the array.\footnote{Incidentally, Apophenia has 
\cind{apop\_matrix\_apply}, \cind{apop\_matrix\_map},
\cind{apop\_vector\_apply}, and \cind{apop\_vector\_map} 
Functions to apply a function to every row of
a matrix or every element of a vector. The \ci{\dots{}apply} Functions 
apply the input function and return nothing, the \ci{\dots{}map}
Functions map the input data to an output vector via the input function,
$f: {\tt in}\rightarrow {\tt out}$.
If \cind{apop\_opts.thread\_count}\ci{>1}, then the
application will be threaded over multiple processes. See the online
reference for details.\index{threading}}
Then the input function has to have a form like:
\begin{lstlisting}
double function_name (double x);
\end{lstlisting}

If the function took in \ci{char*}s or \ci{gsl\_vector}s, it just
wouldn't work; nor would it work if it returned anything but a
\ci{double}.

Thus, function pointers have types just like any other variable, and a
Function that takes a function pointer as input will make the usual
type-checks.

As you will recall, a pointer declaration is just like a declaration for the pointed-to type but with
another star, like \ci{int *x}; the same goes for declaring function
pointers, but there are also extra parens. Here is a declaration for a
function pointer that takes in a \ci{double} and returns an \ci{int}:
\begin{lstlisting}
int (*function_name) (double x);
\end{lstlisting}
You can see that it is just like the usual \ci{int *x} sort of pointer
declaration, but the function name is in parens.  The parentheses are not
optional.

\paragraph{\ci{typedef} revisited}
Now you can put the function into your header line. A Function that
applies a function to a \ci{gsl\_vector} would have a header like
this:
\begin{lstlisting}
void apply (gsl_vector *v, int (*function_name) (double x));
\end{lstlisting}

\ckeyind{typedef}
Are you confused yet? Each component basically makes sense, but together
it is cluttered and confusing. There is a way out: \ci{typedef}. By prepending
that word before the above type declaration,
\begin{lstlisting}
typedef int (*double_to_int) (double x);
\end{lstlisting}
we have created an new type named \ci{double\_to\_int} that we can
use like any other type. Now, the declaration of the \ci{apply} Function
simplifies to:
\begin{lstlisting}[emph={double_to_int,gsl_vector}]
void apply (gsl_vector *v, double_to_int function_name);
\end{lstlisting}

\subsection{Putting \ci{typedef} to work}
Listing \ref{plotafunction} shows a program to plot any function of the
form $\Re\to\Re$. The
details of Gnuplot and its use probably won't make sense to you until
you read Chapter \ref{gnuplot}, and you may need to modify the
\ci{gnuplot} variable on line 5 to indicate the location of Gnuplot on
your system.\footnote{Try the command \bi{which gnuplot} to find it,
and if it isn't found, use your package manager to install it.}

That aside, the elements needed to pass function pointers are all there,
and should be clear to you. A quick tour of the code:\\
Line 3: To make life easier, the \ci{dfn} type is
declared at the top of the file. \\
Line 7: The \ci{sample\_function} appears, and you can see that its type matches that of \ci{dfn}. \\
Line 11: The \ci{plot\_a\_fn} Function specifies that it takes in a function of type
\ci{dfn}.\\
Line 19: Using the passed-in function is as simple
as using any other function: this line  gives no
indication that \ci{plotme} is in any way special.  \\
Line 26: Finally, in \ci{main},
you can see how \ci{plot\_a\_fn} is called. The \ci{sample\_function}
is passed in with just its name.

Once the \ci{typedef} is in place, you can see that the syntax is 
easy. You don't need extra stars in either the declaration of the
Function-of-a-function or in the call to that Function, and you can call
the pointed-to function like any other. 

\lstset{numbers=left, numberstyle=\scshape}
\codefig{plotafunction}{A demonstration of a Function that takes in
any function $\Re\to\Re$ and plots it.}
\lstset{numbers=none}

\exercise{Define a type \ci{dfn} as in line three of Listing \ref{plotafunction}. Then
write a Function with header \ci{void apply(dfn fn,
double *array, int array\_len)}, that takes as arguments a function, an
array, and the length of the array, and changes each element
\ci{array[i]} to \ci{fn(array[i])}.

Test your Function by creating an array of the natural numbers $1, 2,
3,\dots 20$ and transforming it to a list of squares.}

\summary{\item You can pass functions as function arguments, just as you
would pass arrays or numbers.
\item The
syntax for declaring a function pointer is just like the syntax for
declaring a function, but the name is in parens and is prepended by a 
star.
\item Defining a new type to describe the function helps immensely.
This requires prepending \ci{typedef} to the function pointer
declaration in the last summary point.
\item Once you have a \ci{typedef} in place, you can declare Functions
that take functions, use the passed-in functions, and call the parent
Function as you would expect. Given the \ci{typedef}, you need neither
stars nor ampersands for these operations.  
\item If the input function can take multiple types of input, use a
\ci{void *} to tell the compiler not to check types. Use this with
caution.
}

\section{Data structures}\index{data structures} Let us say that you
have a few million observations to store on your computer. How will you
organize them?

There are a few options, and choosing among them is not trivial. This
section will consider three: the array, the linked list, and the binary
tree.

\index{strings!\ci{glib} library}
This section adds yet another library to the mix: \cind{glib}, a library
of general-use functions that every C programmer seems to reimplement.
It includes a few features for string handling and other such
conveniences, and modules to handle the data structures described below.
This book makes no attempt to be a comprehensive guide to \ci{glib},
since your package manager will install both the development tools for
it and the comprehensive documentation. Its format is similar to that
of the GSL or Apophenia: it provides a number of objects, such as a list
or tree object, and the functions you need to interact with those
objects without dealing with their innards. However, the extended
example below provides a catalog of examples how one would initialize,
add to, remove from, and find elements within the structure.

\subsection{An example}
This game consists of a series of meetings between pairs of birds. Each
bird can contribute to building a nest, in which case the other bird
reaps a benefit of two \vocab{utils}, but the bird doing the work
loses one util from energy expended.\footnote{The util is a joke unit of measurement for the quantity of utility an agent gets from an action.}
Thus, if two birds cooperate, both gain one util; if one birds
cooperates and the other does not, then the first loses a util and the
other gains two; if both birds do not cooperate, then neither gains any
utility at all.

\begin{figure}[htb]
\hspace {-0.5cm}
\begin{center}
\begin{tabular}{ccc}
 & cooperate & defect \\
\hhline{~--}
cooperate &\multicolumn{1}{|c}{(1,1)} & \multicolumn{1}{c|}{(-1,2)} \\
defect &\multicolumn{1}{|c}{(2,-1)} &  \multicolumn{1}{c|}{(0,0)} \\
\hhline{~--}
\end{tabular}
\end{center}
\caption{The payoff matrix for the prisoner's dilemma game.}
\label{pdfig}
\end{figure}

This game is commonly known as a \vocab{prisoner's dilemma}, due to a
rather contrived story about two separated prisoners who must choose
between providing evidence about the other prisoner and remaining silent.
Its key feature is that cooperating always makes the agent worse off
than not cooperating (defecting). The only equilibrium to the game is
when nobody cooperates, providing zero utility all around, but the
societal optimum is when both cooperate, producing two utils of utility
total.

On top of this we can add an evolutionary twist: let us say that a bird
that is very successful will spawn chicks. Let \airq{hawks} be birds
that always defect; let \airq{doves} be birds that always cooperate. In
any one interaction, a bird gets a  better payoff as a hawk than as a dove.
So it seems that over time, the doves would all die out. 

Let us begin exploring the implementations of this simulation with a
header file listing almost all of the functions involved. It begins by
describing the basic structure that the rest of the functions depend
upon, describing a single bird.

The functions divide into two parts. The first are functions for
each relevant action in the simulation: startup, births, deaths, and
actual plays of the prisoner's delimma game. The second group are
functions for flock management, such as counting the flock or iterating
over every member of the flock. Program flow will alternate between
these two sets of routines, such as when the main program starts its
birth and death segment, which calls a function to iterate through the
flock and test each bird's status, and that function calls the functions
to generate new birds.

\birdfig{birds.h}{Header file for the birds.}

Listing \ref{birds.c} shows the first half of the program's functions.
As with any program, a good way to begin reading
it is to follow the stack: begin reading at the \ci{main} function at the
end, which begins by calling \ci{setup}, and then, for each period until
the end of the simulation, calls the \ci{flock\_plays} and then the
\ci{count} function. Every $50^{\rm th}$ period, it commits the result
to the database.

The \ci{flock\_plays} function will appear below, and will call
\ci{bird\_plays} for each bird in turn. That function pulls a random
opponent from the flock, and then calls \ci{play\_pd\_game} to pit the
two birds against each other.

The \ci{count} function will primarily call the \ci{birth\_or\_death}
function, which checks for each bird whether it lives or dies.

\comment{
\labelitemi The \ci{birth\_or\_death} function takes two arguments, both of
which are \ci{void *}. A \ci{void} pointer could be pointing to any type
of data, so it is perfect for a generic list that could be holding
anything. Internally, the \ci{GList} stores a \ci{void} pointer to your
data, plus its own internal bookkeeping (such as pointers to other 
list elements). Thus, when \ci{g\_list\_foreach} applies a function to a
list's elements, the function being input must have a header that
accepts a \ci{void*} as well. The third argument to
\ci{g\_list\_foreach} gets passed through directly to the function being
applied, which is why \ci{bird\_count} takes two arguments; this is
another perfect opportunity for a \ci{void*} that could represent any
type at all.

The first line of \ci{bird\_count} p
}
\birdfig{birds.c}{The birds.}

Now for the flock management routines, which will be implemented three
times: as an array, as a list, and as a binary tree.

\subsection{Arrays} An array is as simple as data representation can
get: just write each element right after the other. The matrices
and vectors throughout this book are arrays of this type.\footnote{The glib
library also includes its own implementation of a self-managing array
that internally calls \ci{realloc} as necessary.}

The real failing of arrays comes in adding and deleting elements. Since
the array is given a set size at initialization,
the simulation has to call \ci{realloc} every time the
list expands. If you are lucky, \cind{realloc} will not move the array
from its current location, but will simply find that there is more free
space for the array to grow. If you are not lucky, then the array will
have to be moved in its entirety to a new, more spacious home.

An array can not have a hole in the middle, so elements can not be
deleted by freeing the memory. There are a few solutions, none of which
are very pleasant. The last element of the list could be moved in to the
space, requiring a copy, a shrinking of the array, and a loss of order
in the elements. If order is important, every last element could be
shifted down a notch, so if item 50 is deleted, item 51 is put in slot
50, item 52 is put in slot 51, et cetera. This program marks dead birds
by setting their \ci{id} to \ci{-1}. This means that as the program runs,
more and more memory is used by dead elements, and the rest of the system
must check for the marker at every use.

As for finding an element, we got lucky here because the \ci{id} 
matches one-to-one with the array indices. Notice how
\ci{add\_to\_flock} takes pains to ensure that the \ci{id} and array
index will always match.

\birdfig{arrayflock.c}{The birds, array version. The fatal flaw
is that birds are copied in, but never eliminated. Dead birds will eventually
pile up.}

\subsection{Linked lists} A \vocab{linked list} is a set of \ci{struct}s connected
by pointers. The first \ci{struct} includes a \ci{next} pointer, that
points to the next element, et cetera; see Figure \ref{listfig}.

\begin{figure}[htb]
%\hskip -1.4cm
\begin{center}
\includegraphics[width=\textwidth*\real{0.65}]{figs/links}
\end{center}
\caption{The archetypal linked list.}
\label{listfig}
\end{figure}

The linked list is a favorite for agent-based simulation, because birth
and death is easy to handle.  Adding an element to a linked list is
simple: create a new node, and replace the \ci{NULL} pointer at
the end of the list with a pointer to the new node. Deleting a node is also simple:
to delete bird 2, simply reroute the \ci{next} pointer from bird 1 to bird 2 so
that it points from bird 1 to bird 3, and then free the memory holding
bird 2.

But the real failing of the linked list is the trouble of finding an
arbitrary element.  In an array, finding the ten thousandth element is
easy: \ci{flock[10000]}.
You can see in the code below
that glib provides a \ci{g\_list\_nth\_data} function to return the
$n^{\rm th}$ element of the list, which makes it look simple,
but the only way that that function can find the ten
thousandth member of the \ci{flock} is to start at the head of the list
and take 9,999 \ci{->next}
steps. In fact, if you compile and run this
program, you will see that it runs much more slowly than the array and tree 
versions.

\labelitemi The \ci{g\_list\_foreach} function is also worthy of note. It implements
exactly the sort of apply-function-to-list setup implemented above. It
takes in a list and a function, and internally applies the function to
each element. Notice also that it uses void pointers to do this, which
explains why the \ci{bird\_plays} and \ci{birth\_or\_death} functions
above took \ci{void*} arguments, and begin by casting their arguments to
their correct type.

\labelitemi As for adding and removing, the glib implementation of the list takes in
a pointer to a \ci{GList} and a pointer to the data to be added, and
returns a new pointer to a \ci{GList}. The input and output pointers
could be identical, but since this is not guaranteed, you will always
want to use the form below, that reassigns the list to a new value for
every add/delete. For example, the flock starts as \ci{NULL}, and is
given its first non-\ci{NULL} value when the first item is inserted.


\birdfig{listflock.c}{The birds, linked list version. The fatal flaw
is that finding a given bird requires traversing the entire list every
time.}


\subsection{Binary trees} The \vocab{binary tree} takes the linked list a step further
by giving each node two outgoing pointers instead of one. As in Figure
\ref{btreefig}, one may think of these pointers as the left pointer and
the right pointer, and the branching allows for a tree structure. The
directions to an element are now less than trivial---to get to
\ci{data5}, start at the head (\ci{data1}), then go left, then go right.
But with eight data points in a linked list, one would need up to seven
steps to get to any element, and on average 3.5 steps. In a tree, the
longest walk is three steps, and the average is 1.625 steps. Generally,
the linked list will require on the order of $n$ steps to find an item, and a b-tree
will require on the order of $\ln(n)$ steps.

\begin{figure}[htb]
%\hskip -1.4cm
\begin{center}
\includegraphics[width=\textwidth*\real{0.65}]{figs/btree}
\end{center}
\caption{The archetypal binary tree.}
\label{btreefig}
\end{figure}

The tree arrangement only makes sense if there is some sort of order to
the elements. In this case, the \ci{id} each bird is born with provides
a natural means of ordering birds. For text data, \ci{strcmp} would
provide a similar ordering. More generally, there is a \vocab{key} value given
to each element, and the elements are sorted by that key.

This adds some complication, because you now need to associate with each
tree a function for comparing keys. In the code below, \ci{g\_tree\_new}
initializes a tree using the \ci{compare\_birds} function.

In the next chapter, you will see an interesting implementation of a binary
tree: a database. Since databases require fast access to every element, 
it is natural that they would internally structure data in a binary
tree, and this is exactly how SQLite operates internally.

What if two birds have the same \ci{id}? Then there is no way to order
them uniquely, and therefore there is no way to reliably store and
retrieve them. Thus, the key for each element must be unique.

The added complication solved many of the problems above. As with the
list, inserting and deleting elements does not require major
\ci{realloc}ing, although there is often minor internal reshuffling to
keep the branches of the tree about even.
With the key and short chains, finding an element is much faster.
However, for this to work, we need to maintain a distinct key for every
bird.

This listing begins with a function to compare two keys, appropriately
named \ci{compare\_keys}. When the tree
is created (via \ci{g\_tree\_new} in the \ci{flock\_init} function), it
uses \ci{compare\_keys} as a basis for its sorting of birds.

\birdfig{treeflock.c}{The birds, linked list version. The fatal flaw
is the complication in maintaining the key for every bird. You still do
not know whether a given bird is still in the tree or not.}


\section{Parameters} \index{Command line!arguments on}\label{paramsec}
Your simulations and analyses will require
tweaking. You will want to try more agents, or you may want your program
to load a data set from a text file to a database for one run and then
use the data in the database for later runs.

There are three places where you can put such parameters and
specifications. The first option is to set variables at the top of your \ci{.c}
file or a header file. This is trivial to implement, but you will need
to recompile every time you change parameters.

The second option is to put the data in a parameter file. There are
various libraries that will read parameter files in various formats that
you can find online, and once you have learned about how to read data
from a text file to a database in Chapter \ref{sql}, you will be able to
use that as another easy means of reading in a text file of
parameters; see the exercise on page \pageref{paramex} for details.
The parameter-file method is fairly easy given the available tools, and it is
moderately easy to change a text file, since you won't have to recompile
after changing it.

The third option is to read in parameters from the command line. This
takes the most effort to implement, but allows you to change parameters
every time you run the program. You can even write batch files in Perl,
Python, or a shell-type language to run the program with different parameter variants.

The \ci{main} function takes inputs and produces an output like any
other. The output is an integer \ci{return}ed at the end of \ci{main},
which is typically zero for success or a positive integer indicating
a type of failure. The inputs are always an integer, giving the number
of command-line elements, and a \ci{char**}---an array of
strings---listing the command-line elements themselves. 
Like any function specification, the types are non-negotiable, but the
internal name you choose give these arguments is arbitrary. However, the
universal custom is to name them \cind{argc} (argument count) and
\cind{argv} (argument values).\footnote{They are in alphabetical order
in the parameters to \ci{main}, which provides an easy way to remember
that the count comes first.} This is an ingrained custom, and you can
expect to see those two names everywhere.

\codefig{argv}{Command-line parsing by directly reading \ci{argv}.}

Listing \ref{argv} shows the rudimentary use of \ci{argc} and \ci{argv}.
Here is a sample usage from my command line:
\begin{lstlisting}
>>>  /home/klemens/argv one 2 --three fo\ ur "cinco -- \"five\""
command line argument 0: /home/klemens/argv
command line argument 1: one
command line argument 2: 2
command line argument 3: --three
command line argument 4: fo ur
command line argument 5: cinco -- "five"
\end{lstlisting}
Argument zero (\ci{argv[0]}) is always the name of the command itself.
Some creative programs run differently if they are referred to by
different names, but you will generally want to just skip over \ci{argv[0]}.
After that, the elements of \ci{argv} are the command line broken at
the spaces, and could be dashes, numbers, or any other sort of text. As
you can see from the parsing of \ci{fo\textbs{} ur}, a space prepended
with a backslash is taken to be a character like any other, rather than an
argument separator. Argument five shows that everything between a pair
of quotation marks is a single argument.

For some purposes, this is all you will need to set program options from your
command line. For example you could have one program to run three
different actions with a \ci{main} like the following.
\begin{lstlisting}
int main(int argc, int **argv){
    if (argc == 1){
        printf("I need a command line argument.\n")
        return 1;
    }
    if (!strcmp(argv[1], "read"))
        read_data();
    else if (!strcmp(argv[1], "analysis_1"))
        run_analysis_1();
    else if (!strcmp(argv[1], "analysis_2"))
        run_analysis_2();
    return 0;
}
\end{lstlisting}

\lstset{numbers=left, numberstyle=\scshape}
\codefig{getopt}{Command-line parsing with \ci{getopt}.}
\lstset{numbers=none}

\paragraph{getopt}
For more complex situations, you will want to use \ci{getopt}, which
parses command lines for \vocab{switches} of the form \ci{-x...}.  It is
part of the standard C library, so it is fully portable.\footnote{As
an alternative, the GNU C library provides a library named \cind{argp}
that provides many more features and does more automatically, but is
correspondingly more complex and less portable.} 

Listing
\ref{getopt} shows a program that will display a series of exponents.
As explained by the message on lines 9--14, you can set the minimum of
the series via \ci{-m}, the maximum via \ci{-M}, and the increment via
\ci{-i}. Specify the base of the exponents after the switches.
Sample usage:
\begin{lstlisting}
>>>  ./getopt -m3 -M4 -i0.3 2
2^3: 8
2^3.3: 9.84916
2^3.6: 12.1257
2^3.9: 14.9285
\end{lstlisting}

There are three steps to the process:
\begin{itemize}
\item \ci{\#include <unistd.h>}.\footnote{Apophenia's aggregate header,
\ci{\#include <apophenia/headers.h>} includes \cind{unistd.h}.}
\item Specify a set of letters indicating valid single-letter switches in a crunched-together string like line 7 of Listing \ref{getopt}. If the switch
takes in additional info (here, every switch but \ci{-h}), indicate this with a colon after the letter. 
\item Write a \ci{while} loop to call \ci{getopt} (line 26), and then
act based upon the value of the \ci{char} that \ci{getopt} returned.
\end{itemize}

There are two more details to the process. First, \ci{argv} is text, but
you will often want to specify numbers. The function \cind{atoi}
converts ASCII text to integers, and the function
\cind{atof} converts text to \ci{float}s. 

Second, \ci{optarg} also sets the variable \ci{optind} to indicate the
position in \ci{argv} that it last visited. Thus, line 38 was able to
check whether there are any non-switch arguments remaining, and line 39
could parse the remaining argument (if any) without \ci{getopt}'s help.

Finally, notice that the program provides human assistance. If the user
gives the \ci{-h} switch or leaves off all switches entirely, then the
program prints a help message and exits. Every variable that the
user could forget to set via the command line has a default value.

\exercise{Listing \ref{plotafunction} (page \pageref{plotafunction}) is hard-coded to plot a range from
$x=0$ to $x=15$. Modify it to use \ci{getopt} to get a minimum and 
maximum from the user, with zero and fifteen as defaults. Provide help
if the user uses the \ci{-h} flag.}

\section{More tools} 
Since C is so widely used, there is an ecosystem of tools built around
helping you easily write good code.  Beyond there debugger, here are a
few more programs that will make your life as a programmer easier.

\subsection{Help} \index{help, getting}
You probably have have all the manuals for the programs listed in this
chapter on your hard drive now. 

Over time, documentation has grown increasingly interactive and
hyperlinked. The original UNIX systems included manual pages via the
\ci{man} command, and there are manual pages for most of the C functions
in the standard libraries. Try \bi{man printf} or \bi{man atoi},
for example.

\index{\TeX info@texinfo}
By the mid-90s, the \TeX info format emerged. \TeX info documents
require a \TeX info reader (EMACS can serve as one, or there is a
standalone version), which can navigate among links and tables of
contents in the documentation.
\TeX info documentation is a part of the GNU coding standards, so you
are generally guaranteed that parts of the GNU toolchain, such as
\ci{gcc} and the version of \ci{make} that you are probably using, will
have \TeX info documentation.
You can read by commands such as \bi{info gcc} or \bi{info make}. If
you have trouble navigating in the \bi{info} program, then you can
get help with \bi{info info}.


This help may not be available on every system---it's a bit of
a crap shoot. But all of these documents are online. Just enter the
command you would have typed at the command line into your favorite
search engine. A search for \bi{info gsl} or \bi{man printf} will
turn up exactly the documentation that is missing from your system,
formatted for the web.


\subsection{Memory debugger} \index{memory debugger|see{valgrind}} \index{Valgrind|(}
\index{segmentation fault}

The setup is this: you make a mistake in memory handling early in the
program, but it is not fatal, so the program continues along using bad
data. Later on in the program, you do something innocuous with your bad
data and get a segfault. This is a pain to trace using \bi{gdb}, so
there are packages designed to handle just this problem.

The first alternative is \ind{Electric Fence}, a library by Bruce Perens,
available via your package manager. It allocates memory so that all memory
mis-allocations and mis-reads will immediately crash, so
the debugger will stop on the line with the error, rather than continuing
along with bad data. Electric Fence works by redefining \cind{malloc}
in its library. To use it, you would simply recompile the program using
the efence library, by either adding \bi{-lefence} to the compilation command
or the \ci{LINKFLAGS} line in your Makefile.


Another option is \ind{Valgrind}, a program that will
run your program in anal-retentive mode, and check every memory operation. 
It is not available on all systems (it is generally Linux-centric), but
if it is available, it is easier to use (no recompilation) and provides much more information than efence or
\bi{gdb} alone. If anything breaks the rules, Valgrind will give you
the location, in the form of a backtrace very much like the backtraces
familiar from \bi{gdb}. It can even be set to start the debugger as soon
as it catches something wrong.\footnote{Use the \bi{db-attach} switch.
E.g., \bi{valgrind -v --db-attach=yes ./my\_program}.}

The usage is simple: \bi{valgrind my\_program}. If you have a prodigious amount
of errors, you may want to tack on the \bi{--logfile=problems} option. It doesn't
quite print to the file name you give; do a directory listing after you run \bi{valgrind} to see where it goes.  Your final option is to pipe the standard
error to a file: in the bash shell, which you are probably using: \bi{valgrind my\_program 2$>$ problems}.
\index{Valgrind|)}

\subsection{Revision control} \index{revision control|see{subversion}} \index{CVS|see{subversion}}\index{subversion|(}\label{valgrind}
The idea behind the revision control system (RCS) is that your project
lives in a repository. When you want to work, you check out
a copy of the project, and when you are done making changes, you check
them back in to the repository and can delete the copy.  The repository
makes a note of every change you made, so you can check out a copy of
your program as it looked three weeks ago as easily as you could check
out a current copy.

This has pleasant psychological benefits. Don't worry about experimenting
with your code: it is just a copy, and if you break it you can always check
out a fresh copy from the repository. Also, nothing matches the confidence
one gets from making major changes to the code and finding that the
results still match the results from last month to four decimal places.

Finally, revision control packages facilitate collaboration with
coauthors. If your changes are sufficiently far apart (e.g., you are
working on one function and your coauthor on another in the same file),
then the RCS will merge all changes to a single working copy. If
it is unable to work out how to do so, then it will give you a
clearly demarcated list of changes for you to accept or reject.

This method also works for any other text files you have in your
life, such as papers written in \LaTeX, HTML, or any other text-based
format. For example, this book is under revision control.

There is no universal standard revision control software, but the
Subversion package is readily avialable via your package manager (if it is
not already installed) For usage, the reader is referred to subversion's
own detailed manual describing set-up and operation from the command line.

If subversion is not readily available, the next best is its predecessor,
CVS, which is well-supported and even has a number of graphical
front-ends, such as tkCVS.  
\index{subversion|)}

\subsection{The \ind{profiler}} The \vocab{profiler} times how long every function
takes to execute. Its usage is much like the debugger. First, you need
to add a flag to the compilation to include profiler symbols,
\ci{-pg}. Then, execute your program, which will produce a file named
\bi{gmon.out} in the directory, with the timings that the profiler
will use. Unlike the debugger's \ci{-g} option, the \ci{-pg}
option may slow down the program significantly as it writes to
\bi{gmon.out}, so use \ci{-g} always and \ci{-pg} only
when necessary.

Finally, call \bi{gprof ./my\_executable} to produce a
human-readable table from \ci{gmon.\-out}.\footnote{\bi{gprof}
outputs to \ind{STDOUT}; use the usual shell tricks to manipulate
the output, such as piping output through a pager, \bi{gprof
./my\_executable | less}, or dumping it to a text file, \bi{gprof
./my\_executable > outfile}, that you can view in your text editor.}
See the manual (\bi{man gprof}) for further details about reading
the output.

As with the debugger, once the profiler points out where the most time
is being taken by your program, what you need to do to alleviate the
bottleneck becomes very obvious.

If you are just trying to get your programs to run, optimizing for speed 
may seem far from your mind. But it may be an interesting exercise to
run a modestly complex program through the profiler, because, like the
debugger's backtrace, its output provides another useful view of how
functions call each other.

\exercise{Add the \ci{-pg} switch to the Makefile in the birds
directory and check the timing of the three different versions. }

\exercise{In Chapter \ref{c_crash}, you wrote a number of short programs
with assertions.  [For this exercise, pick a program where \ci{main}
calls at least one other function in your code, since the profiler gets
confused by programs that only contain a \ci{main} function.] Profile
the program's timing, then re-profile it with -DNDEBUG and see how the
profiler timings change.

If the program is too fast for the profiler, then rename \ci{main} to
\ci{internal\_main} and write a new \ci{main} function with a \ci{for}
loop to call \ci{internal\_main} ten thousand times.}

\paragraph{Optimization} \index{optimization}
The \cind{gcc} compiler can do a number of things to your code to make it
run faster. For example, if you assign \ci{a = b + c}, it may replace
every instance of \ci{a} with \ci{b + c}, or it may change the order
in which lines of code are executed. To turn on \ind{optimization},
use the \ci{-O3} flag when compiling with \ci{gcc}. [That's an `O'
as in optimization, not a zero. There is also an \ci{-O1} and an \ci{-O2}, but as long as you are optimizing, why not go all out?]

The problem with optimization, however, is that it makes debugging
difficult. The program jumps around, making stepping through an odd
trip, and if \ci{a} is optimized out, then you can not check its value.
It also sometimes happens that you did not do your memory allocation duties
quite right, and things went OK without optimization, but suddenly the
program crashes when you have optimization on; the debugger will be some
help, but you may just have to re-scour your code to find the problem.
Thus, the \ci{-O3} flag is a final step, to be used only after you
are reasonably confident that your code is debugged.

\ckeyind{inline} 
Finally, you may run into authors who give you advice about how to write
faster code, telling you to use loops here and unroll them there, make
frequent use of the \ci{inline} keyword, or order your commands based
on memory usage instead of human logic. Ignore them. It is much more
valuable to minimize the time you spend deciphering and debugging your
code than shaving seconds off of your run time.  Write code to maximize
readability for yourself and your fellow humans. If you want optimization,
\ci{gcc -O3} will do almost all of these rearrangements for you.




