\setcounter{chapter}{3}
\chapter{Appendix \thechapter: Glossary} \label{glossary}

\long\def\gloss#1#2{\index{#1|textit}{\bf #1}: #2 [p  \pageref{#1firstuse}]}
\long\def\glossy#1#2{\index{#1|textit}{\bf #1}: #2}
\long\def\qv#1{{\em #1}}
\parindent 0pt
\parskip 12pt

\gloss{affine linear projection}{A linear projection can always be
expressed as a matrix $\bf T$ such that $\xv$ transformed is $\xv'{\bf
T}$. But any such projection maps $\bf 0$ to $\bf 0$. An
affine projection adds a constant, transforming $\xv$ to $\xv'{\bf T}+
K$, so $\bf 0$ now transforms to a nonzero value.}

\gloss{ANOVA}{``The analysis of variance is a body of statistical
methods of
analyzing measurements assumed to be of the structure [$y_i =
x_{1i}\beta_1 + x_{2i} \beta_2 + \cdots + x_{pi}\beta_p + e_i$, $i=1,2,
\cdots, n$], where the coefficients $\{x_{ji}\}$ are integers usually 0
or 1'' \citep{scheffe:anova}}

\gloss{apophenia}{The human tendency to see patterns in static.}

\gloss{array}{A sequence of elements, all of the same type. An array of
text characters is called a \qv{string}.}

\gloss{arguments}{The inputs to a function.} 

\gloss{binary tree}{A set of structures, similar to a \qv{linked list},
where each structure consists of data and two pointers, one to a next-left
structure and one to a next-right structure. One can typically go from the head of
the tree to an arbitrary element much more quickly than if the same data
were organized as a linked list.}

\gloss{bootstrap}{By repeated sampling with replacement from a
population, one can produce a sequence of \qv{iid} draws. The
\qv{Central Limit Theorem}
then applies, and one can find the expected value and variance of a
parameter. The name implies that using samples from the data to learn
about the data is a bit like pulling oneself up by the bootstraps.}

\gloss{call-by-address}{When calling a function, sending to the function a
copy of an input variable's location.}

\gloss{call-by-value}{When calling a function, sending to the function a
copy of an input variable's value.}

\gloss{Cauchy-Schwarz inequality}{Given the correlation coefficient
between any two vectors $\xv$ and $\yv$, $\rho_{\xv\yv}$:  $0\leq \rho_{\xv\yv}^2 \leq 1$.}

\glossy{CDF}{Cumulative density function. The integral of a \qv{PDF}.
Its value at any given point indicates the likelihood that a draw from
the distribution will be below the given point. Since the PDF is always
non-negative, the CDF is monotonically nondecreasing; at $-\infty$,
the CDF is always zero; and at $\infty$ the CDF is always one.}

\gloss{Central Limit Theorem}{Given a set of means, each from a set of
\qv{iid} draws from any data set, the set of means will approach a Normal
distribution as $n\to \infty$.}

\gloss{central moments}{Given a data vector $\xv$ and mean $\overline
\xv$, the $n^{\rm th}$ central moment is ${1\over n}\sum_{x\in \xv}
(x-\overline\xv)^n$. In the continuous case, if $x$ has distribution $p(x)$, then
the  $n^{\rm th}$ central moment of $f(x)$ is $\int_{-\infty}^\infty
(f(x)-\overline{f(x)})p(x) dx$. In both cases, the first central moment
is always zero. The second is known as the \qv{variance}, the third as
\qv{skew}, and the fourth as \qv{kurtosis}.}

\gloss{compiler}{A non-interactive program to translate code from a human-readable
\qv{source file} to a computer-readable \qv{object file}.  The compiler
is often closely intertwined with the \qv{preprocessor} and \qv{linker},
to the point that the preprocessor/compiler/linker amalgam is usually
just called the compiler.  The main compiler used in this book is
\ci{gcc}. Compare with \qv{interpreter}.}

\gloss{consistent}{A test is consistent if  the \qv{power} $\to 1$ as $n\to \infty$.}

\gloss{correlation coefficient}{Given the square roots of the covariance and variances, $\sigma_{\xv\yv}$, $\sigma_\xv$, and $\sigma_\yv$,
the correlation coefficient $\rho_{\xv\yv}\equiv{\sigma_{\xv\yv}\over
\sigma_\xv \sigma_\xv}.$}

\gloss{covariance}{For two data vectors $\xv$ and $\yv$, $\sigma^2_{\xv\yv}
\equiv {1\over n}\sum_i(x_i-\overline \xv)(y_i-\overline \yv)$.}

\gloss{crosstab}{A two-dimensional table, where each row represents
values of one variable ($y$), each column represents values of another
variable ($x$), and each (row,column) entry provides some summary statistic of
the subset of data where $y$ has the given row value and $x$ has the
given column value. For example, $y$ may be gender, $x$ may be a set of
age ranges, and the summary statistic may be average income; then the
first cell would give the average income for males age 0--18, the one
below it would give average income for females 0--18; the next colum
would have values for males and females 18--25, et cetera.
}

\glossy{Cram\'er-Rao lower bound}{The elements of the covariance matrix of
the estimate of a parameter vector must be equal to or greater than the
elements of the \qv{information matrix}; that is, the information matrix
provides the lower bound on the variance of an estimate.}

\gloss{debugger}{A standalone program that runs a program, allowing the
user to halt the program at any point, view the \qv{stack} of
\qv{frames}, and query the program for the value of a variable at that
point in the program's execution.}

\gloss{declaration}{A line of code that indicates the \qv{type} of a
variable.}

\gloss{degrees of freedom}{The number of dimensions along which a data set 
varies. If all $n$ data points are independent, then $df=n$, but if
there are restrictions that reduce the data's dimensionality, then
$df<n$.}

\gloss{dependency}{A statement in a Makefile indicating that one file
depends on another, such as an \qv{object file} that depends on a \qv{source file}. 
When the depended-on file changes, the dependent file will need
to be re-produced.}

\glossy{dummy variable}{A variable that takes on discrete values
(usually just zero or one) to indicate the category in which an
observation lies.}

\glossy{environment variable}{A set of variables maintained by the
system and passed to all child programs. They are typically set from the 
\qv{shell}'s \ci{export} command.}

\glossy{efficiency}{A parameter estimate that comes as close as possible
to achieving the \qv{Cram\'er-Rao lower bound}, and thus
has as small a variance as possible, is dubbed an efficient estimate.}

\gloss{expected value}{The first \qv{central moment}, aka the mean.}

\gloss{frame}{A collection of a function and all of the variables that
are in \qv{scope} for the function.}

\gloss{GCC}{The GNU Compiler Collection, which reads \qv{source files}
in a variety of languages and produces \qv{object files} accordingly.
This book only uses its ability to read and compile C code.}

\gloss{generalized least squares}{The \qv{ordinary least squares} model assumes that the
covariance matrix among the observations is $\Sigma = \Iv$ (the identity matrix).
A GLS model is any model that otherwise conforms to the OLS assumptions,
but allows  $\Sigma$ to take on a different form.}

\gloss{Gibbs sampling}{A method of Markov Chain Monte Carlo. All
dimensions but one are held fixed, and a Monte Carlo method is used to
determine the optimum value for the free dimension given the fixed
values. Then, that dimension is held fixed at its new pseudo-optimum,
and the next dimension is allowed to vary, and its optimum found. By
repeatedly iterating through the dimensions, an overall optimum can
be found.}

\gloss{globbing}{The limited \qv{regular expression} parsing provided by
a \qv{shell}, such as expandind \bi{*.c} to the full list of file names
ending in \ci{.c}. Generally uses an entirely different syntax from most
regular expression parsers.}

\gloss{graph}{A set of nodes, connected by edges. The edges may be
directional (thus forming a directional graph). Not to be confused
with a \qv{plot}.}

\glossy{header file}{A C file consisting entirely of declarations and
type definitions. By \ci{\#include}-ing it in multiple C files, the
variables, functions, and types declared in the header file can be
defined in one file and used in many.}

\glossy{Hessian}{The matrix of second derivatives of a function. For
example, given a log likelihood function $L(\thetav)$, the expected
value of its Hessian is
the \qv{information matrix}.}

\gloss{heteroskedastic}{When observations in a data set have different
variances, such as observations on the consumption rates of the 
poor and the wealthy. This violates an assumption of OLS, and can
therefore produce inefficient estimates; \qv{weighted least squares}
solves this problem.}

\glossy{information matrix}{The matrix of expected values of the second
derivatives of the log likelihood. See also the \qv{Cram\'er-Rao lower
bound}.}

\gloss{instrumental variable}{If a variable is measured with error, then
the OLS parameter estimate based on that variable will not be
\qv{unbiased}. An instrumental variable is a replacement variable that
is highly correlated with the measured-with-error variable. A variant
of OLS using the instrumental variable will produce unbiased parameter
estimates.}

\gloss{Interaction}{.}

\glossy{interpreter}{A program to translate code from a human-readable
language to a computer's \qv{object code} or some other binary
format. The user inputs individual commands, and then the interpreter
produces the appropriate machine code and executes that code. Gnuplot
and the sqlite3 command-line program are interpreters. Compare
with \qv{compiler}. }

\gloss{jackknife}{.}

\gloss{join}{.}

\gloss{kurtosis}{The fourth \qv{central moment}.}

\glossy{library}{A set of functions and variables that perform tasks
related to some specific task, such as numeric methods or 
\qv{linked list} handling. The library is basically an \qv{object file}
in a slightly different format, and typically kept elsewhere on the library \qv{path}.}

\gloss{linked list}{A set of structures, where each structure holds data
and a pointer to the next structure in the list. One could traverse the
list by following the pointer from the head element to the next element,
then following that element's pointer to the next element, et cetera.}

\gloss{linker}{A program that takes in a set of \qv{libraries} and
\qv{object files} and outputs an executable program.}

\gloss{make}{A program that keeps track of \qv{dependencies}, and
runs commands (specified in a Makefile) as needed to keep all files 
up-to-date as their dependencies change. Usually used to produce
executables when their \qv{source files} change.}

\gloss{macro}{A string of text that will have another string of
text substituted in its place. For example, a \qv{preprocessor} may
replace every occurence of  
\ci{GSL\_MIN(a,b)} with \ci{((a) < (b) ? (a) : (b))}.}

\gloss{method}{A \qv{structure} can contain pointers to functions as well
as plain data. Object-oriented programmers call a function inside a
structure a method of the structure.}

\gloss{Monte Carlo method}{Generating information about a distribution,
such as parameter estimates, by repeatedly making random draws from
the distribution.}

\gloss{noncentral moment}{Given a data vector $\xv$ and mean $\overline
\xv$, the $n^{\rm th}$ noncentral moment is ${1\over n}\sum_{x\in \xv}
x^n$. In the continuous case, if $x$ has distribution $p(x)$, then
the  $n^{\rm th}$ central moment of $f(x)$ is $\int_{-\infty}^\infty
f(x)p(x) dx$. The only noncentral moment anybody cares about is the
first---aka, the mean.}

\gloss{object file}{A computer-readable file listing the variables,
functions, and types defined in a \ci{.c} file. Object files are not 
executables until they go through \qv{linking}.}

\gloss{ordinary least squares}{A model, fully specified on page
\pageref{olsdef}, that contends that a dependent variable is the linear
combination of
a number of independent variables, plus a Normally distributed error
term.}

\gloss{overflow error}{When the value of a variable is too large for its
type, unpredictable things may occur. For example, on some systems,
\ci{MAX\_INT + 1 == -MAX\_INT}. The IEEE standard specifies that if a
variable overflows, it be set to a special pattern indicating infinity.
See also \qv{underflow error}.}

\glossy{path}{A list of directories along which the computer will search
for files. Most shells have a \ci{PATH} environment variable along which
they search for executable programs. The preprocessor searches for header
files included with angle brackets (e.g., \ci{\#include <stdlib.h>})
along the directories in the  \ci{INCLUDEPATH} environment variable, which 
can be extended using the \bi{-I} flag for the compiler. The linker
searches for libraries to include using the \ci{LIBPATH} and its
extenstions using the \bi{-L} compiler flag.}

\glossy{PDF}{Probability density function, such as the familiar bell-curve
of a Normal distribution. The total area under a PDF for any given range
is equal to the probability that a draw from the distribution will fall
in that range. The PDF is always nonnegative. Compare with \qv{CDF}.}

\gloss{pivot table}{See \qv{crosstab}.}

\gloss{plot}{A graphic with two or three axes and a function plotted
along those axes. Not to be confused with a \qv{graph}.}

\gloss{pointer}{A variable holding the location of a piece of data.}

\gloss{power}{The likelihood of rejecting a false null. This is one
minus the likelihood of a \qv{Type II error}.}

\gloss{profiler}{A program that executes other programs, and determines how much time 
is spent in each of  the program's various functions. It can thus be
used to determine where the bottlenecks are in a slow-running program.}

\gloss{query}{Any command to a database. Typically, the command uses 
the \si{select} keyword to request data from the database, but a query
may also be a non-question command, such as a command to create a new
table, drop an index, et cetera.}

\gloss{pipe}{A \qv{shell} facility that directly redirects the output
from one program to the input of another.}

\glossy{POSIX}{The Portable Operating System Interface standard.
By the mid-1980s, a multitude of variants on the \qv{UNIX} operating
system appeared; the Institute of Electrical and Electronics Engineers
convened a panel to write this standard so that programs written on one
flavor of UNIX could be more easily ported to another flavor. Santa
Cruz Operation's UNIX, International Business Machines' AIX, Hewlett-
Packard's HP-UX, Linux, and others all more or less comply with this
standard.}

\gloss{random number generator}{Formally known as a pseudorandom number
generator, a function that produces a deterministic sequence of numbers that seem
to have no pattern. By initializing the RNG with a different \qv{seed},
one can obtain different streams of numbers.}

\gloss{scope}{The section of code that is able to refer to a variable.
For variables declared outside of a function, the scope is 
everything in a file after the declaration; for variables declared
inside a function, the scope is everything after the declaration inside
the function.\footnote{There is also \qv{block scope}, which this book
does not discuss; see \citet{kandr:c}.}}

\gloss{score}{If the log likelihood function is $L(\thetav)$, then the
score is the vector of its derivatives: $S={\partial \ln P\over \partial \theta}$. }

\gloss{seed}{The value with which a random number generator is initialized.}

\gloss{segmentation fault}{An error wherin the program attempts to
access a part of the computer's memory that was not allocated to the
program. If reading from unauthorized memory, this is a security hole; if writing to
unauthorized memory, this could destroy data or create system instability.
Therefore, the system catches segfaults and halts the program
immediately when they occur.}

\gloss{shell}{A program that does little more than facilitate running
other programs. When you log in to most text-driven systems, you are
immediately put at the shell's input prompt. Most include some amount of
scripting capability.}

\gloss{singular value decomposition}{Given an $m\times n$ data matrix $\Xv$ (where typically $m >> n$), it can
be projected onto a basis space, consisting of the $n$ eigenvalues of
$\Xv'\Xv$, that has a number of desirable properties.\footnote{This is
assuming that $\Xv'\Xv$ has full rank.} The singular value
decomposition is the process of
finding the eigenvalues and projecting the data.}

\gloss{skew}{The third \qv{central moment}.}

\glossy{source code}{The human-readable version of a program. It will be
converted into object code for the computer to execute.}

\gloss{stack}{When a program starts, it begins in a \ci{main} function,
which is level zero of the stack. If \ci{main} calls a new function,
then that function can be thought of as being laid on top of the last
function. If that function calls a subfunction, that subfunction is
stacked on top of the calling function, et cetera. Only the topmost
function in the stack is actively executing at any given time. When the
topmost function completes execution, it is popped off of the stack, and
when \ci{main} is popped off the stack, the program terminates.}

\gloss{string}{An array of characters. Because the string is an array,
it is handled using \qv{pointer}-type operations, but there are also
functions to print the string like the plain text it represents.}

\gloss{structure}{A set of variables that are intended to collectively represent one
object, such as a person (comprising, e.g., a name, height, and weight)
or a bird (comprising, e.g., a type and pointers to offspring). If the
structure contains a pointer to a function, the function is called a
\qv{method} of the structure.}

\gloss{Structured Query Language}{A standard language for writing
database \qv{queries}.}

\gloss{type}{The class of data a variable is intended to represent, such
as an integer, character, or structure (which is an amalgamation of
subtypes).}

\gloss{type cast}{A command to convert a variable from one \qv{type} to
another. Some casts are done automatically, such as \ci{int}
$\rightarrow$ \ci{float}. but type casting can also be explicitly
instructed, such as to use a \ci{float} as an array index (which
requires an \ci{int}).}

\gloss{Type I error}{Rejecting the null when it is true.}

\gloss{Type II error}{Accepting the null when it is false.}

\gloss{unbiased estimator}{A test is unbiased if $(1-\beta)\geq \alpha$ for all values of the parameter.
I.e., you are less likely to accept the null when it is false than when
it is true.}

\gloss{underflow error}{When the value of a variable is smaller than the
smallest number the system can represent. For example, on any
modern system with finite-precision arithmetic, $2^{-10,000}$ is simply
zero. See also \qv{overflow error}.}

\glossy{UNIX}{An operating system developed at Bell Labs. Many
call any UNIX-like operating system by this name (often by the plural, Unices),
but UNIX properly refers only to the code written by Bell Labs, which
has evolved into code owned by Santa Cruz Operation. Others are correctly called \qv{POSIX}-compliant. The name does not stand for anything,
but is a pun on a predecessor operating system, Multics.}

\gloss{weighted least squares}{A type of \qv{GLS} method wherein
different observations are given different weights. The weights can be
for any reason, such as producing a representative survey sample, but
the method is often used for \qv{heteroskedastic} data.}
